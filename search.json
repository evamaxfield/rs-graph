[
  {
    "objectID": "qss-code-authors.html",
    "href": "qss-code-authors.html",
    "title": "Code Contribution and Authorship",
    "section": "",
    "text": "Show the code\nfrom datetime import datetime\nfrom io import StringIO\nimport os\nfrom pathlib import Path\n\nimport colormaps as cmaps\nimport IPython.display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport opinionated  # noqa\nimport pandas as pd\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sci_soft_models.dev_author_em import data as sci_soft_models_data\nfrom scipy.stats import (\n    binomtest,\n    chi2_contingency,\n    false_discovery_control,\n    pearsonr,\n)\nfrom sqlalchemy import text\n\nfrom rs_graph.db import models as db_models\nfrom rs_graph.db import utils as db_utils\n\n# Get db engine for production database\ndb_conn = db_utils.get_engine(use_prod=True)\n\n# Set seaborn style\nplt.style.use(\"opinionated_rc\")\nsns.set_palette(\n    cmaps.bold[2:]._colors.tolist(),\n)\n\n# Get or set USE_SAMPLE\nif \"QSS_CODE_AUTHORSHIP_USE_SAMPLE\" in os.environ:\n    USE_SAMPLE = bool(int(os.environ[\"QSS_CODE_AUTHORSHIP_USE_SAMPLE\"]))\nelse:\n    USE_SAMPLE = True\n\n\nNow downloading: Roboto Condensed\nAdded new font as Roboto Condensed Light\nAdded new font as Roboto Condensed\nAdded new font as Roboto Condensed\nAdded new font as Roboto Condensed Black\nNow downloading: Montserrat\nAdded new font as Montserrat Thin Light\nAdded new font as Montserrat Thin\nAdded new font as Montserrat Thin\nAdded new font as Montserrat Thin Black\nNow downloading: Source Code Pro\nAdded new font as Source Code Pro ExtraLight Light\nAdded new font as Source Code Pro ExtraLight\nAdded new font as Source Code Pro ExtraLight\nAdded new font as Source Code Pro ExtraLight Black\nNow downloading: Fira Sans\nAdded new font as Fira Sans Light\nAdded new font as Fira Sans\nAdded new font as Fira Sans\nAdded new font as Fira Sans Black\nNow downloading: Fira Sans Condensed\nAdded new font as Fira Sans Condensed Light\nAdded new font as Fira Sans Condensed\nAdded new font as Fira Sans Condensed\nAdded new font as Fira Sans Condensed Black\nNow downloading: IBM Plex Sans\nAdded new font as IBM Plex Sans Light\nAdded new font as IBM Plex Sans\nAdded new font as IBM Plex Sans\nNow downloading: Space Grotesk\nAdded new font as Space Grotesk Light Light\nAdded new font as Space Grotesk Light\nAdded new font as Space Grotesk Light\nNow downloading: Space Mono\nAdded new font as Space Mono\nAdded new font as Space Mono\nNow downloading: Roboto\nAdded new font as Roboto Light\nAdded new font as Roboto\nAdded new font as Roboto\nAdded new font as Roboto Black\nNow downloading: Jost\nAdded new font as Jost Light\nAdded new font as Jost\nAdded new font as Jost\nAdded new font as Jost Black\nNow downloading: Titillium Web\nAdded new font as Titillium Web Light\nAdded new font as Titillium Web\nAdded new font as Titillium Web\nAdded new font as Titillium Web Black\n\n\n\nContemporary scientific research fundamentally depends on specialized software tools and computational methods.\n\ndefine scientific software (analysis scripts, research tools, computational infrastructure)\nsoftware enables reproducible research and large-scale experiments\ncode serves as a detailed log of research methodology\ndue to all of the above, code is increasingly being shared alongside research articles\n\nThe development and maintenance of scientific software requires substantial contribution, yet faces persistent challenges in receiving academic recognition.\n\nsoftware contributions often receive only acknowledgments rather than authorship\nlack of formal credit affects career advancement in academia\nother general discussion of software citations and credit systems\n\nRecent initiatives to expand academic credit systems, while promising, have not fully addressed the challenges of recognizing software contributions.\n\ndescribe the Contributor Roles Taxonomy (CRediT)\nprevious research using CRediT to understand research labor distribution\nCRediT research is still centered on traditional author lists\nproblem of self-reporting without verification\n\nOur novel predictive model addresses these challenges by enabling systematic matching between scientific article authors and source code developer accounts.\n\nwe use predictive modeling due to the lack of standardized identifiers (i.e. ORCID) for developers\nfurther, lack consistency in naming and email overlap\nsemantic models handle subtle variations in identity information (general entity matching has moved to transformers and semantic embeddings)\n\nBy applying our model across a corpus of XYZ paired research articles and repositories, we provide unique insight into the dynamics of code contribution within research teams, the impact of code contribution on research outcomes, and an understanding of the authors who are and who aren’t code contributors.\n\nmove from self-reporting to verifiable source code repository commit histories\nprovide preliminary quantitative evidence of exclusion of code contributors from academic authorship\nmodel article level impact metrics as a function of software development dynamics to show the benefit code contributors have on research\nfind that first authors are more likely to be code contributors than not\nfind that code-contributing authors have reduced individual level impact metrics compared to their non-coding counterparts\n\nThese findings not only illuminate the relationship between code contribution and scientific impact but also provide an empirical foundation for reforming academic credit systems to better recognize software development contributions in research."
  },
  {
    "objectID": "qss-code-authors.html#linking-scientific-articles-and-source-code-repositories",
    "href": "qss-code-authors.html#linking-scientific-articles-and-source-code-repositories",
    "title": "Code Contribution and Authorship",
    "section": "3.1 Linking Scientific Articles and Source Code Repositories",
    "text": "3.1 Linking Scientific Articles and Source Code Repositories\n\n\nShow the code\ndef read_table(table: str) -&gt; pd.DataFrame:\n    return pd.read_sql(text(f\"SELECT * FROM {table}\"), db_conn)\n\n\n# Read all data from database\ndoc_repo_links = read_table(db_models.DocumentRepositoryLink.__tablename__)\nresearchers = read_table(db_models.Researcher.__tablename__)\ndevs = read_table(db_models.DeveloperAccount.__tablename__)\ndocuments = read_table(db_models.Document.__tablename__)\ndocument_contributors = read_table(db_models.DocumentContributor.__tablename__)\nrepositories = read_table(db_models.Repository.__tablename__)\nrepository_contributors = read_table(db_models.RepositoryContributor.__tablename__)\ntopics = read_table(db_models.Topic.__tablename__)\ndocument_topics = read_table(db_models.DocumentTopic.__tablename__)\ndataset_sources = read_table(db_models.DatasetSource.__tablename__)\nresearcher_dev_links = read_table(\n    db_models.ResearcherDeveloperAccountLink.__tablename__\n)\n\n# Drop all \"updated_datetime\" and \"created_datetime\" columns\nfor df in [\n    doc_repo_links,\n    researchers,\n    devs,\n    documents,\n    document_contributors,\n    repositories,\n    repository_contributors,\n    topics,\n    document_topics,\n    dataset_sources,\n    researcher_dev_links,\n]:\n    df.drop(columns=[\"updated_datetime\", \"created_datetime\"], inplace=True)\n\n# Specifically drop doc_repo_links \"id\" column\n# It isn't used and will get in the way later when we do a lot of joins\ndoc_repo_links.drop(columns=[\"id\"], inplace=True)\n\n# Construct reduced doc_repo_links\noriginal_doc_repo_links_len = len(doc_repo_links)\ndoc_repo_links = doc_repo_links.drop_duplicates(subset=[\"document_id\"], keep=False)\ndoc_repo_links = doc_repo_links.drop_duplicates(subset=[\"repository_id\"], keep=False)\n\n# Reduce other tables to only documents / repositories in the updated doc_repo_links\ndocuments = documents[documents[\"id\"].isin(doc_repo_links[\"document_id\"])]\nrepositories = repositories[repositories[\"id\"].isin(doc_repo_links[\"repository_id\"])]\ndocument_contributors = document_contributors[\n    document_contributors[\"document_id\"].isin(documents[\"id\"])\n]\nrepository_contributors = repository_contributors[\n    repository_contributors[\"repository_id\"].isin(repositories[\"id\"])\n]\ndocument_topics = document_topics[document_topics[\"document_id\"].isin(documents[\"id\"])]\n\n# Reduce researchers and devs to only those in the\n# updated document_contributors and repository_contributors\nresearchers = researchers[\n    researchers[\"id\"].isin(document_contributors[\"researcher_id\"])\n]\ndevs = devs[devs[\"id\"].isin(repository_contributors[\"developer_account_id\"])]\nresearcher_dev_links = researcher_dev_links[\n    (\n        researcher_dev_links[\"researcher_id\"].isin(researchers[\"id\"])\n        & researcher_dev_links[\"developer_account_id\"].isin(devs[\"id\"])\n    )\n]\n\n# Sort document topics and keep first\ndocument_topics = document_topics.sort_values(\"score\", ascending=False)\ndocument_topics = document_topics.drop_duplicates(subset=[\"document_id\"], keep=\"first\")\n\n# Create document, document topic merged table\nmerged_document_topics = pd.merge(\n    document_topics, topics, left_on=\"topic_id\", right_on=\"id\"\n)\n\n# Create basic merged tables\nmerged_document_contributor_doc_repo_links = pd.merge(\n    document_contributors, doc_repo_links, left_on=\"document_id\", right_on=\"document_id\"\n)\nmerged_repository_contributor_doc_repo_links = pd.merge(\n    repository_contributors,\n    doc_repo_links,\n    left_on=\"repository_id\",\n    right_on=\"repository_id\",\n)\n\n# Compute stats for data sources\ndata_source_stats = []\nfor _, data_source in dataset_sources.iterrows():\n    # Get total article-repo pairs\n    data_source_stats.append(\n        {\n            \"data_source\": data_source[\"name\"],\n            \"n_article_repo_pairs\": len(\n                doc_repo_links[doc_repo_links[\"dataset_source_id\"] == data_source[\"id\"]]\n            ),\n            \"n_authors\": merged_document_contributor_doc_repo_links.loc[\n                merged_document_contributor_doc_repo_links[\"dataset_source_id\"]\n                == data_source[\"id\"]\n            ][\"researcher_id\"].nunique(),\n            \"n_devs\": merged_repository_contributor_doc_repo_links.loc[\n                merged_repository_contributor_doc_repo_links[\"dataset_source_id\"]\n                == data_source[\"id\"]\n            ][\"developer_account_id\"].nunique(),\n        }\n    )\n\n# Create topic merged tables\nmerged_doc_repo_links_topics = pd.merge(\n    doc_repo_links, document_topics, left_on=\"document_id\", right_on=\"document_id\"\n).merge(topics, left_on=\"topic_id\", right_on=\"id\")\nmerged_doc_repo_links_topics_document_contributors = pd.merge(\n    merged_doc_repo_links_topics,\n    document_contributors,\n    left_on=\"document_id\",\n    right_on=\"document_id\",\n)\nmerged_doc_repo_links_topics_repository_contributors = pd.merge(\n    merged_doc_repo_links_topics,\n    repository_contributors,\n    left_on=\"repository_id\",\n    right_on=\"repository_id\",\n)\n\n# Compute stats for domains\ndomain_stats = []\nfor domain in merged_doc_repo_links_topics.domain_name.unique():\n    # Get total article-repo pairs\n    domain_stats.append(\n        {\n            \"domain\": domain,\n            \"n_article_repo_pairs\": len(\n                merged_doc_repo_links_topics[\n                    merged_doc_repo_links_topics[\"domain_name\"] == domain\n                ]\n            ),\n            \"n_authors\": merged_doc_repo_links_topics_document_contributors.loc[\n                merged_doc_repo_links_topics_document_contributors[\"domain_name\"]\n                == domain\n            ][\"researcher_id\"].nunique(),\n            \"n_devs\": merged_doc_repo_links_topics_repository_contributors.loc[\n                merged_doc_repo_links_topics_repository_contributors[\"domain_name\"]\n                == domain\n            ][\"developer_account_id\"].nunique(),\n        }\n    )\n\n# Create document merged tables\nmerged_doc_repo_links_documents = pd.merge(\n    doc_repo_links, documents, left_on=\"document_id\", right_on=\"id\"\n)\nmerged_doc_repo_links_documents_document_contributors = pd.merge(\n    merged_doc_repo_links_documents,\n    document_contributors,\n    left_on=\"document_id\",\n    right_on=\"document_id\",\n)\nmerged_doc_repo_links_documents_repository_contributors = pd.merge(\n    merged_doc_repo_links_documents,\n    repository_contributors,\n    left_on=\"repository_id\",\n    right_on=\"repository_id\",\n)\n\n# Compute stats for document types\n# This isn't a standard data pull\n# In short:\n# - pairs from PLOS are \"research articles\"\n# - pairs from JOSS are \"software articles\"\n# - pairs from SoftwareX are \"software articles\"\n# - pairs from Papers with Code / ArXiv are \"pre-prints\"\n#   UNLESS they have been published in a journal\n# All of those should be easy to assert / apply a label to with the exception\n# of Papers with Code / ArXiv pre-prints that have been published in a journal\n# In that case, we need to look at the existing document type in the database\n# If the document type is \"preprint\" use preprint, otherwise, if it's anything else,\n# use \"research article\"\n\n# Create a \"reduced_doc_types\" dataframe with document_id and \"reduced_doc_type\"\n# columns\nreduced_doc_types_rows = []\n# We can use the \"reduced_doc_types\" dataframe to calculate the stats\n\n# Iter over data sources even though we are looking for doc types\nfor _, data_source in dataset_sources.iterrows():\n    # Get total article-repo pairs\n    doc_type = None\n    if data_source[\"name\"] in [\"plos\", \"joss\", \"softwarex\"]:\n        if data_source[\"name\"] == \"plos\":\n            doc_type = \"research article\"\n        else:\n            doc_type = \"software article\"\n\n        # Add all document_ids to reduced_doc_types_rows\n        reduced_doc_types_rows.extend(\n            [\n                {\"document_id\": doc_id, \"reduced_doc_type\": doc_type}\n                for doc_id in doc_repo_links[\n                    (doc_repo_links[\"dataset_source_id\"] == data_source[\"id\"])\n                ][\"document_id\"]\n            ]\n        )\n\n    # Handle PwC\n    else:\n        # Get preprint pairs\n        preprint_pairs = merged_doc_repo_links_documents[\n            (merged_doc_repo_links_documents[\"dataset_source_id\"] == data_source[\"id\"])\n            & (merged_doc_repo_links_documents[\"document_type\"] == \"preprint\")\n        ]\n\n        # Add all document_ids to reduced_doc_types_rows\n        reduced_doc_types_rows.extend(\n            [\n                {\"document_id\": doc_id, \"reduced_doc_type\": \"preprint\"}\n                for doc_id in preprint_pairs[\"document_id\"]\n            ]\n        )\n\n        # Get research article pairs\n        # This is the same just inverted to != \"preprint\"\n        research_article_pairs = merged_doc_repo_links_documents[\n            (merged_doc_repo_links_documents[\"dataset_source_id\"] == data_source[\"id\"])\n            & (merged_doc_repo_links_documents[\"document_type\"] != \"preprint\")\n        ]\n\n        # Add all document_ids to reduced_doc_types_rows\n        reduced_doc_types_rows.extend(\n            [\n                {\"document_id\": doc_id, \"reduced_doc_type\": \"research article\"}\n                for doc_id in research_article_pairs[\"document_id\"]\n            ]\n        )\n\n# Create reduced_doc_types dataframe\nreduced_doc_types = pd.DataFrame(reduced_doc_types_rows)\n\n\n\nModern scientific research increasingly requires the public sharing of research code, creating unique opportunities to study the relationship between academic authorship and software development.\n\nmany journals and platforms now require or recommend code and data sharing\nthis requirement creates traceable links between publications and code\nthese links enable systematic study of both article-repository and author-developer relationships\n\nOur data collection process leverages multiple complementary sources of linked scientific articles and code repositories to ensure comprehensive coverage.\n\nPLOS: Traditional research articles with code requirements\nJOSS and SoftwareX: Specialized software-focused publications\nPapers with Code / ArXiv: Capturing pre-print landscape\nto reduce the complexity of dataset processing and enrichment, we filter out any article-source-code-repository pairs which store code somewhere other than GitHub\n\nThrough integration of multiple data sources, we extract detailed information about both the academic and software development aspects of each project.\n\nspecifically we utilize the Semantic Scholar API for article DOI resolution to ensure that we find the latest version for each article.\nthis is particularly important for working with preprints as they may have been published in a journal since their inclusion in the Papers with Code dataset\nwe then utilize the OpenAlex API to gather publication metadata (i.e. open access status, domain, publication date), author details (i.e. name, author position, corresponding author status), and article- and individual-level metrics (i.e. citation count, FWCI, h-index).\nthe GitHub API provides similar information for source code repositories, including repository metadata (i.e. name, description, languages, creation date), contributor details (i.e. username, name, email), and repository-level metrics (i.e. star count, fork count, issue count).\n\nwhile the majority of our data is sourced from Papers with Code, our additional collection from PLOS, JOSS, and SoftwareX as well as the enrichment from GitHub and OpenAlex together form one of the largest collections of linked, metadata enriched, datasets of paired scientific articles and associated source code repositories.\n\nin total, we collect and enrich data for 163292 article-repository pairs"
  },
  {
    "objectID": "qss-code-authors.html#a-predictive-model-for-matching-article-authors-and-source-code-contributors",
    "href": "qss-code-authors.html#a-predictive-model-for-matching-article-authors-and-source-code-contributors",
    "title": "Code Contribution and Authorship",
    "section": "3.2 A Predictive Model for Matching Article Authors and Source Code Contributors",
    "text": "3.2 A Predictive Model for Matching Article Authors and Source Code Contributors\n\n3.2.1 Annotated Dataset Creation\n\n\nShow the code\n# Load annotated dataset\nannotated_dataset = sci_soft_models_data.load_annotated_dev_author_em_dataset()\n\n# Get counts of positive and negative examples\nn_positive_examples = len(annotated_dataset.loc[annotated_dataset[\"match\"]])\nn_negative_examples = len(annotated_dataset.loc[~annotated_dataset[\"match\"]])\npct_positive_examples = round(n_positive_examples / len(annotated_dataset), 3) * 100\npct_negative_examples = round(n_negative_examples / len(annotated_dataset), 3) * 100\n\n# Create function to split row details\ndef split_dev_details(dev_details: str) -&gt; dict:\n    details_list = dev_details.split(\";\\n\")\n    details_dict = {}\n    for detail in details_list:\n        try:\n            key, value = detail.split(\": \", 1)\n        except Exception:\n            print(detail)\n            raise\n\n        # Only keep username, name, and email\n        if key in [\"username\", \"name\", \"email\"]:\n            # If value is \"None\" replace with None\n            if value == \"None\":\n                value = None\n\n            # Store to details dict\n            details_dict[key] = value\n    \n    return details_dict\n\n# Split dev details\nall_dev_details = annotated_dataset[\"dev_details\"].apply(split_dev_details)\n\n# Convert to dataframe\nall_dev_details_df = pd.DataFrame(all_dev_details.tolist())\n\n# Drop duplicates on username\nall_dev_details_df = all_dev_details_df.drop_duplicates(subset=[\"username\"])\n\n# Get counts\nn_devs = len(all_dev_details_df)\nn_devs_with_name = all_dev_details_df[\"name\"].notnull().sum()\nn_devs_with_email = all_dev_details_df[\"email\"].notnull().sum()\n\npct_devs_with_name = round(n_devs_with_name / n_devs, 3) * 100\npct_devs_with_email = round(n_devs_with_email / n_devs, 3) * 100\n\n# Get unique authors from original frame from unique semantic scholar id\nn_authors = annotated_dataset[\"semantic_scholar_id\"].nunique()\n\n\n\nThe development of an accurate author-developer matching model requires high-quality labeled training data that captures the complexity of real-world identity matching.\n\nentity matching between authors and developers is non-trivial\nmultiple forms of name variation and incomplete information\nneed to expand on specific matching challenges\nadd figure showing example matches/non-matches\n\nWe developed an annotation process to create a robust training dataset while maximizing efficiency and accuracy.\n\nfocus on JOSS articles to increase positive match density\nwe create author-developer pairs for annotation by creating all possible combinations of authors and developers within a single JOSS article-repository pair\nwe take a random sample of 3000 pairs from the full set and have two independent annotators label each\nstructured conflict resolution process\nneed to add details about annotation guidelines/criteria\n\nThe resulting annotated dataset provides a comprehensive foundation for training our predictive model while highlighting common patterns in author-developer identity matching.\n\nafter resolution of all annotated pairs, our annotated dataset contains 451 (15.0%) positive and 2548 (85.0%) negative author-developer-account pairs\nthere are 2027 unique authors and 2733 unique developer accounts within this annotated set\nhowever, not all developer accounts contain complete information, in our set 2191 (80.2%) have associated names and 839 (30.7%) have associated emails\n\n\n\n\n3.2.2 Training and Evaluation\n\n\nShow the code\ntraining_split_counts = sci_soft_models_data.load_final_model_training_split_details()\n\n# Take sum on rows\ntraining_split_counts = training_split_counts.set_index(\"split\").sum(axis=1)\ntraining_split_pct = ((training_split_counts / training_split_counts.sum()) * 100).round(1)\n\n\n\nTo optimize our predictive model for author-contributor matching, we evaluate a variety of Transformer-based base models and input features.\n\nmultiple transformer base models available\nvarious potential feature combinations\n\nWe employed a systematic evaluation to identify optimal combination of base models and input features.\n\nfirst, to ensure that there was no data leakage, we split our dataset into training and test sets\nspecifically, we created two random sets of 10% of all unique authors and 10% of all unique developers, any pairs containing either the author or developer were placed into the test set\nin doing so, we ensured that the model was never trained on any author or developer information later used for evaluation\ndue to the fact that each author and developer-account can be included in multiple annotated pairs, our final training set contains 2442 (81.4%) and our test set contains 557 (18.6%) author-developer-account pairs\nwe used three different transformer models as our fine-tuning bases and fine-tuned each using all combinations of avaiable developer-account features, from including only the developer account username to including the developer’s username, name, and email.\nto avoid overfitting and ensure generalizability, we fine-tuned each of the base models for only a single training epoch.\nmodel evaluation was performed using standard classification metrics, including accuracy, precision, recall, and F1 score\n\n\n\n\nShow the code\nexp_results = sci_soft_models_data.load_experimental_training_results()\n\n# Remove the \"time_pred\" and \"epoch_val\" columns\nexp_results = exp_results.drop(columns=[\"time_pred\", \"epoch_val\"])\n\n# Round accuracy, precision, recall, and f1 to 3 decimal places\nexp_results = exp_results.round(\n    {\n        \"accuracy\": 3,\n        \"precision\": 3,\n        \"recall\": 3,\n        \"f1\": 3,\n    }\n)\n\n# Replace \"no-optional-data\" with \"n/a\"\nexp_results[\"fieldset\"] = exp_results[\"fieldset\"].replace(\n    \"no-optional-data\", \"n/a\"\n)\n\n# Str replace references to \"dev_\" in \"fieldset\" column\nexp_results[\"fieldset\"] = exp_results[\"fieldset\"].str.replace(\"dev_\", \"\")\n\n# Str replace \"_\" with \" \" in \"fieldset\" column\nexp_results[\"fieldset\"] = exp_results[\"fieldset\"].str.replace(\"_\", \" \")\n\n# Str split fieldset values on \"-\" and rejoin with \", \"\nexp_results[\"fieldset\"] = exp_results[\"fieldset\"].str.split(\"-\").apply(\n    lambda x: \", \".join(x)\n)\n\n# Rename fieldset column to \"Optional Features\"\nexp_results = exp_results.rename(columns={\"fieldset\": \"Optional Feats.\"})\n\n# Capitalize column names\nexp_results.columns = exp_results.columns.str.title()\n\n# Get best model f1 and get the accuracy, precision, recall, and f1 for that model\nbest_model_idx = exp_results[\"F1\"].idxmax()\nbest_model_acc = exp_results.loc[best_model_idx, \"Accuracy\"]\nbest_model_prec = exp_results.loc[best_model_idx, \"Precision\"]\nbest_model_rec = exp_results.loc[best_model_idx, \"Recall\"]\nbest_model_f1 = exp_results.loc[best_model_idx, \"F1\"]\n\n\n\nAfter extensive model comparison we find that fine-tuning from Microsoft’s deberta-v3-base and including only the developer’s username and name achieves the best performance for author-developer matching.\n\nour best model achieves a binary F1 score of 0.944, with an accuracy of 0.984, precision of 0.938, and recall of 0.95 (see Figure 1 for a confusion matrix of model predictions on the test set).\nanalysis of feature importance\n\nnote that the addition of developer’s name has a “larger effect” on model performance but that could simply be because of how many more developers have a name available than an email\nalso note that there is a model that performs just as well as this one using bert-multilingual and includes the developers email however we choose to use the deberta and name only version for its simplicity as well as the fact that deberta is a much more recently developed and released model which was pre-trained on a much larger dataset (including multilingual data).\nconsidering that in most cases, deberta out-performs bert-multilingual, we believe that while the overall evaluation metrics between the top two performing models are the same, the deberta based model will generalize to other unseen data better than the bert-multilingual model\n\nall model and feature set combination results are available in Table 10\n\n\n\n\nShow the code\nIPython.display.Image(sci_soft_models_data.FINAL_MODEL_TRAINING_DATA_DIR / \"dev-author-em-confusion-matrix.png\")\n\n\n\n\n\n\n\n\nFigure 1: Confusion Matrix Produced From Evaluation of Best Performing Model (deberta-v3 with developer username, developer name, and author name).\n\n\n\n\n\n\nTo enable future research, we have made our trained model and supporting application library publicly available.\n\nPython library implementation\nHuggingFace model deployment"
  },
  {
    "objectID": "qss-code-authors.html#linking-authors-and-github-developer-accounts",
    "href": "qss-code-authors.html#linking-authors-and-github-developer-accounts",
    "title": "Code Contribution and Authorship",
    "section": "3.3 Linking Authors and GitHub Developer Accounts",
    "text": "3.3 Linking Authors and GitHub Developer Accounts\n\n\nShow the code\n# Compute stats\ndoc_type_stats = reduced_doc_types.groupby(\"reduced_doc_type\").apply(\n    lambda x: {\n        \"doc_type\": x.name,\n        \"n_article_repo_pairs\": len(x),\n        \"n_authors\": merged_doc_repo_links_documents_document_contributors.loc[\n            merged_doc_repo_links_documents_document_contributors[\"document_id\"].isin(\n                x[\"document_id\"]\n            )\n        ][\"researcher_id\"].nunique(),\n        \"n_devs\": merged_doc_repo_links_documents_repository_contributors.loc[\n            merged_doc_repo_links_documents_repository_contributors[\"document_id\"].isin(\n                x[\"document_id\"]\n            )\n        ][\"developer_account_id\"].nunique(),\n    },\n    include_groups=False,\n)\n\n# Compute stats for access status\naccess_stats = []\nfor access_status_int, access_status_name in [\n    (0, \"Closed\"),\n    (1, \"Open\"),\n]:\n    # Get total article-repo pairs\n    access_stats.append(\n        {\n            \"access_status\": access_status_name,\n            \"n_article_repo_pairs\": len(\n                merged_doc_repo_links_documents[\n                    merged_doc_repo_links_documents[\"is_open_access\"]\n                    == access_status_int\n                ]\n            ),\n            \"n_authors\": merged_doc_repo_links_documents_document_contributors.loc[\n                merged_doc_repo_links_documents_document_contributors[\"is_open_access\"]\n                == access_status_int\n            ][\"researcher_id\"].nunique(),\n            \"n_devs\": merged_doc_repo_links_documents_repository_contributors.loc[\n                merged_doc_repo_links_documents_repository_contributors[\n                    \"is_open_access\"\n                ]\n                == access_status_int\n            ][\"developer_account_id\"].nunique(),\n        }\n    )\n\n# Compute totals\ntotal_article_repo_pairs = len(doc_repo_links)\ntotal_authors = merged_document_contributor_doc_repo_links[\"researcher_id\"].nunique()\ntotal_devs = merged_repository_contributor_doc_repo_links[\n    \"developer_account_id\"\n].nunique()\n\n\n\nOur trained entity-matching model enables comprehensive identification of author-developer relationships while accounting for the complex realities of academic software development practices.\n\nmodel applied to all possible author and developer-account combinations within each article-repository pair\nrecognition that one-to-one matching may not reflect reality\ndeliberate choice to allow many-to-many relationships in matching\n\nThe presence of multiple developer accounts per individual reflects common practices in academic software development that must be accommodated in our analysis.\n\ndevelopers often maintain separate accounts for different projects or institutions\naccount transitions are common as researchers move between roles\nCHAOSS project provides precedent for this type of identity resolution\n\nFurther, while our model performs well overall, we note that there are some limitations to our approach.\n\nin most cases predictions are trivial due to minor differences in text (spelling of author name to username)\nhowever we do observe a few cases in which our model may not perform as well\nnamely, shorter names, articles and repositories which have contributors with the same last name (i.e. siblings or other relationship), and “organization” accounts (i.e. research lab GitHub accounts used for management, administration, and documentation or a project)\nTODO: should we take a sample and estimate how widespread these problems are?\nwe include appropriate filtering during analysis to ensure that we do not include author-developer pairs which are unlikely to be the same individual\n\nOur final dataset provides unprecedented scale and scope for analyzing the relationship between academic authorship and software development contributions.\n\nSpecifically, our dataset contains 138596 article-repository pairs, 295806 distinct authors, and 152170 distinct developer accounts.\na detailed breakdown of these counts by data source, domain, document type, and open access status is available in Table 1\n\n\n\n\nShow the code\n# Construct multi-row span HTML table\n# Columns should be: \"n_article_repo_pairs\", \"n_authors\", \"n_devs\"\n# Rows should be:\n# \"By Data Source\", \"By Domain\", \"By Document Type\", \"By Access Status\", and \"Total\"\n\n# HTML templates\nstats_piece_inital_row_template = \"\"\"\n&lt;tr&gt;\n  &lt;td rowspan=\"{n_rows}\"&gt;{row_name}&lt;/td&gt;\n  &lt;td&gt;{value_name}&lt;/td&gt;\n  &lt;td&gt;{article_repo_pairs}&lt;/td&gt;\n  &lt;td&gt;{authors}&lt;/td&gt;\n  &lt;td&gt;{devs}&lt;/td&gt;\n&lt;/tr&gt;\n\"\"\".strip()\n\nstats_piece_subsequent_row_template = \"\"\"\n&lt;tr&gt;\n  &lt;td&gt;{value_name}&lt;/td&gt;\n  &lt;td&gt;{article_repo_pairs}&lt;/td&gt;\n  &lt;td&gt;{authors}&lt;/td&gt;\n  &lt;td&gt;{devs}&lt;/td&gt;\n&lt;/tr&gt;\n\"\"\".strip()\n\n# Iter over stats portions (and total)\nstats_portions_html = []\nfor stats_portion, stats_name, value_key in [\n    (domain_stats, \"&lt;b&gt;By Domain&lt;/b&gt;\", \"domain\"),\n    (doc_type_stats, \"&lt;b&gt;By Document Type&lt;/b&gt;\", \"doc_type\"),\n    (access_stats, \"&lt;b&gt;By Access Status&lt;/b&gt;\", \"access_status\"),\n    (data_source_stats, \"&lt;b&gt;By Data Source&lt;/b&gt;\", \"data_source\"),\n    (\n        [\n            {\n                \"empty\": \"\",\n                \"n_article_repo_pairs\": f\"&lt;b&gt;{total_article_repo_pairs}&lt;/b&gt;\",\n                \"n_authors\": f\"&lt;b&gt;{total_authors}&lt;/b&gt;\",\n                \"n_devs\": f\"&lt;b&gt;{total_devs}&lt;/b&gt;\",\n            }\n        ],\n        \"&lt;b&gt;Total&lt;/b&gt;\",\n        \"empty\",\n    ),\n]:\n    # Order by article-repo pairs\n    stats_portion = sorted(\n        stats_portion, key=lambda x: x[\"n_article_repo_pairs\"], reverse=True\n    )\n\n    stats_portion_html = []\n    for i, stats_piece in enumerate(stats_portion):\n        if i == 0:\n            stats_portion_html.append(\n                stats_piece_inital_row_template.format(\n                    n_rows=len(stats_portion),\n                    row_name=stats_name,\n                    value_name=stats_piece[value_key],\n                    article_repo_pairs=stats_piece[\"n_article_repo_pairs\"],\n                    authors=stats_piece[\"n_authors\"],\n                    devs=stats_piece[\"n_devs\"],\n                )\n            )\n        else:\n            stats_portion_html.append(\n                stats_piece_subsequent_row_template.format(\n                    value_name=stats_piece[value_key],\n                    article_repo_pairs=stats_piece[\"n_article_repo_pairs\"],\n                    authors=stats_piece[\"n_authors\"],\n                    devs=stats_piece[\"n_devs\"],\n                )\n            )\n\n    stats_portions_html.append(\"\\n\".join(stats_portion_html))\n\n# Concat and wrap in table\nstats_table_html = f\"\"\"\n&lt;table&gt;\n  &lt;tr&gt;\n    &lt;th&gt;&lt;b&gt;Category&lt;/b&gt;&lt;/th&gt;\n    &lt;th&gt;&lt;b&gt;Subset&lt;/b&gt;&lt;/th&gt;\n    &lt;th&gt;&lt;b&gt;Article-Repository Pairs&lt;/b&gt;&lt;/th&gt;\n    &lt;th&gt;&lt;b&gt;Authors&lt;/b&gt;&lt;/th&gt;\n    &lt;th&gt;&lt;b&gt;Developers&lt;/b&gt;&lt;/th&gt;\n  &lt;/tr&gt;\n  {\" \".join(stats_portions_html)}\n&lt;/table&gt;\n\"\"\".strip()\n\nIPython.display.HTML(stats_table_html)\n\n\n\n\nTable 1: Counts of Article-Repository Pairs, Authors, and Developers broken out by Data Sources, Domains, Document Types, and Access Status.\n\n\n\n\n\n\nCategory\nSubset\nArticle-Repository Pairs\nAuthors\nDevelopers\n\n\nBy Domain\nPhysical Sciences\n116600\n240545\n130592\n\n\nSocial Sciences\n8838\n29269\n14043\n\n\nLife Sciences\n7729\n31649\n12150\n\n\nHealth Sciences\n5172\n25979\n7248\n\n\nBy Document Type\npreprint\n72177\n170301\n87311\n\n\nresearch article\n63528\n173183\n78935\n\n\nsoftware article\n2891\n9294\n12868\n\n\nBy Access Status\nOpen\n132856\n286874\n147831\n\n\nClosed\n5740\n23668\n9352\n\n\nBy Data Source\npwc\n129615\n262889\n134926\n\n\nplos\n6090\n30233\n8784\n\n\njoss\n2336\n7105\n11362\n\n\nsoftwarex\n555\n2244\n1628\n\n\nTotal\n\n138596\n295806\n152170\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Create a subset of the documents table with only document_id and publication_date\ndocuments_pub_year = documents[[\"id\", \"publication_date\"]].copy()\ndocuments_pub_year[\"publication_year\"] = pd.to_datetime(\n    documents_pub_year[\"publication_date\"],\n    utc=True,\n).dt.year\n\n# Remove any documents with pub years that have less than 100 documents\nyear_counts = documents_pub_year[\"publication_year\"].value_counts()\ndocuments_pub_year = documents_pub_year[\n    documents_pub_year[\"publication_year\"].isin(\n        year_counts[year_counts &gt;= 100].index\n    )\n]\n\n# Plot\nax = sns.countplot(\n    data=documents_pub_year,\n    x=\"publication_year\",\n)\n\n# Rotate x-labels\n_ = plt.xticks(rotation=45, ha=\"right\")\n\n\n\n\n\n\n\n\nFigure 2: Number of articles by publication year. Only publication years with 100 or more articles are included."
  },
  {
    "objectID": "qss-code-authors.html#software-development-dynamics-within-research-teams",
    "href": "qss-code-authors.html#software-development-dynamics-within-research-teams",
    "title": "Code Contribution and Authorship",
    "section": "4.1 Software Development Dynamics Within Research Teams",
    "text": "4.1 Software Development Dynamics Within Research Teams\n\nWe begin by measuring the distributions of different coding and non-coding contributors across all of the article-code-repository pairs within our dataset.\n\nexplain more, what are the different types of contributions? (coding contributor, coding-with-authorship contributor, non-coding-author, etc.)\nwhat are the basics / what do we see across the board? What are the distributions of each of these contributor types\ncompare against analysis built on CRediT statements?\n\nNext we investigate if these distributions change over time, or, by “research team size”.\n\ndefine research team size, in our case this is the total number of author-developers + non-coding authors + non-credited developers\nplot the medians of the contributor type distributions over time (by publication year)\nresults in summary\n\n\n\n\nShow the code\n# Create subset documents\ndocs_w_1_citation = documents.loc[documents[\"cited_by_count\"] &gt;= 1].copy()\n\n# Take sample?\nif USE_SAMPLE:\n    docs_w_1_citation = docs_w_1_citation.sample(frac=0.02, random_state=12)\n\n# Subset to only certain columns\ndocs_w_1_citation = docs_w_1_citation[\n    [\n        \"id\",\n        \"publication_date\",\n        \"cited_by_count\",\n        \"fwci\",\n        \"is_open_access\",\n    ]\n]\n\n# Rename id to document_id\ndocs_w_1_citation = docs_w_1_citation.rename(columns={\"id\": \"document_id\"})\n\n# Merge repository id in\ndocs_w_1_citation = docs_w_1_citation.merge(\n    doc_repo_links[\n        [\n            \"document_id\",\n            \"repository_id\",\n        ]\n    ],\n    left_on=\"document_id\",\n    right_on=\"document_id\",\n)\n\n# Merge in document details (domain, document type)\ndocs_w_1_citation = (\n    docs_w_1_citation.merge(\n        document_topics[[\"document_id\", \"topic_id\"]],\n        left_on=\"document_id\",\n        right_on=\"document_id\",\n    )\n    .merge(\n        repositories[[\"id\", \"creation_datetime\", \"last_pushed_datetime\"]],\n        left_on=\"repository_id\",\n        right_on=\"id\",\n    )\n    .drop(\n        columns=[\"id\"],\n    )\n    .merge(\n        topics[[\"id\", \"domain_name\"]],\n        left_on=\"topic_id\",\n        right_on=\"id\",\n    )\n    .drop(\n        columns=[\"id\", \"topic_id\"],\n    )\n    .merge(\n        reduced_doc_types,\n        left_on=\"document_id\",\n        right_on=\"document_id\",\n    )\n    .rename(\n        columns={\n            \"domain_name\": \"domain\",\n            \"reduced_doc_type\": \"article_type\",\n        }\n    )\n)\n\n# Drop any documents that have more than one repository (and vice versa)\ndocs_w_1_citation = docs_w_1_citation.drop_duplicates(\n    subset=[\"document_id\"], keep=False\n)\ndocs_w_1_citation = docs_w_1_citation.drop_duplicates(\n    subset=[\"repository_id\"], keep=False\n)\n\n# Iter over articles and get the team composition info\nteam_composition_rows = []\nfor _, row in docs_w_1_citation.iterrows():\n    # Get a boolean value for \"no pushes after publication\"\n    repo_details = repositories.loc[repositories[\"id\"] == row[\"repository_id\"]].iloc[0]\n\n    # Get the number of authors\n    author_ids = document_contributors.loc[\n        document_contributors[\"document_id\"] == row[\"document_id\"]\n    ][\"researcher_id\"].unique()\n    n_authors = len(author_ids)\n\n    # Get the number of devs\n    dev_ids = repository_contributors.loc[\n        repository_contributors[\"repository_id\"] == row[\"repository_id\"]\n    ][\"developer_account_id\"].unique()\n    n_devs = len(dev_ids)\n\n    # Get the set of researcher_dev_links for the authors\n    author_dev_links = researcher_dev_links.loc[\n        researcher_dev_links[\"researcher_id\"].isin(author_ids)\n    ].sort_values(\"predictive_model_confidence\", ascending=False)\n\n    # Drop duplicates by developer_account_id (keeping first)\n    # as we may have accidently matched the same dev to the multiple authors\n    author_dev_links = author_dev_links.drop_duplicates(\n        subset=[\"developer_account_id\"],\n        keep=\"first\",\n    )\n\n    # Drop any author dev links that have less than 90% confidence\n    author_dev_links = author_dev_links.loc[\n        author_dev_links[\"predictive_model_confidence\"] &gt;= 0.9\n    ]\n\n    # Get the number of authors who were devs on this paper\n    n_author_devs = 0\n    n_non_author_devs = 0\n    for author_id in author_ids:\n        author_dev_ids = author_dev_links.loc[\n            author_dev_links[\"researcher_id\"] == author_id\n        ][\"developer_account_id\"].unique()\n\n        # Fast exit\n        if len(author_dev_ids) == 0:\n            continue\n\n        # Something likely went wrong in matching\n        if len(author_dev_ids) &gt; 3:\n            continue\n\n        if any(author_dev_id in dev_ids for author_dev_id in author_dev_ids):\n            n_author_devs += 1\n        else:\n            n_non_author_devs += 1\n\n    # Append\n    team_composition_rows.append(\n        {\n            \"document_id\": row[\"document_id\"],\n            \"repository_id\": row[\"repository_id\"],\n            \"n_authors\": n_authors,\n            \"n_author_devs\": n_author_devs,\n            \"n_non_author_devs\": n_non_author_devs,\n            \"n_devs\": n_devs,\n        }\n    )\n\n# Create dataframe\nteam_composition = pd.DataFrame(team_composition_rows)\n\n# Merge with docs_w_1_citation\nteam_composition = team_composition.merge(\n    docs_w_1_citation,\n    left_on=[\"document_id\", \"repository_id\"],\n    right_on=[\"document_id\", \"repository_id\"],\n)\n\n# Filter out papers with less than 3 authors or 1 dev\nteam_composition = team_composition.loc[team_composition[\"n_authors\"] &gt;= 3]\nteam_composition = team_composition.loc[team_composition[\"n_devs\"] &gt;= 1]\n\n# Convert datetimes to datetime\nteam_composition[\"publication_date\"] = pd.to_datetime(\n    team_composition[\"publication_date\"],\n    utc=True,\n)\nteam_composition[\"last_pushed_datetime\"] = pd.to_datetime(\n    team_composition[\"last_pushed_datetime\"],\n    utc=True,\n)\nteam_composition[\"creation_datetime\"] = pd.to_datetime(\n    team_composition[\"creation_datetime\"],\n    utc=True,\n)\n\n# Calculate years since publication from 2024-11-01\nteam_composition[\"years_since_publication\"] = (\n    pd.to_datetime(\"2024-11-01\", utc=True) - team_composition[\"publication_date\"]\n).dt.days / 365.25\n\n# Calculate repo creation to last push\nteam_composition[\"repo_commit_duration\"] = (\n    team_composition[\"last_pushed_datetime\"] - team_composition[\"creation_datetime\"]\n).dt.days / 365.25\n\n# Create a \"days_since_last_push\" column\nteam_composition[\"days_from_publication_to_last_push\"] = (\n    team_composition[\"last_pushed_datetime\"] - team_composition[\"publication_date\"]\n).dt.days\n\n# Create a \"days_since_last_push\" column\nteam_composition[\"days_from_publication_to_last_push\"] = (\n    team_composition[\"last_pushed_datetime\"] - team_composition[\"publication_date\"]\n).dt.days\n\n# Must have a push within 90 days of publication\nteam_comp_no_push_after_pub = team_composition.loc[\n    team_composition[\"days_from_publication_to_last_push\"] &lt;= 90\n].copy()\n\n# Create a \"publication_year\" column\nteam_comp_no_push_after_pub[\"publication_year\"] = team_comp_no_push_after_pub[\n    \"publication_date\"\n].dt.year\n\n# Drop columns that would conflict with conversion to float\nteam_comp_no_push_after_pub = team_comp_no_push_after_pub.drop(\n    columns=[\n        \"publication_date\",\n        \"last_pushed_datetime\",\n        \"creation_datetime\",\n    ]\n)\n\n# Add dummies\nteam_comp_no_push_after_pub_dummies = pd.get_dummies(\n    team_comp_no_push_after_pub,\n    columns=[\"article_type\", \"domain\"],\n    drop_first=True,\n)\n\n# Cast all to float\nteam_comp_no_push_after_pub_dummies = team_comp_no_push_after_pub_dummies.astype(float)\n\n\n\n\nShow the code\n# Reuse the \"team_composition\" dataframe and\n# plot the distribution of the\n# number of authors, author devs, and non-author devs, and total devs\n# Split by domain, article type, and open access status\n\n# Melt the data to convert to long form\nteam_comp_no_push_after_pub_long = team_comp_no_push_after_pub.melt(\n    id_vars=[\n        \"document_id\",\n        \"publication_year\",\n        \"domain\",\n        \"article_type\",\n        \"is_open_access\",\n    ],\n    value_vars=[\n        \"n_authors\",\n        \"n_author_devs\",\n        \"n_non_author_devs\",\n    ],\n    var_name=\"Contributor Type\",\n    value_name=\"count\",\n)\n\n# Replace \"team_member_type\" values\nteam_comp_no_push_after_pub_long[\"Contributor Type\"] = (\n    team_comp_no_push_after_pub_long[\"Contributor Type\"].replace(\n        {\n            \"n_authors\": \"Authors\",\n            \"n_author_devs\": \"Code Contrib. Authors\",\n            \"n_non_author_devs\": \"Non-Author Code Contribs.\",\n        }\n    )\n)\n\n# Plot\nsns.catplot(\n    data=team_comp_no_push_after_pub_long,\n    x=\"Contributor Type\",\n    y=\"count\",\n    hue=\"Contributor Type\",\n    kind=\"box\",\n    showfliers=False,\n)\n\n_ = plt.xticks(rotation=45, ha=\"right\")\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nteam_comp_no_push_after_pub_long.groupby(\"Contributor Type\")[\"count\"].describe().drop(\n    columns=[\"count\"],\n).round(1).astype({\n    \"min\": int,\n    \"25%\": int,\n    \"50%\": int,\n    \"75%\": int,\n    \"max\": int,\n})\n\n\n\n\n\n\n\n\n\nmean\nstd\nmin\n25%\n50%\n75%\nmax\n\n\nContributor Type\n\n\n\n\n\n\n\n\n\n\n\nAuthors\n5.7\n13.2\n3\n3\n4\n6\n282\n\n\nCode Contrib. Authors\n1.0\n0.7\n0\n1\n1\n1\n6\n\n\nNon-Author Code Contribs.\n1.0\n1.2\n0\n0\n1\n1\n10\n\n\n\n\n\n\n\n\n\nShow the code\n# Create a copy of the team_comp_no_push_after_pub dataframe\nteam_comp_no_push_after_pub_counts = team_comp_no_push_after_pub.copy()\n\n# Replace binary values in \"is_open_access\" to \"Open Access\" and \"Closed Access\"\nteam_comp_no_push_after_pub_counts[\"is_open_access\"] = (\n    team_comp_no_push_after_pub_counts.apply(\n        lambda x: \"Open\" if x[\"is_open_access\"] == 1 else \"Closed\",\n        axis=1,\n    )\n)\n\n# Count team composition values and always for each control variable\ncontrol_vars = {\n    \"is_open_access\": \"OA Status\",\n    \"domain\": \"Domain\",\n    \"article_type\": \"Article Type\",\n}\ncontrol_var_tables = {}\nfor control_var, control_display_name in control_vars.items():\n    # Instead of taking median, let's return the mean and std in the following format\n    # \"mean ± std\"\n    mean_table = (\n        team_comp_no_push_after_pub_counts.groupby(control_var)[\n            [\"n_authors\", \"n_author_devs\", \"n_non_author_devs\"]\n        ]\n        .mean()\n        .reset_index()\n    )\n    std_table = (\n        team_comp_no_push_after_pub_counts.groupby(control_var)[\n            [\"n_authors\", \"n_author_devs\", \"n_non_author_devs\"]\n        ]\n        .std()\n        .reset_index()\n    )\n\n    # Merge and format to string\n    count_table_rows = []\n    for _, row in mean_table.iterrows():\n        std_row = std_table.loc[std_table[control_var] == row[control_var]]\n        count_table_rows.append(\n            {\n                control_var: row[control_var],\n                \"n_authors\": f\"{row['n_authors']:.1f} ± {std_row['n_authors'].iloc[0]:.1f}\",\n                \"n_author_devs\": f\"{row['n_author_devs']:.1f} ± {std_row['n_author_devs'].iloc[0]:.1f}\",\n                \"n_non_author_devs\": f\"{row['n_non_author_devs']:.1f} ± {std_row['n_non_author_devs'].iloc[0]:.1f}\",\n            }\n        )\n\n    # Create dataframe\n    count_table = pd.DataFrame(count_table_rows)\n\n    # Change name of the control_var column to \"Subset\"\n    count_table = count_table.rename(columns={control_var: \"Subset\"})\n\n    # Order columns\n    count_table = count_table[\n        [\"Subset\", \"n_authors\", \"n_author_devs\", \"n_non_author_devs\"]\n    ]\n    \n    # Rename columns\n    count_table = count_table.rename(\n        columns={\n            \"n_authors\": \"Authors\",\n            \"n_author_devs\": \"Code Cntrb. Auth.\",\n            \"n_non_author_devs\": \"Non-Auth. Code Cntrb.\",\n        }\n    )\n\n    # Order alphabetically\n    count_table = count_table.sort_values(\"Subset\")\n    \n    # Append\n    control_var_tables[control_display_name] = count_table\n\n\n\n\nShow the code\n# Construct multi-row span HTML table\n# Columns should be: \"Authors\", \"Code Contributing Authors\", \"Non-Author Code Contributors\"\n# Rows should be:\n# \"Open Access Status\", \"Domain\", \"Article Type\"\n\n# HTML templates\ncount_piece_inital_row_template = \"\"\"\n&lt;tr&gt;\n  &lt;td rowspan=\"{n_rows}\"&gt;{row_name}&lt;/td&gt;\n  &lt;td&gt;{value_name}&lt;/td&gt;\n  &lt;td&gt;{n_authors}&lt;/td&gt;\n  &lt;td&gt;{n_author_devs}&lt;/td&gt;\n  &lt;td&gt;{n_non_author_devs}&lt;/td&gt;\n&lt;/tr&gt;\n\"\"\".strip()\n\ncount_piece_subsequent_row_template = \"\"\"\n&lt;tr&gt;\n  &lt;td&gt;{value_name}&lt;/td&gt;\n  &lt;td&gt;{n_authors}&lt;/td&gt;\n  &lt;td&gt;{n_author_devs}&lt;/td&gt;\n  &lt;td&gt;{n_non_author_devs}&lt;/td&gt;\n&lt;/tr&gt;\n\"\"\".strip()\n\n# Iter over stats portions (and total)\ncount_portions_html = []\nfor key, count_table in control_var_tables.items():\n    count_portion_html = []\n    for i, control_value in enumerate(count_table[\"Subset\"].unique()):\n        if i == 0:\n            count_portion_html.append(\n                count_piece_inital_row_template.format(\n                    n_rows=len(count_table),\n                    row_name=key,\n                    value_name=control_value,\n                    n_authors=count_table.loc[\n                        count_table[\"Subset\"] == control_value,\n                        \"Authors\",\n                    ].iloc[0],\n                    n_author_devs=count_table.loc[\n                        count_table[\"Subset\"] == control_value,\n                        \"Code Cntrb. Auth.\",\n                    ].iloc[0],\n                    n_non_author_devs=count_table.loc[\n                        count_table[\"Subset\"] == control_value,\n                        \"Non-Auth. Code Cntrb.\",\n                    ].iloc[0],\n                )\n            )\n        else:\n            count_portion_html.append(\n                count_piece_subsequent_row_template.format(\n                    value_name=control_value,\n                    n_authors=count_table.loc[\n                        count_table[\"Subset\"] == control_value,\n                        \"Authors\",\n                    ].iloc[0],\n                    n_author_devs=count_table.loc[\n                        count_table[\"Subset\"] == control_value,\n                        \"Code Cntrb. Auth.\",\n                    ].iloc[0],\n                    n_non_author_devs=count_table.loc[\n                        count_table[\"Subset\"] == control_value,\n                        \"Non-Auth. Code Cntrb.\",\n                    ].iloc[0],\n                )\n            )\n\n    count_portions_html.append(\"\\n\".join(count_portion_html))\n\n# Concat and wrap in table\ncount_table_html = f\"\"\"\n&lt;table&gt;\n  &lt;tr&gt;\n    &lt;th&gt;&lt;b&gt;Control&lt;/b&gt;&lt;/th&gt;\n    &lt;th&gt;&lt;b&gt;Subset&lt;/b&gt;&lt;/th&gt;\n    &lt;th&gt;&lt;b&gt;Authors&lt;/b&gt;&lt;/th&gt;\n    &lt;th&gt;&lt;b&gt;Code Cntrb. Auth.&lt;/b&gt;&lt;/th&gt;\n    &lt;th&gt;&lt;b&gt;Non-Auth. Code Cntrb.&lt;/b&gt;&lt;/th&gt;\n  &lt;/tr&gt;\n  {\" \".join(count_portions_html)}\n&lt;/table&gt;\n\"\"\".strip()\n\nIPython.display.HTML(count_table_html)\n\n\n\n\nTable 2: Team Composition and Coding Status Counts Used in H1\n\n\n\n\n\n\nControl\nSubset\nAuthors\nCode Cntrb. Auth.\nNon-Auth. Code Cntrb.\n\n\nOA Status\nClosed\n5.5 ± 2.2\n1.2 ± 1.0\n1.3 ± 0.9\n\n\nOpen\n5.7 ± 13.6\n1.0 ± 0.6\n0.9 ± 1.2\n\n\nDomain\nHealth Sciences\n6.3 ± 3.2\n1.1 ± 0.5\n0.7 ± 1.0\n\n\nLife Sciences\n5.2 ± 3.2\n1.0 ± 0.6\n0.5 ± 0.7\n\n\nPhysical Sciences\n5.7 ± 14.8\n1.0 ± 0.7\n1.1 ± 1.2\n\n\nSocial Sciences\n4.4 ± 1.6\n1.0 ± 0.6\n0.5 ± 0.7\n\n\nArticle Type\npreprint\n4.9 ± 4.1\n0.9 ± 0.6\n1.1 ± 1.2\n\n\nresearch article\n5.9 ± 14.4\n1.0 ± 0.7\n0.9 ± 1.2\n\n\nsoftware article\n3.3 ± 0.5\n0.7 ± 1.1\n0.0 ± 0.0\n\n\n\n\n\n\n\n\n\n\nShow the code\ndef compute_article_level_models(\n    y_col: str,\n    data: pd.DataFrame,\n    glm_family: sm.families.Family,\n) -&gt; dict[str, sm.GLM]:\n    # Remove outliers\n    no_outliers = data[\n        data[y_col].between(\n            data[y_col].quantile(0.03),\n            data[y_col].quantile(0.97),\n        )\n    ].copy()\n\n    # Remove nans\n    no_outliers = no_outliers.dropna(subset=[y_col])\n\n    # Common features to use in all models\n    required_features = [\n        y_col,\n        \"n_authors\",\n        \"n_author_devs\",\n        \"n_non_author_devs\",\n        \"years_since_publication\",\n    ]\n\n    # Iter over different control variables and create models for each\n    models = {}\n    for control_var in [\n        \"article_type\",\n        \"domain\",\n        \"is_open_access\",\n    ]:\n        # Get control variable list\n        control_variables = [\n            col for col in no_outliers.columns if col.startswith(control_var)\n        ]\n\n        # Create control variable subset of the data\n        control_var_subset = no_outliers[required_features + control_variables].copy()\n\n        # Create interactions\n        for coding_status_col in [\"n_author_devs\", \"n_non_author_devs\"]:\n            for control_col in control_variables:\n                control_var_subset[f\"{coding_status_col} * {control_col}\"] = (\n                    control_var_subset[coding_status_col]\n                    * control_var_subset[control_col]\n                )\n\n        # Drop inf and nan\n        control_var_subset = control_var_subset.replace(\n            [float(\"inf\"), -float(\"inf\")], float(\"nan\")\n        ).dropna()\n\n        # Create x and y\n        y = control_var_subset[y_col]\n        x = control_var_subset.drop(columns=[y_col])\n        x = sm.add_constant(x)\n\n        # Fit model\n        model = sm.GLM(y, x, family=glm_family).fit()\n        models[control_var] = model\n\n    return models\n\n\n\n\nShow the code\n# Create models for cited_by_count\narticle_cited_by_count_models = compute_article_level_models(\n    \"cited_by_count\",\n    team_comp_no_push_after_pub_dummies,\n    glm_family=sm.families.NegativeBinomial(),\n)\n\n\n/opt/hostedtoolcache/Python/3.12.8/x64/lib/python3.12/site-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n\n\n\n\nShow the code\n# Get value count of publication year\nyear_counts = team_comp_no_push_after_pub[\"publication_year\"].value_counts()\n\n# Drop years with less than 100 publications\nteam_comp_no_push_after_pub_long = team_comp_no_push_after_pub_long.loc[\n    team_comp_no_push_after_pub_long[\"publication_year\"].isin(\n        year_counts.loc[lambda x: x &gt;= 100].index\n    )\n]\n\n# Look at mean of all counts of team member types over time\nsns.relplot(\n    data=team_comp_no_push_after_pub_long,\n    x=\"publication_year\",\n    y=\"count\",\n    hue=\"Contributor Type\",\n    kind=\"line\",\n    estimator=\"mean\",\n)\n\n\n\n\n\n\n\n\n\n\n4.1.1 Modeling Citations\n\nWe model an article’s total citations by the coding contributorship of the research team and controlled by a number of different factors.\nEach control variable is modeled separately and the results are presented in the tables below:\n\nControlling for article open access status: Table 3\nControlling for article domain: Table 4\nControlling for article type: Table 5\n\n\n\n4.1.1.1 Open Access Status\n\n\nShow the code\narticle_cited_by_count_models[\"is_open_access\"].summary()\n\n\n\n\nTable 3: Article Citations by Code Contributorship of Research Team Controlled by Open Access Status\n\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ncited_by_count\nNo. Observations:\n444\n\n\nModel:\nGLM\nDf Residuals:\n436\n\n\nModel Family:\nNegativeBinomial\nDf Model:\n7\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-1603.0\n\n\nDate:\nTue, 07 Jan 2025\nDeviance:\n518.69\n\n\nTime:\n18:43:34\nPearson chi2:\n921.\n\n\nNo. Iterations:\n12\nPseudo R-squ. (CS):\n0.3336\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n0.7602\n0.441\n1.724\n0.085\n-0.104\n1.624\n\n\nn_authors\n-0.0044\n0.004\n-1.097\n0.272\n-0.012\n0.003\n\n\nn_author_devs\n0.1001\n0.220\n0.454\n0.650\n-0.332\n0.532\n\n\nn_non_author_devs\n0.1467\n0.243\n0.603\n0.547\n-0.330\n0.624\n\n\nyears_since_publication\n0.3969\n0.028\n14.227\n0.000\n0.342\n0.452\n\n\nis_open_access\n0.5839\n0.451\n1.294\n0.196\n-0.300\n1.468\n\n\nn_author_devs * is_open_access\n-0.0704\n0.234\n-0.300\n0.764\n-0.530\n0.389\n\n\nn_non_author_devs * is_open_access\n0.0408\n0.248\n0.164\n0.869\n-0.445\n0.527\n\n\n\n\n\n\n\n\n\n\nShow the code\n# LaTeX templates\nmodel_results_row_template = \"\"\"    {bold_str}\\\\cellcolor{{{color}}}{var_name}{stars} & {bold_str}\\\\cellcolor{{{color}}}{coef:.2f} & {bold_str}\\\\cellcolor{{{color}}}{p:.2f} & {bold_str}\\\\cellcolor{{{color}}}{ci_low:.2f} & {bold_str}\\\\cellcolor{{{color}}}{ci_high:.2f} \\\\\\\\\"\"\"\n\n# Table header and footer templates\nmodel_results_table_header = \"\"\"\\\\begin{tabular}{l*{6}{r}}\n\\\\toprule\n\\\\textbf{Variable} & \\\\textbf{coef} & \\\\textbf{P&gt;|z|} & \\\\multicolumn{2}{c}{\\\\textbf{[0.025 0.975]}} \\\\\\\\\n\\\\midrule\"\"\"\n\nmodel_results_table_footer = \"\"\"\\\\bottomrule\n\\\\end{tabular}\"\"\"\n\ndef convert_model_results_to_printable_pdf_ready(\n    model: sm.GLM,\n    tbl_cap: str,\n    tbl_label: str,\n) -&gt; tuple[str, pd.DataFrame]:\n    # Get only the dataframe\n    summary_simple_tab = model.summary().tables[1]\n    model_results_df = pd.read_html(StringIO(summary_simple_tab.as_html()), header=0, index_col=0)[0]\n\n    # Add exponentiated coef\n    model_results_df[\"exp(coef)\"] = np.exp(model_results_df[\"coef\"])\n\n    # Keep only the specified columns\n    model_results_df = model_results_df[\n        [\"exp(coef)\", \"coef\", \"z\", \"P&gt;|z|\", \"[0.025\", \"0.975]\"]\n    ]\n\n    # Set index name to \"variable\"\n    model_results_df.index.name = \"variable\"\n    model_results_df = model_results_df.reset_index()\n\n    rows_latex = []\n    for i, result_row in model_results_df.iterrows():\n        # Determine if row should be bold and if stars should be added\n        is_significant = result_row[\"P&gt;|z|\"] &lt; 0.05\n        stars = \"~$^{***}$\" if is_significant else \"\"\n        \n        # Handle bolding - only for significant rows\n        if is_significant:\n            bold_str = \"\\\\bfseries\"\n        else:\n            bold_str = \"\"\n        \n        # Set background color for alternating rows\n        color = \"gray!10\" if i % 2 == 1 else \"white\"\n        \n        # Format the row\n        rows_latex.append(\n            model_results_row_template.format(\n                bold_str=bold_str,\n                var_name=result_row[\"variable\"].replace(\"_\", \" \"),\n                # exp_coef=result_row[\"exp(coef)\"],\n                coef=result_row[\"coef\"],\n                # z=result_row[\"z\"],\n                p=result_row[\"P&gt;|z|\"],\n                ci_low=result_row[\"[0.025\"],\n                ci_high=result_row[\"0.975]\"],\n                stars=stars,\n                color=color\n            )\n        )\n\n    # Combine all parts\n    regression_table_latex = f\"\"\"\\\\begin{{table}}\n\\\\centering\n\\\\caption{{{tbl_cap}}}\n\\\\label{{{tbl_label}}}\n\\\\label{{tbl-reg-results}}\n{model_results_table_header}\n{chr(10).join(rows_latex)}\n{model_results_table_footer}\n\\\\end{{table}}\"\"\"\n\n    return regression_table_latex, model_results_df\n\n\n\nopen access articles\n\nn_author_devs is not significant\ngain 1.1621828452888712 more citations per non-author code contributor\n\nclosed access articles\n\nn_author_devs is not significant\ngain 1.1681251177146603 more citations per non-author code contributor\n\n\n\n\n4.1.1.2 Domain\n\n\nShow the code\narticle_cited_by_count_models[\"domain\"].summary()\n\n\n\n\nTable 4: Article Citations by Code Contributorship of Research Team Controlled by Domain\n\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ncited_by_count\nNo. Observations:\n444\n\n\nModel:\nGLM\nDf Residuals:\n430\n\n\nModel Family:\nNegativeBinomial\nDf Model:\n13\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-1595.4\n\n\nDate:\nTue, 07 Jan 2025\nDeviance:\n503.42\n\n\nTime:\n18:43:34\nPearson chi2:\n879.\n\n\nNo. Iterations:\n12\nPseudo R-squ. (CS):\n0.3562\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n0.7796\n0.461\n1.692\n0.091\n-0.124\n1.683\n\n\nn_authors\n-0.0052\n0.004\n-1.280\n0.201\n-0.013\n0.003\n\n\nn_author_devs\n0.2681\n0.358\n0.749\n0.454\n-0.433\n0.969\n\n\nn_non_author_devs\n-0.0191\n0.196\n-0.097\n0.923\n-0.404\n0.366\n\n\nyears_since_publication\n0.4144\n0.028\n14.964\n0.000\n0.360\n0.469\n\n\ndomain_Life Sciences\n0.7371\n0.583\n1.264\n0.206\n-0.406\n1.880\n\n\ndomain_Physical Sciences\n0.5243\n0.466\n1.126\n0.260\n-0.388\n1.437\n\n\ndomain_Social Sciences\n0.7065\n0.637\n1.109\n0.268\n-0.542\n1.955\n\n\nn_author_devs * domain_Life Sciences\n-0.2454\n0.483\n-0.508\n0.611\n-1.192\n0.701\n\n\nn_author_devs * domain_Physical Sciences\n-0.2344\n0.367\n-0.639\n0.523\n-0.953\n0.485\n\n\nn_author_devs * domain_Social Sciences\n-0.6152\n0.528\n-1.166\n0.244\n-1.649\n0.419\n\n\nn_non_author_devs * domain_Life Sciences\n-0.3776\n0.325\n-1.162\n0.245\n-1.015\n0.259\n\n\nn_non_author_devs * domain_Physical Sciences\n0.2244\n0.203\n1.106\n0.269\n-0.173\n0.622\n\n\nn_non_author_devs * domain_Social Sciences\n-0.6423\n0.374\n-1.719\n0.086\n-1.374\n0.090\n\n\n\n\n\n\n\n\n\nhealth sciences\n\ngain 1.0989992577120393 more citations per author code contributor compared to no author code contributor health science papers\ngain 1.0733665310933769 more citations per non-author code contributor compared to no non-author code contributor health science papers\n\nlife sciences\n\nn_author_devs is not significant\nn_non_author_devs is not significant\n\nphysical sciences\n\nn_author_devs is not significant\ngain 1.0836121025480543 more citations per non-author code contributor compared to no non-author code contributor physical science papers\n\nsocial sciences\n\nn_author_devs is not significant\nn_non_author_devs is not significant\n\n\n\n\n4.1.1.3 Article Type\n\n\nShow the code\narticle_cited_by_count_models[\"article_type\"].summary()\n\n\n\n\nTable 5: Article Citations by Code Contributorship of Research Team Controlled by Article Type\n\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\ncited_by_count\nNo. Observations:\n444\n\n\nModel:\nGLM\nDf Residuals:\n434\n\n\nModel Family:\nNegativeBinomial\nDf Model:\n9\n\n\nLink Function:\nLog\nScale:\n1.0000\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-1584.3\n\n\nDate:\nTue, 07 Jan 2025\nDeviance:\n481.14\n\n\nTime:\n18:43:34\nPearson chi2:\n855.\n\n\nNo. Iterations:\n12\nPseudo R-squ. (CS):\n0.3877\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n0.9171\n0.283\n3.246\n0.001\n0.363\n1.471\n\n\nn_authors\n-0.0056\n0.004\n-1.367\n0.172\n-0.014\n0.002\n\n\nn_author_devs\n-0.3751\n0.216\n-1.735\n0.083\n-0.799\n0.049\n\n\nn_non_author_devs\n0.1192\n0.113\n1.053\n0.292\n-0.103\n0.341\n\n\nyears_since_publication\n0.4420\n0.028\n15.874\n0.000\n0.387\n0.497\n\n\narticle_type_research article\n0.3902\n0.290\n1.346\n0.178\n-0.178\n0.958\n\n\narticle_type_software article\n-1.1850\n0.592\n-2.001\n0.045\n-2.345\n-0.025\n\n\nn_author_devs * article_type_research article\n0.3908\n0.232\n1.687\n0.092\n-0.063\n0.845\n\n\nn_author_devs * article_type_software article\n-0.1074\n0.485\n-0.222\n0.825\n-1.057\n0.842\n\n\nn_non_author_devs * article_type_research article\n0.0828\n0.123\n0.675\n0.500\n-0.158\n0.323\n\n\nn_non_author_devs * article_type_software article\n0\n0\nnan\nnan\n0\n0\n\n\n\n\n\n\n\n\n\npreprint\n\nn_author_devs is not significant\ngain 1.132242296815202 more citations per non-author code contributor compared to no non-author code contributor preprints\n\nresearch article\n\ngain 1.0934086297167769 more citations per author code contributor compared to no author code contributor research articles\ngain 1.0381081810730037 more citations per non-author code contributor compared to no non-author code contributor research articles\n\nsoftware article\n\nn_author_devs is not significant\nn_non_author_devs is not significant\n\n\n\n\n\n4.1.2 Team Composition and Project Duration\n\nWe next investigate the relationship between the duration of a project and the coding contributorship of the research team.\n\n\n\nShow the code\nteam_comp_no_push_after_pub_for_duration = team_comp_no_push_after_pub.copy()\n\n# Calculate ratio\nteam_comp_no_push_after_pub_for_duration[\"non_author_to_author_devs_ratio\"] = (\n    team_comp_no_push_after_pub_for_duration[\"n_non_author_devs\"]\n    / team_comp_no_push_after_pub_for_duration[\"n_author_devs\"]\n)\n\n# Drop inf and nan\nteam_comp_no_push_after_pub_for_duration = (\n    team_comp_no_push_after_pub_for_duration.replace(\n        [float(\"inf\"), -float(\"inf\")], float(\"nan\")\n    ).dropna()\n)\n\n# Remove negative \"repo_commit_duration\" repos\nteam_comp_no_push_after_pub_for_duration = team_comp_no_push_after_pub_for_duration[\n    team_comp_no_push_after_pub_for_duration[\"repo_commit_duration\"] &gt;= 0\n]\n\n# Plot\nsns.lmplot(\n    data=team_comp_no_push_after_pub_for_duration,\n    y=\"non_author_to_author_devs_ratio\",\n    x=\"repo_commit_duration\",\n    scatter_kws={\"alpha\": 0.2},\n    line_kws={\"color\": \"red\"},\n    order=1,\n)\n\n\n\n\n\n\n\n\n\n\n\nShow the code\npearsonr(\n    team_comp_no_push_after_pub_for_duration[\"non_author_to_author_devs_ratio\"],\n    team_comp_no_push_after_pub_for_duration[\"repo_commit_duration\"],\n)\n\n\nPearsonRResult(statistic=-0.04559088784200119, pvalue=0.4170758230020255)"
  },
  {
    "objectID": "qss-code-authors.html#characteristics-of-scientific-code-contributors",
    "href": "qss-code-authors.html#characteristics-of-scientific-code-contributors",
    "title": "Code Contribution and Authorship",
    "section": "4.2 Characteristics of Scientific Code Contributors",
    "text": "4.2 Characteristics of Scientific Code Contributors\n\nNext we investigate the differences between coding and non-coding article authors.\n\nspecifics, author position in authorship list is a commonly used tool in scientometrics\nsimilarly, metrics of “scientific impact” such as h-index, i10 index, and two-year mean citedness are also available to us.\nplot / table of the distributions between coding and non-coding authors\nANOVA / Chi2 tests to see if these differences are significant\nresults in summary\n\nJust as before, we next investigate if these results are affected by article type and research domain.\n\nsubplot + stats tests for differences by each article type\nsubplot + stats tests for differences by each domain\nresults in summary\n\n\n\n4.2.1 Author Positions of Code Contributing Authors\n\n\nShow the code\n# Create subset documents\ndocs_for_per_repo_stats = documents[[\n    \"id\",\n    \"publication_date\",\n    \"is_open_access\",\n]].copy()\n\n# Take sample?\nif USE_SAMPLE:\n    docs_for_per_repo_stats = docs_for_per_repo_stats.sample(frac=0.02, random_state=12)\n\n# Rename id to document_id\ndocs_for_per_repo_stats = docs_for_per_repo_stats.rename(columns={\"id\": \"document_id\"})\n\n# Merge repository id in\ndocs_for_per_repo_stats = docs_for_per_repo_stats.merge(\n    doc_repo_links[\n        [\n            \"document_id\",\n            \"repository_id\",\n        ]\n    ],\n    left_on=\"document_id\",\n    right_on=\"document_id\",\n)\n\n# Merge in document details (domain, document type)\ndocs_for_per_repo_stats = (\n    docs_for_per_repo_stats.merge(\n        document_topics[[\"document_id\", \"topic_id\"]],\n        left_on=\"document_id\",\n        right_on=\"document_id\",\n    )\n    .merge(\n        repositories[[\"id\", \"last_pushed_datetime\"]],\n        left_on=\"repository_id\",\n        right_on=\"id\",\n    )\n    .drop(\n        columns=[\"id\"],\n    )\n    .merge(\n        topics[[\"id\", \"domain_name\"]],\n        left_on=\"topic_id\",\n        right_on=\"id\",\n    )\n    .drop(\n        columns=[\"id\", \"topic_id\"],\n    )\n    .merge(\n        reduced_doc_types,\n        left_on=\"document_id\",\n        right_on=\"document_id\",\n    )\n    .rename(\n        columns={\n            \"domain_name\": \"domain\",\n            \"reduced_doc_type\": \"article_type\",\n        }\n    )\n)\n\n# Drop any documents that have more than one repository (and vice versa)\ndocs_for_per_repo_stats = docs_for_per_repo_stats.drop_duplicates(\n    subset=[\"document_id\"], keep=False\n)\ndocs_for_per_repo_stats = docs_for_per_repo_stats.drop_duplicates(\n    subset=[\"repository_id\"], keep=False\n)\n\n# Convert datetimes to datetimes\ndocs_for_per_repo_stats[\"publication_date\"] = pd.to_datetime(\n    docs_for_per_repo_stats[\"publication_date\"],\n    utc=True,\n)\ndocs_for_per_repo_stats[\"last_pushed_datetime\"] = pd.to_datetime(\n    docs_for_per_repo_stats[\"last_pushed_datetime\"],\n    utc=True,\n)\n\n# Remove any documents that have pushes after 90 days\n# past publication\ndocs_for_per_repo_stats = docs_for_per_repo_stats.loc[\n    (docs_for_per_repo_stats[\"last_pushed_datetime\"] - docs_for_per_repo_stats[\"publication_date\"]).dt.days &lt;= 90\n]\n\n# Drop publication date and last pushed datetime\ndocs_for_per_repo_stats = docs_for_per_repo_stats.drop(\n    columns=[\n        \"publication_date\",\n        \"last_pushed_datetime\",\n    ]\n)\n\n# Get document contributors\ndoc_contribs_for_code_char = document_contributors.loc[\n    document_contributors[\"document_id\"].isin(docs_for_per_repo_stats[\"document_id\"])\n]\n\n# Merge with docs_for_per_repo_stats\ndoc_contribs_for_code_char = doc_contribs_for_code_char.merge(\n    docs_for_per_repo_stats,\n    left_on=\"document_id\",\n    right_on=\"document_id\",\n).drop(columns=[\"id\"])\n\n# Iter over rows and check if the author is a dev on the same article-repo pair\ndoc_contribs_for_code_char_rows = []\nfor i, row in doc_contribs_for_code_char.iterrows():\n    # Get devs\n    this_repo_devs = repository_contributors.loc[\n        repository_contributors[\"repository_id\"] == row[\"repository_id\"]\n    ]\n\n    # Get the set of researcher_dev_links for the authors\n    author_dev_links = researcher_dev_links.loc[\n        researcher_dev_links[\"researcher_id\"] == row.researcher_id\n    ].sort_values(\"predictive_model_confidence\", ascending=False)\n\n    # Drop duplicates by developer_account_id (keeping first)\n    # as we may have accidently matched the same dev to the multiple authors\n    author_dev_links = author_dev_links.drop_duplicates(\n        subset=[\"developer_account_id\"],\n        keep=\"first\",\n    )\n\n    # Drop any author dev links that have less than 90% confidence\n    author_dev_links = author_dev_links.loc[\n        author_dev_links[\"predictive_model_confidence\"] &gt;= 0.9\n    ]\n\n    # If no author dev links return same rows and \"is_code_contributor\" as False\n    if len(author_dev_links) == 0:\n        doc_contribs_for_code_char_rows.append(\n            {\n                **row.to_dict(),\n                \"is_code_contributor\": False,\n            }\n        )\n    \n    else:\n        # Add same rows and add \"is_code_contributor\" based on if developer_account_id is in this_repo_devs\n        doc_contribs_for_code_char_rows.append(\n            {\n                **row.to_dict(),\n                \"is_code_contributor\": any(\n                    author_dev_link[\"developer_account_id\"]\n                    in this_repo_devs[\"developer_account_id\"].unique()\n                    for _, author_dev_link in author_dev_links.iterrows()\n                ),\n            }\n        )\n\n# Create dataframe\ndoc_contribs_for_code_char = pd.DataFrame(doc_contribs_for_code_char_rows)\n\n# Replace binary values in \"is_open_access\" to \"Open Access\" and \"Closed Access\"\ndoc_contribs_for_code_char[\"is_open_access\"] = (\n    doc_contribs_for_code_char.apply(\n        lambda x: \"Open Access\" if x[\"is_open_access\"] == 1 else \"Closed Access\",\n        axis=1,\n    )\n)\n\n# Replace binary values in \"is_corresponding\" to \"Corresponding\" and \"Not Corresponding\"\ndoc_contribs_for_code_char[\"is_corresponding\"] = (\n    doc_contribs_for_code_char.apply(\n        lambda x: \"Corresponding\" if x[\"is_corresponding\"] == 1 else \"Not Corresponding\",\n        axis=1,\n    )\n)\n\n\n\n\nShow the code\ndef _run_posthocs(\n    data: pd.DataFrame,\n    split_var: str,\n) -&gt; None:            \n    # Conduct pairwise posthocs\n    binom_results = []\n    for split_val in data[split_var].unique():\n        split_val_subset = data.loc[\n            data[split_var] == split_val\n        ]\n\n        # Run test\n        results = binomtest(\n            sum(split_val_subset[\"is_code_contributor\"]),\n            len(split_val_subset),\n            0.5,\n        )\n        \n        # Conduct binomial test\n        binom_results.append(\n            {\n                split_var: split_val,\n                \"p\": results.pvalue,\n                \"statistic\": results.statistic,\n                \"n\": len(split_val_subset),\n                \"n_code_contributors\": sum(split_val_subset[\"is_code_contributor\"]),\n            }\n        )\n\n        # P adjust\n        p_values = false_discovery_control(\n            [result[\"p\"] for result in binom_results],\n            method=\"bh\",\n        )\n\n        # Replace p values\n        for i, result in enumerate(binom_results):\n            result[\"p\"] = p_values[i]\n        \n    # Print results\n    for result in binom_results:\n        print(\n            f\"{split_var}: {result[split_var]}, \"\n            f\"p: {result['p']}, statistic: {result['statistic']}, n: {result['n']}\"\n        )\n\n\ndef _run_chi2_and_posthocs(\n    data: pd.DataFrame,\n    control_var: str | None,\n    split_var: str,\n) -&gt; None:\n    if control_var is None:\n        print(\"Overall\")\n        xtabs = pd.crosstab(\n            data[split_var],\n            data[\"is_code_contributor\"],\n        )\n        print(xtabs)\n        chi2, p, _, _ = chi2_contingency(xtabs)\n        if p &lt; 0.05:\n            print(f\"Chi2: {chi2}, p: {p}, n: {len(data)}\")\n            _run_posthocs(\n                data,\n                split_var=split_var,\n            )\n\n        else:\n            print(f\"Coding by {split_var} not significant\")\n\n    else:\n        for control_val in data[control_var].unique():\n            print(control_val)\n            # Get data with control_val subset\n            control_val_subset = data.loc[\n                data[control_var] == control_val\n            ]\n            xtabs = pd.crosstab(\n                control_val_subset[split_var],\n                control_val_subset[\"is_code_contributor\"],\n            )\n            print(xtabs)\n            chi2, p, _, _ = chi2_contingency(xtabs)\n            if p &lt; 0.05:\n                print(f\"Chi2: {chi2}, p: {p}, n: {len(control_val_subset)}\")\n                _run_posthocs(\n                    control_val_subset,\n                    split_var=split_var,\n                )\n\n            else:\n                print(f\"Coding by {split_var} not significant\")\n\n        print()\n        print()\n\n\n\n\nShow the code\n# Run chi2 and posthocs for overall author position\n_run_chi2_and_posthocs(\n    doc_contribs_for_code_char,\n    control_var=None,\n    split_var=\"position\",\n)\n\n\nOverall\nis_code_contributor  False  True \nposition                         \nfirst                  344    692\nlast                   897     98\nmiddle                2489    249\nChi2: 1573.7007703450245, p: 0.0, n: 4769\nposition: first, p: 1.3595284036907975e-27, statistic: 0.667953667953668, n: 1036\nposition: middle, p: 0.0, statistic: 0.09094229364499634, n: 2738\nposition: last, p: 4.664618018331252e-162, statistic: 0.09849246231155778, n: 995\n\n\n\n4.2.1.1 Domain\n\n\nShow the code\n_run_chi2_and_posthocs(\n    doc_contribs_for_code_char,\n    control_var=\"domain\",\n    split_var=\"position\",\n)\n\n\nPhysical Sciences\nis_code_contributor  False  True \nposition                         \nfirst                  267    547\nlast                   710     73\nmiddle                1842    196\nChi2: 1206.5828720684517, p: 9.859578539300722e-263, n: 3635\nposition: first, p: 5.18883630471438e-23, statistic: 0.671990171990172, n: 814\nposition: middle, p: 0.0, statistic: 0.09617271835132483, n: 2038\nposition: last, p: 8.073489906806108e-132, statistic: 0.09323116219667944, n: 783\nSocial Sciences\nis_code_contributor  False  True \nposition                         \nfirst                   24     71\nlast                    83      6\nmiddle                 206     22\nChi2: 174.2064389083228, p: 1.48440509062201e-38, n: 412\nposition: first, p: 1.4640982465812788e-06, statistic: 0.7473684210526316, n: 95\nposition: middle, p: 7.279596608707229e-38, statistic: 0.09649122807017543, n: 228\nposition: last, p: 3.0300683691960934e-18, statistic: 0.06741573033707865, n: 89\nLife Sciences\nis_code_contributor  False  True \nposition                         \nfirst                   33     47\nlast                    67     10\nmiddle                 191     19\nChi2: 90.69296421064769, p: 2.0242914833256164e-20, n: 367\nposition: first, p: 0.1456354544029827, statistic: 0.5875, n: 80\nposition: middle, p: 3.8054427733088936e-36, statistic: 0.09047619047619047, n: 210\nposition: last, p: 2.5451112492298424e-11, statistic: 0.12987012987012986, n: 77\nHealth Sciences\nis_code_contributor  False  True \nposition                         \nfirst                   20     27\nlast                    37      9\nmiddle                 250     12\nChi2: 96.9046842630867, p: 9.065988774549225e-22, n: 355\nposition: first, p: 0.38169339766321275, statistic: 0.574468085106383, n: 47\nposition: last, p: 0.00012168108398213917, statistic: 0.1956521739130435, n: 46\nposition: middle, p: 1.437849113319602e-58, statistic: 0.04580152671755725, n: 262\n\n\n\n\n\n\n4.2.1.2 Article Type\n\n\nShow the code\n_run_chi2_and_posthocs(\n    doc_contribs_for_code_char,\n    control_var=\"article_type\",\n    split_var=\"position\",\n)\n\n\nresearch article\nis_code_contributor  False  True \nposition                         \nfirst                  211    418\nlast                   552     60\nmiddle                1487    146\nChi2: 948.5560326647192, p: 1.0560260192415677e-206, n: 2874\nposition: first, p: 1.141630468905074e-16, statistic: 0.6645468998410174, n: 629\nposition: middle, p: 4.627473147140983e-279, statistic: 0.08940600122473974, n: 1633\nposition: last, p: 1.9168122526132562e-100, statistic: 0.09803921568627451, n: 612\npreprint\nis_code_contributor  False  True \nposition                         \nfirst                  129    259\nlast                   332     37\nmiddle                 982     93\nChi2: 610.1420076137606, p: 3.231070677235308e-133, n: 1832\nposition: first, p: 3.832984890110952e-11, statistic: 0.6675257731958762, n: 388\nposition: middle, p: 3.9144650058522523e-187, statistic: 0.08651162790697674, n: 1075\nposition: last, p: 3.0073911290981897e-60, statistic: 0.1002710027100271, n: 369\nsoftware article\nis_code_contributor  False  True \nposition                         \nfirst                    4     15\nlast                    13      1\nmiddle                  20     10\nChi2: 18.634943648101547, p: 8.984075676892809e-05, n: 63\nposition: first, p: 0.0576324462890625, statistic: 0.7894736842105263, n: 19\nposition: middle, p: 0.09873714670538905, statistic: 0.3333333333333333, n: 30\nposition: last, p: 0.0054931640625, statistic: 0.07142857142857142, n: 14\n\n\n\n\n\n\n4.2.1.3 Open Access Status\n\n\nShow the code\n_run_chi2_and_posthocs(\n    doc_contribs_for_code_char,\n    control_var=\"is_open_access\",\n    split_var=\"position\",\n)\n\n\nOpen Access\nis_code_contributor  False  True \nposition                         \nfirst                  321    636\nlast                   830     88\nmiddle                2291    233\nChi2: 1435.8973993251022, p: 0.0, n: 4399\nposition: first, p: 1.2585382845090118e-24, statistic: 0.664576802507837, n: 957\nposition: middle, p: 0.0, statistic: 0.09231378763866878, n: 2524\nposition: last, p: 5.895849124885255e-152, statistic: 0.09586056644880174, n: 918\nClosed Access\nis_code_contributor  False  True \nposition                         \nfirst                   23     56\nlast                    67     10\nmiddle                 198     16\nChi2: 139.23147690860233, p: 5.83806512957191e-31, n: 370\nposition: first, p: 0.000263636776465269, statistic: 0.7088607594936709, n: 79\nposition: middle, p: 2.578180225515499e-40, statistic: 0.07476635514018691, n: 214\nposition: last, p: 2.5451112492298424e-11, statistic: 0.12987012987012986, n: 77\n\n\n\n\n\n\n\n4.2.2 Corresponding Status of Code Contributing Authors\n\n\nShow the code\n# Run chi2 and posthocs for overall corresponding status\n_run_chi2_and_posthocs(\n    doc_contribs_for_code_char,\n    control_var=None,\n    split_var=\"is_corresponding\",\n)\n\n\nOverall\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding          308    149\nNot Corresponding     3422    890\nChi2: 34.01034754514929, p: 5.48197611232872e-09, n: 4769\nis_corresponding: Corresponding, p: 8.234394918300371e-14, statistic: 0.32603938730853393, n: 457\nis_corresponding: Not Corresponding, p: 0.0, statistic: 0.20640074211502782, n: 4312\n\n\n\n4.2.2.1 Domain\n\n\nShow the code\n_run_chi2_and_posthocs(\n    doc_contribs_for_code_char,\n    control_var=\"domain\",\n    split_var=\"is_corresponding\",\n)\n\n\nPhysical Sciences\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding          119     95\nNot Corresponding     2700    721\nChi2: 61.563992239064525, p: 4.285851268982526e-15, n: 3635\nis_corresponding: Corresponding, p: 0.11568423859513763, statistic: 0.4439252336448598, n: 214\nis_corresponding: Not Corresponding, p: 1.662130205982161e-266, statistic: 0.2107570885705934, n: 3421\nSocial Sciences\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding           15     13\nNot Corresponding      298     86\nChi2: 6.992816447988175, p: 0.008183747997774883, n: 412\nis_corresponding: Not Corresponding, p: 3.4749206085129074e-28, statistic: 0.22395833333333334, n: 384\nis_corresponding: Corresponding, p: 0.8505540192127228, statistic: 0.4642857142857143, n: 28\nLife Sciences\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding          129     32\nNot Corresponding      162     44\nCoding by is_corresponding not significant\nHealth Sciences\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding           45      9\nNot Corresponding      262     39\nCoding by is_corresponding not significant\n\n\n\n\n\n\n4.2.2.2 Article Type\n\n\nShow the code\n_run_chi2_and_posthocs(\n    doc_contribs_for_code_char,\n    control_var=\"article_type\",\n    split_var=\"is_corresponding\",\n)\n\n\nresearch article\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding          299    129\nNot Corresponding     1951    495\nChi2: 20.437869830135387, p: 6.159873685691146e-06, n: 2874\nis_corresponding: Corresponding, p: 1.2332229324952902e-16, statistic: 0.3014018691588785, n: 428\nis_corresponding: Not Corresponding, p: 5.691041647750157e-203, statistic: 0.20237121831561733, n: 2446\npreprint\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding            8     13\nNot Corresponding     1435    376\nChi2: 18.622425729828503, p: 1.5933517219738882e-05, n: 1832\nis_corresponding: Not Corresponding, p: 4.670437820233032e-145, statistic: 0.20762009939260076, n: 1811\nis_corresponding: Corresponding, p: 0.38331031799316406, statistic: 0.6190476190476191, n: 21\nsoftware article\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding            1      7\nNot Corresponding       36     19\nChi2: 6.043143427518427, p: 0.013960405516720398, n: 63\nis_corresponding: Not Corresponding, p: 0.06005789082378497, statistic: 0.34545454545454546, n: 55\nis_corresponding: Corresponding, p: 0.0703125, statistic: 0.875, n: 8\n\n\n\n\n\n\n4.2.2.3 Open Access Status\n\n\nShow the code\n_run_chi2_and_posthocs(\n    doc_contribs_for_code_char,\n    control_var=\"is_open_access\",\n    split_var=\"is_corresponding\",\n)\n\n\nOpen Access\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding          305    146\nNot Corresponding     3137    811\nChi2: 32.58898647084339, p: 1.1385811922148022e-08, n: 4399\nis_corresponding: Corresponding, p: 5.5545343605113554e-14, statistic: 0.3237250554323725, n: 451\nis_corresponding: Not Corresponding, p: 1.50216e-319, statistic: 0.20542046605876393, n: 3948\nClosed Access\nis_code_contributor  False  True \nis_corresponding                 \nCorresponding            3      3\nNot Corresponding      285     79\nCoding by is_corresponding not significant\n\n\n\n\n\n\n\n4.2.3 Modeling H-Index\n\nWe model an authors total citations by their coding status and controlled by a number of different factors.\nEach control variable is modeled separately and the results are presented in the tables below:\n\nControlling for an authors most frequent author position: Table 7\nControlling for an authors most frequent domain: Table 8\nControlling for an authors most frequent article type: Table 9\n\n\n\n\nShow the code\n# First, get the set of researchers who have at least 3 documents\nresearchers_w_3_docs = researchers.loc[\n    researchers[\"id\"].isin(\n        document_contributors[\"researcher_id\"]\n        .value_counts()\n        .loc[lambda x: x &gt;= 3]\n        .index\n    )\n]\n\n# Use sample?\nif USE_SAMPLE:\n    researchers_w_3_docs = researchers_w_3_docs.sample(frac=0.02, random_state=12)\n\n# Next, for each researcher, get the set of documents they have contributed to\nresearchers_w_3_docs = document_contributors.loc[\n    document_contributors[\"researcher_id\"].isin(researchers_w_3_docs[\"id\"])\n].merge(\n    researchers_w_3_docs,\n    left_on=\"researcher_id\",\n    right_on=\"id\",\n)\n\n# Attach document for publication date\nresearchers_w_3_docs = researchers_w_3_docs.merge(\n    documents[[\"id\", \"publication_date\"]],\n    left_on=\"document_id\",\n    right_on=\"id\",\n).drop(\n    columns=[\"id\"],\n)\n\n# Keep only certain columns\nresearchers_w_3_docs = researchers_w_3_docs[\n    [\n        \"researcher_id\",\n        \"document_id\",\n        \"publication_date\",\n        \"position\",\n        \"is_corresponding\",\n        \"works_count\",\n        \"cited_by_count\",\n        \"h_index\",\n        \"i10_index\",\n        \"two_year_mean_citedness\",\n    ]\n]\n\n# Next, for each researcher_doc, attach the document details (domain, reduced_doc_type)\nresearchers_w_3_docs = (\n    researchers_w_3_docs.merge(\n        document_topics[[\"document_id\", \"topic_id\"]],\n        left_on=\"document_id\",\n        right_on=\"document_id\",\n    )\n    .merge(\n        topics[[\"id\", \"domain_name\"]],\n        left_on=\"topic_id\",\n        right_on=\"id\",\n    )\n    .drop(\n        columns=[\"id\", \"topic_id\"],\n    )\n    .merge(\n        reduced_doc_types,\n        left_on=\"document_id\",\n        right_on=\"document_id\",\n    )\n)\n\n# Now for each of these, we want to see if they have coded on the document\nresearchers_coded = []\nfor _, row in researchers_w_3_docs.iterrows():\n    # Check for dev account\n    dev_links = researcher_dev_links.loc[\n        researcher_dev_links[\"researcher_id\"] == row[\"researcher_id\"]\n    ]\n    if len(dev_links) == 0:\n        researchers_coded.append(\n            {\n                \"researcher_id\": row[\"researcher_id\"],\n                \"document_id\": row[\"document_id\"],\n                \"coded_on_article\": 0,\n            }\n        )\n        continue\n\n    # Skip this person if they have more than 3 links\n    # Likely something went wrong\n    if len(dev_links) &gt; 3:\n        continue\n\n    # Get repos associated with document\n    repo_links_for_doc = doc_repo_links.loc[\n        doc_repo_links[\"document_id\"] == row[\"document_id\"]\n    ]\n\n    # Skip if there is more than 1 repo associated with the document\n    # We just don't know how to handle these cases right now\n    if len(repo_links_for_doc) &gt; 1:\n        continue\n\n    # Also skip if 0\n    if len(repo_links_for_doc) == 0:\n        continue\n\n    # Get the repo_id for the single repo\n    repo_id = repo_links_for_doc[\"repository_id\"].iloc[0]\n\n    # Get the repo_contributors for this repository\n    repo_contributors = repository_contributors.loc[\n        repository_contributors[\"repository_id\"] == repo_id\n    ]\n\n    # Check if any of the dev accounts are in the repo contribs\n    researcher_coded = (\n        len(\n            set(repo_contributors[\"developer_account_id\"].unique()).intersection(\n                set(dev_links[\"developer_account_id\"].unique()),\n            )\n        )\n        &gt; 0\n    )\n\n    # Finally assert any of the repo_contributors are the dev account\n    # associated with the researcher\n    researchers_coded.append(\n        {\n            \"researcher_id\": row[\"researcher_id\"],\n            \"document_id\": row[\"document_id\"],\n            \"coded_on_article\": int(researcher_coded),\n        }\n    )\n\n# Create dataframe\nresearchers_coded_df = pd.DataFrame(researchers_coded)\n\n# Merge with researchers_w_3_docs\nresearchers_w_3_docs_and_coded = researchers_coded_df.merge(\n    researchers_w_3_docs,\n    left_on=[\"researcher_id\", \"document_id\"],\n    right_on=[\"researcher_id\", \"document_id\"],\n)\n\ndef _mode_or_recent_reduce(group: pd.DataFrame, col: str) -&gt; str:\n    # Get the mode\n    mode = group[col].mode().tolist()\n    if len(mode) == 1:\n        return mode[0]\n\n    # Otherwise, iter over most recent publications until value in mode is found\n    group_ordered_by_date = group.sort_values(\"publication_date\", ascending=False)\n    for _, row in group_ordered_by_date.iterrows():\n        if row[col] in mode:\n            return row[col]\n\n\ndef _agg_apply(group: pd.DataFrame) -&gt; dict:\n    return {\n        \"n_documents\": group[\"document_id\"].nunique(),\n        \"n_coded\": group[\"coded_on_article\"].sum(),\n        \"works_count\": group[\"works_count\"].iloc[0],\n        \"cited_by_count\": group[\"cited_by_count\"].iloc[0],\n        \"h_index\": group[\"h_index\"].iloc[0],\n        \"i10_index\": group[\"i10_index\"].iloc[0],\n        \"two_year_mean_citedness\": group[\"two_year_mean_citedness\"].iloc[0],\n        \"position\": _mode_or_recent_reduce(group, \"position\"),\n        \"domain_name\": _mode_or_recent_reduce(group, \"domain_name\"),\n        \"reduced_doc_type\": _mode_or_recent_reduce(group, \"reduced_doc_type\"),\n    }\n\n\nresearchers_w_3_docs_and_coded_agg = (\n    researchers_w_3_docs_and_coded.groupby(\"researcher_id\")[\n        [col for col in researchers_w_3_docs_and_coded if col != \"researcher_id\"]\n    ]\n    .apply(_agg_apply)\n    .reset_index(name=\"dicts\")\n)\nresearchers_w_3_docs_and_coded_agg = researchers_w_3_docs_and_coded_agg.join(\n    pd.json_normalize(researchers_w_3_docs_and_coded_agg[\"dicts\"])\n).drop(columns=[\"dicts\"])\n\n# Create three features for coding status\n# \"any\" coding status\n# \"majority\" coding status\n# \"always\" coding status\n# determine type by taking the percentage of documents coded on\n# and determining if it is greater than 0, greater than 0.5, or 1\nresearchers_w_3_docs_and_coded_agg[\"coding_pct\"] = (\n    researchers_w_3_docs_and_coded_agg[\"n_coded\"]\n    / researchers_w_3_docs_and_coded_agg[\"n_documents\"]\n)\n\nresearchers_w_3_docs_and_coded_agg[\"any_coding\"] = (\n    (researchers_w_3_docs_and_coded_agg[\"coding_pct\"] &gt; 0)\n    & (researchers_w_3_docs_and_coded_agg[\"coding_pct\"] &lt;= 0.5)\n).astype(int)\nresearchers_w_3_docs_and_coded_agg[\"majority_coding\"] = (\n    (researchers_w_3_docs_and_coded_agg[\"coding_pct\"] &gt; 0.5)\n    & (researchers_w_3_docs_and_coded_agg[\"coding_pct\"] &lt; 1)\n).astype(int)\nresearchers_w_3_docs_and_coded_agg[\"always_coding\"] = (\n    researchers_w_3_docs_and_coded_agg[\"coding_pct\"] == 1\n).astype(int)\n\n# Drop n_documents, n_coded and\n# rename \"position\" to \"common_author_position\",\n# \"domain_name\" to \"common_domain\",\n# and \"reduced_doc_type\" to \"common_article_type\"\nresearchers_w_3_docs_and_coded_agg = researchers_w_3_docs_and_coded_agg.drop(\n    columns=[\"n_documents\", \"n_coded\"]\n)\nresearchers_w_3_docs_and_coded_agg = researchers_w_3_docs_and_coded_agg.rename(\n    columns={\n        \"position\": \"common_author_position\",\n        \"domain_name\": \"common_domain\",\n        \"reduced_doc_type\": \"common_article_type\",\n    }\n)\n\n# Get dummies for categorical variables\nresearchers_w_3_docs_and_coded_agg_dummies = pd.get_dummies(\n    researchers_w_3_docs_and_coded_agg,\n    columns=[\"common_author_position\", \"common_domain\", \"common_article_type\"],\n    drop_first=True,\n)\n\n# Cast all to float\nresearchers_w_3_docs_and_coded_agg_dummies = (\n    researchers_w_3_docs_and_coded_agg_dummies.astype(float)\n)\n\n\n\n\nShow the code\ndef compute_researcher_level_models(\n    y_col: str,\n    data: pd.DataFrame,\n    glm_family: sm.families.Family,\n) -&gt; dict[str, sm.GLM]:\n    # Remove all \"zero\" y_col authors\n    no_outliers = data[data[y_col] &gt; 0].copy()\n\n    # Remove outliers\n    no_outliers = no_outliers[\n        no_outliers[y_col].between(\n            no_outliers[y_col].quantile(0.03),\n            no_outliers[y_col].quantile(0.97),\n        )\n    ].copy()\n\n    # Common features to use in all models\n    required_features = [\n        y_col,\n        \"works_count\",\n        \"any_coding\",\n        \"majority_coding\",\n        \"always_coding\",\n    ]\n\n    # Iter over different control variables and create models for each\n    models = {}\n    for control_var in [\n        \"common_author_position\",\n        \"common_article_type\",\n        \"common_domain\",\n    ]:\n        # Get control variable list\n        control_variables = [\n            col for col in no_outliers.columns if col.startswith(control_var)\n        ]\n\n        # Create control variable subset of the data\n        control_var_subset = no_outliers[required_features + control_variables].copy()\n\n        # Create interactions\n        for coding_status_col in [\"any_coding\", \"majority_coding\", \"always_coding\"]:\n            for control_col in control_variables:\n                control_var_subset[f\"{coding_status_col} * {control_col}\"] = (\n                    control_var_subset[coding_status_col]\n                    * control_var_subset[control_col]\n                )\n\n        # Drop inf and nan\n        control_var_subset = control_var_subset.replace(\n            [float(\"inf\"), -float(\"inf\")], float(\"nan\")\n        ).dropna()\n\n        # Create x and y\n        y = control_var_subset[y_col]\n        x = control_var_subset.drop(columns=[y_col])\n        x = sm.add_constant(x)\n\n        # Fit model\n        model = sm.GLM(y, x, family=glm_family).fit()\n        models[control_var] = model\n\n    return models\n\n\n\n\n\n\nTable 6: Counts of Researcher Coding Status Used in H5\n\n\n\n\n\n\nControl\nSubset\nAny Coding\nMajority Coding\nAlways Coding\nTotal\n\n\nFreq. Author Pos.\nfirst\n35\n85\n73\n218\n\n\nlast\n50\n13\n5\n215\n\n\nmiddle\n259\n75\n7\n643\n\n\nFreq. Domain\nHealth Sciences\n5\n2\n1\n24\n\n\nLife Sciences\n12\n3\n3\n29\n\n\nPhysical Sciences\n323\n163\n79\n1000\n\n\nSocial Sciences\n4\n5\n2\n23\n\n\nFreq. Article Type\npreprint\n219\n103\n38\n605\n\n\nresearch article\n124\n70\n45\n466\n\n\nsoftware article\n1\n0\n2\n5\n\n\n\n\n\n\n\n\n\n\nShow the code\n# Create models for h_index\nauthor_h_index_models = compute_researcher_level_models(\n    \"h_index\",\n    researchers_w_3_docs_and_coded_agg_dummies,\n    glm_family=sm.families.Gaussian(sm.families.links.Log()),\n)\n\n\n\n4.2.3.1 Author Position\n\n\nShow the code\nauthor_h_index_models[\"common_author_position\"].summary()\n\n\n\n\nTable 7: Researcher H-Index by Coding Status Controlled by Most Freq. Author Position\n\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nh_index\nNo. Observations:\n980\n\n\nModel:\nGLM\nDf Residuals:\n967\n\n\nModel Family:\nGaussian\nDf Model:\n12\n\n\nLink Function:\nLog\nScale:\n110.78\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3690.8\n\n\nDate:\nTue, 07 Jan 2025\nDeviance:\n1.0712e+05\n\n\nTime:\n18:43:46\nPearson chi2:\n1.07e+05\n\n\nNo. Iterations:\n14\nPseudo R-squ. (CS):\n0.6686\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.1606\n0.250\n8.625\n0.000\n1.670\n2.652\n\n\nworks_count\n0.0015\n4.97e-05\n30.482\n0.000\n0.001\n0.002\n\n\nany_coding\n0.3943\n0.279\n1.415\n0.157\n-0.152\n0.940\n\n\nmajority_coding\n0.0767\n0.275\n0.279\n0.780\n-0.462\n0.616\n\n\nalways_coding\n0.0463\n0.282\n0.164\n0.870\n-0.507\n0.600\n\n\ncommon_author_position_last\n0.8734\n0.253\n3.457\n0.001\n0.378\n1.369\n\n\ncommon_author_position_middle\n0.7000\n0.252\n2.773\n0.006\n0.205\n1.195\n\n\nany_coding * common_author_position_last\n-0.3409\n0.285\n-1.198\n0.231\n-0.899\n0.217\n\n\nany_coding * common_author_position_middle\n-0.5305\n0.283\n-1.875\n0.061\n-1.085\n0.024\n\n\nmajority_coding * common_author_position_last\n-0.3229\n0.308\n-1.049\n0.294\n-0.926\n0.280\n\n\nmajority_coding * common_author_position_middle\n-0.5689\n0.296\n-1.925\n0.054\n-1.148\n0.010\n\n\nalways_coding * common_author_position_last\n-1.3193\n0.912\n-1.447\n0.148\n-3.107\n0.468\n\n\nalways_coding * common_author_position_middle\n-0.7379\n0.536\n-1.377\n0.169\n-1.788\n0.312\n\n\n\n\n\n\n\n\n\nfirst authors\n\nany coding has a positive association with citations (1.2636444922077779)\nmajority coding has a negative association with citations (0.8860339595928756)\nalways coding has a negative association with citations (0.764143255648199)\n\nmiddle authors\n\nany coding has a negative association with citations (0.7482635675785653)\nmajority coding has a negative association with citations (0.9039330328858641)\nalways coding is not significant\n\nlast authors\n\nany coding has a negative association with citations (0.8737159116880344)\nmajority coding is not significant\nalways coding is not significant\n\n\nIn general, any coding has a positive association while majority and always coding have negative associations with citations. “The more you code the less you are cited” – granted that we don’t have a lot of data for always coding authors (which itself backs up qual lit).\nin general, coding is associated with about a ~10 - 30% decrease in citations for a number of conditions when compared to non-coding first authors.\n\n\n4.2.3.2 Domain\n\n\nShow the code\nauthor_h_index_models[\"common_domain\"].summary()\n\n\n\n\nTable 8: Researcher H-Index by Coding Status Controlled by Most Freq. Domain\n\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nh_index\nNo. Observations:\n980\n\n\nModel:\nGLM\nDf Residuals:\n963\n\n\nModel Family:\nGaussian\nDf Model:\n16\n\n\nLink Function:\nLog\nScale:\n117.99\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3719.7\n\n\nDate:\nTue, 07 Jan 2025\nDeviance:\n1.1363e+05\n\n\nTime:\n18:43:46\nPearson chi2:\n1.14e+05\n\n\nNo. Iterations:\n15\nPseudo R-squ. (CS):\n0.6250\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n3.1594\n0.084\n37.529\n0.000\n2.994\n3.324\n\n\nworks_count\n0.0015\n4.94e-05\n31.319\n0.000\n0.001\n0.002\n\n\nany_coding\n-0.4703\n0.333\n-1.411\n0.158\n-1.124\n0.183\n\n\nmajority_coding\n-0.1995\n0.351\n-0.568\n0.570\n-0.887\n0.488\n\n\nalways_coding\n-1.5670\n2.174\n-0.721\n0.471\n-5.828\n2.694\n\n\ncommon_domain_Life Sciences\n-0.1778\n0.173\n-1.027\n0.305\n-0.517\n0.162\n\n\ncommon_domain_Physical Sciences\n-0.2774\n0.085\n-3.281\n0.001\n-0.443\n-0.112\n\n\ncommon_domain_Social Sciences\n-0.2139\n0.148\n-1.441\n0.150\n-0.505\n0.077\n\n\nany_coding * common_domain_Life Sciences\n0.6767\n0.382\n1.770\n0.077\n-0.073\n1.426\n\n\nany_coding * common_domain_Physical Sciences\n0.3547\n0.335\n1.058\n0.290\n-0.302\n1.012\n\n\nany_coding * common_domain_Social Sciences\n0.5676\n0.412\n1.378\n0.168\n-0.240\n1.375\n\n\nmajority_coding * common_domain_Life Sciences\n-0.4009\n0.662\n-0.606\n0.545\n-1.698\n0.896\n\n\nmajority_coding * common_domain_Physical Sciences\n-0.3273\n0.359\n-0.912\n0.362\n-1.031\n0.376\n\n\nmajority_coding * common_domain_Social Sciences\n-0.3976\n0.532\n-0.747\n0.455\n-1.441\n0.646\n\n\nalways_coding * common_domain_Life Sciences\n0.0247\n2.618\n0.009\n0.992\n-5.106\n5.156\n\n\nalways_coding * common_domain_Physical Sciences\n0.8993\n2.178\n0.413\n0.680\n-3.370\n5.168\n\n\nalways_coding * common_domain_Social Sciences\n0.6767\n2.358\n0.287\n0.774\n-3.944\n5.297\n\n\n\n\n\n\n\n\n\nhealth sciences\n\nany coding is not significant\nmajority coding has a negative association with citations (0.7527666447061963)\nalways coding has a negative association with citations (0.6120140740013499)\n\nlife sciences\n\nany coding is not significant\nmajority coding is not significant\nalways coding has a positive association with citations (1.5983949987546404)\n\nphysical sciences\n\nany coding is not significant\nmajority coding is not significant\nalways coding is not significant\n\nsocial sciences\n\nany coding has a negative associate with citations (0.8033217181536265)\nmajority coding is not significant\nalways coding has a positive association with citations (1.587245303225596)\n\n\nWe couldn’t significant results for a majority of the groupings so I don’t think that we can say anything too strongly, however, health sciences doesn’t seem to favor coding (which I think is inline most with “RSE” dynamics). Social sciences is split, and social science is broad so this may be a “qual” vs “quant” split, if you include mixed methods researchers in there its hard to parse.\nPhysical sciences being entirely non-significant is interesting because a majority of our data comes from Physical sciences. this could indicate that coding is just a part of the culture and doesn’t have a significant impact on citations (which is inline with CS being the bulk of our physical sciences data).\n\n\n4.2.3.3 Article Type\n\n\nShow the code\nauthor_h_index_models[\"common_article_type\"].summary()\n\n\n\n\nTable 9: Researcher H-Index by Coding Status Controlled by Most Freq. Article Type\n\n\n\n\nGeneralized Linear Model Regression Results\n\n\nDep. Variable:\nh_index\nNo. Observations:\n980\n\n\nModel:\nGLM\nDf Residuals:\n968\n\n\nModel Family:\nGaussian\nDf Model:\n11\n\n\nLink Function:\nLog\nScale:\n118.31\n\n\nMethod:\nIRLS\nLog-Likelihood:\n-3723.5\n\n\nDate:\nTue, 07 Jan 2025\nDeviance:\n1.1452e+05\n\n\nTime:\n18:43:46\nPearson chi2:\n1.15e+05\n\n\nNo. Iterations:\n15\nPseudo R-squ. (CS):\n0.6211\n\n\nCovariance Type:\nnonrobust\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP&gt;|z|\n[0.025\n0.975]\n\n\nconst\n2.8933\n0.032\n89.108\n0.000\n2.830\n2.957\n\n\nworks_count\n0.0015\n5e-05\n30.719\n0.000\n0.001\n0.002\n\n\nany_coding\n-0.1805\n0.052\n-3.470\n0.001\n-0.282\n-0.079\n\n\nmajority_coding\n-0.5650\n0.099\n-5.689\n0.000\n-0.760\n-0.370\n\n\nalways_coding\n-0.7088\n0.202\n-3.512\n0.000\n-1.104\n-0.313\n\n\ncommon_article_type_research article\n0.0148\n0.040\n0.372\n0.710\n-0.063\n0.093\n\n\ncommon_article_type_software article\n-0.0987\n0.545\n-0.181\n0.856\n-1.166\n0.969\n\n\nany_coding * common_article_type_research article\n0.1529\n0.073\n2.098\n0.036\n0.010\n0.296\n\n\nany_coding * common_article_type_software article\n0.9878\n0.588\n1.680\n0.093\n-0.165\n2.140\n\n\nmajority_coding * common_article_type_research article\n0.0766\n0.146\n0.523\n0.601\n-0.210\n0.363\n\n\nmajority_coding * common_article_type_software article\n1.726e-16\n6.76e-16\n0.256\n0.798\n-1.15e-15\n1.5e-15\n\n\nalways_coding * common_article_type_research article\n-0.0031\n0.264\n-0.012\n0.991\n-0.521\n0.515\n\n\nalways_coding * common_article_type_software article\n-0.5010\n2.251\n-0.223\n0.824\n-4.914\n3.912\n\n\n\n\n\n\n\n\n\npreprint\n\nany coding is not significant\nmajority coding has a negative association with citations (0.6736800392488677)\nalways coding has a negative association with citations (0.6306526773980542)\n\nresearch article\n\nany coding is not significant\nmajority coding has a positive association with citations (1.0565406146754943)\nalways coding has a positive association with citations (1.0843708965667604)\n\nsoftware article\n\nany coding has a positive association with citations (1.7471746543074462)\nmajority coding is not significant\nalways coding has a positive association with citations (1.4681454416819895)\n\n\nPreprints (from arXiv) have a negative association with coding generally. Research articles have a very slim positive association with coding. Software articles have a strongly positive association with coding (unsuprising)."
  },
  {
    "objectID": "qss-code-authors.html#full-comparison-of-models-and-optional-features-for-author-developer-account-matching",
    "href": "qss-code-authors.html#full-comparison-of-models-and-optional-features-for-author-developer-account-matching",
    "title": "Code Contribution and Authorship",
    "section": "5.1 Full Comparison of Models and Optional Features for Author-Developer-Account Matching",
    "text": "5.1 Full Comparison of Models and Optional Features for Author-Developer-Account Matching\n\n\nShow the code\nexp_results\n\n\n\n\nTable 10: Comparison of Models for Author-Developer-Account Matching\n\n\n\n\n\n\n\n\n\n\nOptional Feats.\nModel\nAccuracy\nPrecision\nRecall\nF1\n\n\n\n\n0\nname\ndeberta\n0.984\n0.938\n0.950\n0.944\n\n\n1\nname, email\nbert-multilingual\n0.984\n0.938\n0.950\n0.944\n\n\n2\nname, email\ndeberta\n0.982\n0.907\n0.975\n0.940\n\n\n3\nname\nbert-multilingual\n0.982\n0.938\n0.938\n0.938\n\n\n4\nname\ndistilbert\n0.978\n0.936\n0.912\n0.924\n\n\n5\nname, email\ndistilbert\n0.978\n0.936\n0.912\n0.924\n\n\n6\nemail\ndeberta\n0.957\n0.859\n0.838\n0.848\n\n\n7\nemail\nbert-multilingual\n0.950\n0.894\n0.738\n0.808\n\n\n8\nn/a\ndeberta\n0.946\n0.847\n0.762\n0.803\n\n\n9\nn/a\nbert-multilingual\n0.941\n0.862\n0.700\n0.772\n\n\n10\nn/a\ndistilbert\n0.856\n0.000\n0.000\n0.000\n\n\n11\nemail\ndistilbert\n0.856\n0.000\n0.000\n0.000"
  }
]