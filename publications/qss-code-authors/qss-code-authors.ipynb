{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Code Contribution and Authorship\"\n",
    "author:\n",
    "  - name: \"Eva Maxfield Brown\"\n",
    "    email: evamxb@uw.edu\n",
    "    orcid: 0000-0003-2564-0373\n",
    "    affliation:\n",
    "      name: University of Washington Information School\n",
    "      city: Seattle\n",
    "      state: Washington\n",
    "      country: USA\n",
    "  - name: \"Nicholas Weber\"\n",
    "    email: nmweber@uw.edu\n",
    "    orcid: 0000-0002-6008-3763\n",
    "    affliation:\n",
    "      name: University of Washington Information School\n",
    "      city: Seattle\n",
    "      state: Washington\n",
    "      country: USA\n",
    "\n",
    "abstract: |\n",
    "  Lorem ipsum dolor sit amet, consectetur adipiscing elit. Curabitur eget porta erat. Morbi consectetur est vel gravida pretium. Suspendisse ut dui eu ante cursus gravida non sed sem. Nullam sapien tellus, commodo id velit id, eleifend volutpat quam. Phasellus mauris velit, dapibus finibus elementum vel, pulvinar non tellus. Nunc pellentesque pretium diam, quis maximus dolor faucibus id. Nunc convallis sodales ante, ut ullamcorper est egestas vitae. Nam sit amet enim ultrices, ultrices elit pulvinar, volutpat risus.\n",
    "\n",
    "## Basics\n",
    "bibliography: main.bib\n",
    "\n",
    "## Number sections (required for section cross ref)\n",
    "number-sections: true\n",
    "\n",
    "## Citation Style Language\n",
    "# See https://github.com/citation-style-language/styles for more options\n",
    "# We default to PNAS (Proceedings of the National Academy of Sciences)\n",
    "# csl: support/acm-proceedings.csl\n",
    "\n",
    "## Specific for target format\n",
    "format:\n",
    "  html:\n",
    "    code-tools: true\n",
    "    code-fold: true\n",
    "    code-summary: \"Show the code\"\n",
    "    standalone: true\n",
    "    embed-resources: true\n",
    "    toc: true\n",
    "    toc-location: left\n",
    "    reference-location: margin\n",
    "    citation-location: margin\n",
    "\n",
    "  pdf:\n",
    "    toc: false\n",
    "    execute:\n",
    "      echo: false\n",
    "    include-in-header:  \n",
    "      - text: |\n",
    "          \\usepackage{multirow}\n",
    "\n",
    "---\n",
    "\n",
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import IPython.display\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from sci_soft_models.dev_author_em.data import load_annotated_dev_author_em_dataset\n",
    "from sqlalchemy import text\n",
    "from sqlmodel import create_engine\n",
    "\n",
    "from rs_graph.db import models as db_models\n",
    "\n",
    "# Get db engine for production database\n",
    "db_path = Path(\"rs-graph-temp.db\").resolve().absolute()\n",
    "db_conn = create_engine(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Contemporary scientific research has become increasingly dependent on specialized software tools and computational methods.\n",
    "  - define scientific software (scripts, tools, infrastructure)\n",
    "  - importance in enabling large scale experiments and acting as a direct log of processing and analysis\n",
    "  - scientific code sharing is on the rise\n",
    "\n",
    "- Despite increased reliance on computational methodologies, the developers of scientific software have historically not been given traditional academic credit for their work: authorship on research articles.\n",
    "  - qualitative research which talks about acknowledgements sections instead of authorship\n",
    "  - lack of authorship can affect career prospects\n",
    "\n",
    "- While new credit systems aim to be more inclusive towards more contribution types, they still suffer from two key problems.\n",
    "\t- Contributor Roles Taxonomy (CRediT) allows for specific “software” contribution\n",
    "  - Others have used CREDIT to understand distribution of labor…\n",
    "\t- they are still based around an author list (it’s hard to change existing human practices, especially biased ones)\n",
    "\t- they aren’t verifiable, they are self-reported\n",
    "\n",
    "- To address these problems, we create a novel predictive model that enables matching scientific article authors and source code developer accounts.\n",
    "\t- a predictive model is the best choice for entity matching because while authors have ORCIDs, developer accounts do not***\n",
    "\t- further, developer account information may be slightly different from publication information (preferred name / legal name), username’s, etc\n",
    "\t- a fine-tuned transformer model enables us to connect accounts which have similar enough information, hopefully providing us with many more author-code-contributor matches than would be possible on exact name or email address matching alone\n",
    "\n",
    "- Our predictive model serves two primary purposes: identifying authors who directly contribute to an article’s associated codebase, and, revealing developers who were not included on the article’s authorship list.\n",
    "\t- while predictive, it is grounded in the commit logs of source code repositories, no longer self reported\n",
    "\t- individuals who have been left off can at least for now be identified by their developer account\n",
    "\n",
    "- Further, by applying our model across a large corpora of paired research articles and source code repositories, we enable objective insight into the software development dynamics of research teams.\n",
    "\t- much like studies of CRediT, we can investigate both how many article authors contribute code\n",
    "\t- similarly, we can investigate who contributes code (by author position and external characteristics\n",
    "\t- again, this is via commit logs and contribution histories, rather than self-reported data\n",
    "\n",
    "- To summarize, this paper makes the following contributions:\n",
    "\t- we train, evaluate, and make publicly available a predictive model to match article authors with developer accounts together\n",
    "\t- we create a large dataset of linked articles and source code repositories with accompanying bibliometric and repository information, and, further match article authors with repository developers\n",
    "\t- demonstration of the value of our predictive model through preliminary analysis of research team software development dynamics and code contributor characteristics\n",
    "\n",
    "- The rest of this paper is organized as follows:\n",
    "\t- …\n",
    "\n",
    "# Data and Methods\n",
    "\n",
    "## Linking Scientific Articles and Associated Source Code Repositories\n",
    "\n",
    "- Our trained predictive model and our preliminary analyses are based on datasets of linked bibliographic and source code repository information from multiple journals and publication platforms.\n",
    "\t- Each data source (the journals and publication platforms) either requires or recommends the sharing of code repositories related to a piece of work at the time of publication.\n",
    "\t- In turn, this allows us to mine article information for their either required, or recommended “data or code availability” links.\n",
    "\t- our data sources are:\n",
    "    - PLOS: research articles\n",
    "    - JOSS: software articles\n",
    "    - SoftwareX: software articles\n",
    "    - Papers with Code / ArXiv: pre-prints\n",
    "\n",
    "- Using each data source, we process the pairs of scientific articles and associated source code repositories, in order to extract the authorship and source code repository contributor lists as well as other bibliometric and repository information.\n",
    "\t- we use open alex to extract bibliometric information\n",
    "\t- we use the github API to extract repository information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc-repo-links that point at mult- docs or repos: 24696\n",
      "these are currently ignored / dropped before analysis\n"
     ]
    }
   ],
   "source": [
    "def read_table(table: str) -> pd.DataFrame:\n",
    "    return pd.read_sql(text(f\"SELECT * FROM {table}\"), db_conn)\n",
    "\n",
    "\n",
    "# Read all data from database\n",
    "doc_repo_links = read_table(db_models.DocumentRepositoryLink.__tablename__)\n",
    "researchers = read_table(db_models.Researcher.__tablename__)\n",
    "devs = read_table(db_models.DeveloperAccount.__tablename__)\n",
    "documents = read_table(db_models.Document.__tablename__)\n",
    "document_contributors = read_table(db_models.DocumentContributor.__tablename__)\n",
    "repositories = read_table(db_models.Repository.__tablename__)\n",
    "repository_contributors = read_table(db_models.RepositoryContributor.__tablename__)\n",
    "topics = read_table(db_models.Topic.__tablename__)\n",
    "document_topics = read_table(db_models.DocumentTopic.__tablename__)\n",
    "dataset_sources = read_table(db_models.DatasetSource.__tablename__)\n",
    "researcher_dev_links = read_table(\n",
    "    db_models.ResearcherDeveloperAccountLink.__tablename__\n",
    ")\n",
    "\n",
    "# Drop all \"updated_datetime\" and \"created_datetime\" columns\n",
    "for df in [\n",
    "    doc_repo_links,\n",
    "    researchers,\n",
    "    devs,\n",
    "    documents,\n",
    "    document_contributors,\n",
    "    repositories,\n",
    "    repository_contributors,\n",
    "    topics,\n",
    "    document_topics,\n",
    "    dataset_sources,\n",
    "    researcher_dev_links,\n",
    "]:\n",
    "    df.drop(columns=[\"updated_datetime\", \"created_datetime\"], inplace=True)\n",
    "\n",
    "# Specifically drop doc_repo_links \"id\" column\n",
    "# It isn't used and will get in the way later when we do a lot of joins\n",
    "doc_repo_links.drop(columns=[\"id\"], inplace=True)\n",
    "\n",
    "# Construct reduced doc_repo_links\n",
    "original_doc_repo_links_len = len(doc_repo_links)\n",
    "doc_repo_links = doc_repo_links.drop_duplicates(subset=[\"document_id\"], keep=False)\n",
    "doc_repo_links = doc_repo_links.drop_duplicates(subset=[\"repository_id\"], keep=False)\n",
    "print(\n",
    "    \"doc-repo-links that point at mult- docs or repos:\",\n",
    "    original_doc_repo_links_len - len(doc_repo_links),\n",
    ")\n",
    "print(\"these are currently ignored / dropped before analysis\")\n",
    "\n",
    "# Reduce other tables to only documents / repositories in the updated doc_repo_links\n",
    "documents = documents[documents[\"id\"].isin(doc_repo_links[\"document_id\"])]\n",
    "repositories = repositories[repositories[\"id\"].isin(doc_repo_links[\"repository_id\"])]\n",
    "document_contributors = document_contributors[\n",
    "    document_contributors[\"document_id\"].isin(documents[\"id\"])\n",
    "]\n",
    "repository_contributors = repository_contributors[\n",
    "    repository_contributors[\"repository_id\"].isin(repositories[\"id\"])\n",
    "]\n",
    "document_topics = document_topics[document_topics[\"document_id\"].isin(documents[\"id\"])]\n",
    "\n",
    "# Reduce researchers and devs to only those in the\n",
    "# updated document_contributors and repository_contributors\n",
    "researchers = researchers[\n",
    "    researchers[\"id\"].isin(document_contributors[\"researcher_id\"])\n",
    "]\n",
    "devs = devs[devs[\"id\"].isin(repository_contributors[\"developer_account_id\"])]\n",
    "researcher_dev_links = researcher_dev_links[\n",
    "    (\n",
    "        researcher_dev_links[\"researcher_id\"].isin(researchers[\"id\"])\n",
    "        & researcher_dev_links[\"developer_account_id\"].isin(devs[\"id\"])\n",
    "    )\n",
    "]\n",
    "\n",
    "# Sort document topics and keep first\n",
    "document_topics = document_topics.sort_values(\"score\", ascending=False)\n",
    "document_topics = document_topics.drop_duplicates(subset=[\"document_id\"], keep=\"first\")\n",
    "\n",
    "# Create document, document topic merged table\n",
    "merged_document_topics = pd.merge(\n",
    "    document_topics, topics, left_on=\"topic_id\", right_on=\"id\"\n",
    ")\n",
    "\n",
    "# Create basic merged tables\n",
    "merged_document_contributor_doc_repo_links = pd.merge(\n",
    "    document_contributors, doc_repo_links, left_on=\"document_id\", right_on=\"document_id\"\n",
    ")\n",
    "merged_repository_contributor_doc_repo_links = pd.merge(\n",
    "    repository_contributors,\n",
    "    doc_repo_links,\n",
    "    left_on=\"repository_id\",\n",
    "    right_on=\"repository_id\",\n",
    ")\n",
    "\n",
    "# Compute stats for data sources\n",
    "data_source_stats = []\n",
    "for _, data_source in dataset_sources.iterrows():\n",
    "    # Get total article-repo pairs\n",
    "    data_source_stats.append(\n",
    "        {\n",
    "            \"data_source\": data_source[\"name\"],\n",
    "            \"n_article_repo_pairs\": len(\n",
    "                doc_repo_links[doc_repo_links[\"dataset_source_id\"] == data_source[\"id\"]]\n",
    "            ),\n",
    "            \"n_authors\": merged_document_contributor_doc_repo_links.loc[\n",
    "                merged_document_contributor_doc_repo_links[\"dataset_source_id\"]\n",
    "                == data_source[\"id\"]\n",
    "            ][\"researcher_id\"].nunique(),\n",
    "            \"n_devs\": merged_repository_contributor_doc_repo_links.loc[\n",
    "                merged_repository_contributor_doc_repo_links[\"dataset_source_id\"]\n",
    "                == data_source[\"id\"]\n",
    "            ][\"developer_account_id\"].nunique(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create topic merged tables\n",
    "merged_doc_repo_links_topics = pd.merge(\n",
    "    doc_repo_links, document_topics, left_on=\"document_id\", right_on=\"document_id\"\n",
    ").merge(topics, left_on=\"topic_id\", right_on=\"id\")\n",
    "merged_doc_repo_links_topics_document_contributors = pd.merge(\n",
    "    merged_doc_repo_links_topics,\n",
    "    document_contributors,\n",
    "    left_on=\"document_id\",\n",
    "    right_on=\"document_id\",\n",
    ")\n",
    "merged_doc_repo_links_topics_repository_contributors = pd.merge(\n",
    "    merged_doc_repo_links_topics,\n",
    "    repository_contributors,\n",
    "    left_on=\"repository_id\",\n",
    "    right_on=\"repository_id\",\n",
    ")\n",
    "\n",
    "# Compute stats for domains\n",
    "domain_stats = []\n",
    "for domain in merged_doc_repo_links_topics.domain_name.unique():\n",
    "    # Get total article-repo pairs\n",
    "    domain_stats.append(\n",
    "        {\n",
    "            \"domain\": domain,\n",
    "            \"n_article_repo_pairs\": len(\n",
    "                merged_doc_repo_links_topics[\n",
    "                    merged_doc_repo_links_topics[\"domain_name\"] == domain\n",
    "                ]\n",
    "            ),\n",
    "            \"n_authors\": merged_doc_repo_links_topics_document_contributors.loc[\n",
    "                merged_doc_repo_links_topics_document_contributors[\"domain_name\"]\n",
    "                == domain\n",
    "            ][\"researcher_id\"].nunique(),\n",
    "            \"n_devs\": merged_doc_repo_links_topics_repository_contributors.loc[\n",
    "                merged_doc_repo_links_topics_repository_contributors[\"domain_name\"]\n",
    "                == domain\n",
    "            ][\"developer_account_id\"].nunique(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create document merged tables\n",
    "merged_doc_repo_links_documents = pd.merge(\n",
    "    doc_repo_links, documents, left_on=\"document_id\", right_on=\"id\"\n",
    ")\n",
    "merged_doc_repo_links_documents_document_contributors = pd.merge(\n",
    "    merged_doc_repo_links_documents,\n",
    "    document_contributors,\n",
    "    left_on=\"document_id\",\n",
    "    right_on=\"document_id\",\n",
    ")\n",
    "merged_doc_repo_links_documents_repository_contributors = pd.merge(\n",
    "    merged_doc_repo_links_documents,\n",
    "    repository_contributors,\n",
    "    left_on=\"repository_id\",\n",
    "    right_on=\"repository_id\",\n",
    ")\n",
    "\n",
    "# Compute stats for document types\n",
    "# This isn't a standard data pull\n",
    "# In short:\n",
    "# - pairs from PLOS are \"research articles\"\n",
    "# - pairs from JOSS are \"software articles\"\n",
    "# - pairs from SoftwareX are \"software articles\"\n",
    "# - pairs from Papers with Code / ArXiv are \"pre-prints\"\n",
    "#   UNLESS they have been published in a journal\n",
    "# All of those should be easy to assert / apply a label to with the exception\n",
    "# of Papers with Code / ArXiv pre-prints that have been published in a journal\n",
    "# In that case, we need to look at the existing document type in the database\n",
    "# If the document type is \"preprint\" use preprint, otherwise, if it's anything else,\n",
    "# use \"research article\"\n",
    "\n",
    "# Create a \"reduced_doc_types\" dataframe with document_id and \"reduced_doc_type\"\n",
    "# columns\n",
    "reduced_doc_types_rows = []\n",
    "# We can use the \"reduced_doc_types\" dataframe to calculate the stats\n",
    "\n",
    "# Iter over data sources even though we are looking for doc types\n",
    "for _, data_source in dataset_sources.iterrows():\n",
    "    # Get total article-repo pairs\n",
    "    doc_type = None\n",
    "    if data_source[\"name\"] in [\"plos\", \"joss\", \"softwarex\"]:\n",
    "        if data_source[\"name\"] == \"plos\":\n",
    "            doc_type = \"research article\"\n",
    "        else:\n",
    "            doc_type = \"software article\"\n",
    "\n",
    "        # Add all document_ids to reduced_doc_types_rows\n",
    "        reduced_doc_types_rows.extend(\n",
    "            [\n",
    "                {\"document_id\": doc_id, \"reduced_doc_type\": doc_type}\n",
    "                for doc_id in doc_repo_links[\n",
    "                    (doc_repo_links[\"dataset_source_id\"] == data_source[\"id\"])\n",
    "                ][\"document_id\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Handle PwC\n",
    "    else:\n",
    "        # Get preprint pairs\n",
    "        preprint_pairs = merged_doc_repo_links_documents[\n",
    "            (merged_doc_repo_links_documents[\"dataset_source_id\"] == data_source[\"id\"])\n",
    "            & (merged_doc_repo_links_documents[\"document_type\"] == \"preprint\")\n",
    "        ]\n",
    "\n",
    "        # Add all document_ids to reduced_doc_types_rows\n",
    "        reduced_doc_types_rows.extend(\n",
    "            [\n",
    "                {\"document_id\": doc_id, \"reduced_doc_type\": \"preprint\"}\n",
    "                for doc_id in preprint_pairs[\"document_id\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Get research article pairs\n",
    "        # This is the same just inverted to != \"preprint\"\n",
    "        research_article_pairs = merged_doc_repo_links_documents[\n",
    "            (merged_doc_repo_links_documents[\"dataset_source_id\"] == data_source[\"id\"])\n",
    "            & (merged_doc_repo_links_documents[\"document_type\"] != \"preprint\")\n",
    "        ]\n",
    "\n",
    "        # Add all document_ids to reduced_doc_types_rows\n",
    "        reduced_doc_types_rows.extend(\n",
    "            [\n",
    "                {\"document_id\": doc_id, \"reduced_doc_type\": \"research article\"}\n",
    "                for doc_id in research_article_pairs[\"document_id\"]\n",
    "            ]\n",
    "        )\n",
    "\n",
    "# Create reduced_doc_types dataframe\n",
    "reduced_doc_types = pd.DataFrame(reduced_doc_types_rows)\n",
    "\n",
    "# Now compute stats\n",
    "doc_type_stats = reduced_doc_types.groupby(\"reduced_doc_type\").apply(\n",
    "    lambda x: {\n",
    "        \"doc_type\": x.name,\n",
    "        \"n_article_repo_pairs\": len(x),\n",
    "        \"n_authors\": merged_doc_repo_links_documents_document_contributors.loc[\n",
    "            merged_doc_repo_links_documents_document_contributors[\"document_id\"].isin(\n",
    "                x[\"document_id\"]\n",
    "            )\n",
    "        ][\"researcher_id\"].nunique(),\n",
    "        \"n_devs\": merged_doc_repo_links_documents_repository_contributors.loc[\n",
    "            merged_doc_repo_links_documents_repository_contributors[\"document_id\"].isin(\n",
    "                x[\"document_id\"]\n",
    "            )\n",
    "        ][\"developer_account_id\"].nunique(),\n",
    "    },\n",
    "    include_groups=False,\n",
    ")\n",
    "\n",
    "# Compute stats for access status\n",
    "access_stats = []\n",
    "for access_status_int, access_status_name in [\n",
    "    (0, \"Closed\"),\n",
    "    (1, \"Open\"),\n",
    "]:\n",
    "    # Get total article-repo pairs\n",
    "    access_stats.append(\n",
    "        {\n",
    "            \"access_status\": access_status_name,\n",
    "            \"n_article_repo_pairs\": len(\n",
    "                merged_doc_repo_links_documents[\n",
    "                    merged_doc_repo_links_documents[\"is_open_access\"]\n",
    "                    == access_status_int\n",
    "                ]\n",
    "            ),\n",
    "            \"n_authors\": merged_doc_repo_links_documents_document_contributors.loc[\n",
    "                merged_doc_repo_links_documents_document_contributors[\"is_open_access\"]\n",
    "                == access_status_int\n",
    "            ][\"researcher_id\"].nunique(),\n",
    "            \"n_devs\": merged_doc_repo_links_documents_repository_contributors.loc[\n",
    "                merged_doc_repo_links_documents_repository_contributors[\n",
    "                    \"is_open_access\"\n",
    "                ]\n",
    "                == access_status_int\n",
    "            ][\"developer_account_id\"].nunique(),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Compute totals\n",
    "total_article_repo_pairs = len(doc_repo_links)\n",
    "total_authors = merged_document_contributor_doc_repo_links[\"researcher_id\"].nunique()\n",
    "total_devs = merged_repository_contributor_doc_repo_links[\n",
    "    \"developer_account_id\"\n",
    "].nunique()\n",
    "\n",
    "###############################################################################\n",
    "# Constuct HTML Table\n",
    "\n",
    "# Construct multi-row span HTML table\n",
    "# Columns should be: \"n_article_repo_pairs\", \"n_authors\", \"n_devs\"\n",
    "# Rows should be:\n",
    "# \"By Data Source\", \"By Domain\", \"By Document Type\", \"By Access Status\", and \"Total\"\n",
    "\n",
    "# HTML templates\n",
    "stats_piece_inital_row_template = \"\"\"\n",
    "<tr>\n",
    "  <td rowspan=\"{n_rows}\">{row_name}</td>\n",
    "  <td>{value_name}</td>\n",
    "  <td>{n_article_repo_pairs}</td>\n",
    "  <td>{n_authors}</td>\n",
    "  <td>{n_devs}</td>\n",
    "</tr>\n",
    "\"\"\".strip()\n",
    "\n",
    "stats_piece_subsequent_row_template = \"\"\"\n",
    "<tr>\n",
    "  <td>{value_name}</td>\n",
    "  <td>{n_article_repo_pairs}</td>\n",
    "  <td>{n_authors}</td>\n",
    "  <td>{n_devs}</td>\n",
    "</tr>\n",
    "\"\"\".strip()\n",
    "\n",
    "# Iter over stats portions (and total)\n",
    "stats_portions_html = []\n",
    "for stats_portion, stats_name, value_key in [\n",
    "    (data_source_stats, \"<b>By Data Source</b>\", \"data_source\"),\n",
    "    (domain_stats, \"<b>By Domain</b>\", \"domain\"),\n",
    "    (doc_type_stats, \"<b>By Document Type</b>\", \"doc_type\"),\n",
    "    (access_stats, \"<b>By Access Status</b>\", \"access_status\"),\n",
    "    (\n",
    "        [\n",
    "            {\n",
    "                \"empty\": \"\",\n",
    "                \"n_article_repo_pairs\": f\"<b>{total_article_repo_pairs}</b>\",\n",
    "                \"n_authors\": f\"<b>{total_authors}</b>\",\n",
    "                \"n_devs\": f\"<b>{total_devs}</b>\",\n",
    "            }\n",
    "        ],\n",
    "        \"<b>Total</b>\",\n",
    "        \"empty\",\n",
    "    ),\n",
    "]:\n",
    "    # Order by article-repo pairs\n",
    "    stats_portion = sorted(\n",
    "        stats_portion, key=lambda x: x[\"n_article_repo_pairs\"], reverse=True\n",
    "    )\n",
    "\n",
    "    stats_portion_html = []\n",
    "    for i, stats_piece in enumerate(stats_portion):\n",
    "        if i == 0:\n",
    "            stats_portion_html.append(\n",
    "                stats_piece_inital_row_template.format(\n",
    "                    n_rows=len(stats_portion),\n",
    "                    row_name=stats_name,\n",
    "                    value_name=stats_piece[value_key],\n",
    "                    n_article_repo_pairs=stats_piece[\"n_article_repo_pairs\"],\n",
    "                    n_authors=stats_piece[\"n_authors\"],\n",
    "                    n_devs=stats_piece[\"n_devs\"],\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            stats_portion_html.append(\n",
    "                stats_piece_subsequent_row_template.format(\n",
    "                    value_name=stats_piece[value_key],\n",
    "                    n_article_repo_pairs=stats_piece[\"n_article_repo_pairs\"],\n",
    "                    n_authors=stats_piece[\"n_authors\"],\n",
    "                    n_devs=stats_piece[\"n_devs\"],\n",
    "                )\n",
    "            )\n",
    "\n",
    "    stats_portions_html.append(\"\\n\".join(stats_portion_html))\n",
    "\n",
    "# Concat and wrap in table\n",
    "stats_table_html = f\"\"\"\n",
    "<table>\n",
    "  <tr>\n",
    "    <th><b>Category</b></th>\n",
    "    <th><b>Subset</b></th>\n",
    "    <th><b># Article-Repository Pairs</b></th>\n",
    "    <th><b># Authors</b></th>\n",
    "    <th><b># Developers</b></th>\n",
    "  </tr>\n",
    "  {\" \".join(stats_portions_html)}\n",
    "</table>\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Our final dataset contains the bibliometric and code repository information for hundreds of thousands of scientific-article-source-code-repository pairs from multiple article types and fields.\n",
    "  - Specifically, our dataset contains `{python} total_article_repo_pairs` article-repository pairs, `{python} total_authors` distinct authors, and `{python} total_devs` distinct developer accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "  <tr>\n",
       "    <th><b>Category</b></th>\n",
       "    <th><b>Subset</b></th>\n",
       "    <th><b># Article-Repository Pairs</b></th>\n",
       "    <th><b># Authors</b></th>\n",
       "    <th><b># Developers</b></th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "  <td rowspan=\"4\"><b>By Data Source</b></td>\n",
       "  <td>pwc</td>\n",
       "  <td>129615</td>\n",
       "  <td>262889</td>\n",
       "  <td>134926</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>plos</td>\n",
       "  <td>6090</td>\n",
       "  <td>30233</td>\n",
       "  <td>8784</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>joss</td>\n",
       "  <td>2336</td>\n",
       "  <td>7105</td>\n",
       "  <td>11362</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>softwarex</td>\n",
       "  <td>555</td>\n",
       "  <td>2244</td>\n",
       "  <td>1628</td>\n",
       "</tr> <tr>\n",
       "  <td rowspan=\"4\"><b>By Domain</b></td>\n",
       "  <td>Physical Sciences</td>\n",
       "  <td>116600</td>\n",
       "  <td>240545</td>\n",
       "  <td>130592</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Social Sciences</td>\n",
       "  <td>8838</td>\n",
       "  <td>29269</td>\n",
       "  <td>14043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Life Sciences</td>\n",
       "  <td>7729</td>\n",
       "  <td>31649</td>\n",
       "  <td>12150</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Health Sciences</td>\n",
       "  <td>5172</td>\n",
       "  <td>25979</td>\n",
       "  <td>7248</td>\n",
       "</tr> <tr>\n",
       "  <td rowspan=\"3\"><b>By Document Type</b></td>\n",
       "  <td>preprint</td>\n",
       "  <td>72177</td>\n",
       "  <td>170301</td>\n",
       "  <td>87311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>research article</td>\n",
       "  <td>63528</td>\n",
       "  <td>173183</td>\n",
       "  <td>78935</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>software article</td>\n",
       "  <td>2891</td>\n",
       "  <td>9294</td>\n",
       "  <td>12868</td>\n",
       "</tr> <tr>\n",
       "  <td rowspan=\"2\"><b>By Access Status</b></td>\n",
       "  <td>Open</td>\n",
       "  <td>132856</td>\n",
       "  <td>286874</td>\n",
       "  <td>147831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Closed</td>\n",
       "  <td>5740</td>\n",
       "  <td>23668</td>\n",
       "  <td>9352</td>\n",
       "</tr> <tr>\n",
       "  <td rowspan=\"1\"><b>Total</b></td>\n",
       "  <td></td>\n",
       "  <td><b>138596</b></td>\n",
       "  <td><b>295806</b></td>\n",
       "  <td><b>152170</b></td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | label: tbl-rs-graph-overall-counts\n",
    "# | tbl-cap: \"Counts of Article-Repository Pairs, Authors, and Developers broken out by Data Sources, Domains, Document Types, and Access Status.\"\n",
    "# | echo: false\n",
    "\n",
    "IPython.display.HTML(stats_table_html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Matching of Article Authors and Source Code Repository Contributors\n",
    "\n",
    "- Before we can train and validate a predictive entity matching model, we must first create a large annotated dataset of article authors and source code repository contributor pairs.\n",
    "\t- describe the task (we have info about an author identity and a developer identity, are they the same identity)\n",
    "\t- add figure for more detail\n",
    "\n",
    "- We had two annotators each label 3000 pairs of article author and source code repository contributor information.\n",
    "\t- we use the subset of our dataset of joss authors and contributors.\n",
    "\t- we use JOSS as we believe a software article sample will provide us with the highest rate of positive identity matches for training (or a somewhat balanced dataset)\n",
    "\t- we create author-developer-account annotation pairs using data from individual single paper-repository pairs.\n",
    "\t- that is, developers and authors were only paired for annotation if they were paired together meaning that we would never annotate a author-developer-account pair that had developer information with an author from an unrelated paper\n",
    "\t- After each annotator completed labeling all 3000 author-code-contributor pairs, annotators then resolved any differences between their labels.\n",
    "\n",
    "- Our final annotated dataset used for model training consists of the author names and source code repository contributor information from the 3000 labeled author-code-contributor pairs.\n",
    "\t- basic numbers, number of “positive” and “negative” matches\n",
    "\t- note however that some developer accounts do not have a complete set of information available\n",
    "\t- table of number of developer accounts with each feature and by their match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching dev-author-em model data...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>github_id</th>\n",
       "      <th>semantic_scholar_id</th>\n",
       "      <th>dev_details</th>\n",
       "      <th>author_details</th>\n",
       "      <th>match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JonasGe</td>\n",
       "      <td>48985590</td>\n",
       "      <td>username: JonasGe;\\nname: Jonas Geuens;\\nemail...</td>\n",
       "      <td>name: J. Geuens;\\nrepos: https://github.com/On...</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lindonroberts</td>\n",
       "      <td>2671934</td>\n",
       "      <td>username: lindonroberts;\\nname: Lindon Roberts...</td>\n",
       "      <td>name: Á. Bürmen;\\nrepos: https://github.com/jf...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>retdop</td>\n",
       "      <td>3278559</td>\n",
       "      <td>username: retdop;\\nname: Gabriel Bastard;\\nema...</td>\n",
       "      <td>name: David Eargle;\\nrepos: https://github.com...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>benjaminpope</td>\n",
       "      <td>2086347474</td>\n",
       "      <td>username: benjaminpope;\\nname: Benjamin Pope;\\...</td>\n",
       "      <td>name: Jordan Dennis;\\nrepos: https://github.co...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zachmayer</td>\n",
       "      <td>144385402</td>\n",
       "      <td>username: zachmayer;\\nname: Zach Deane-Mayer;\\...</td>\n",
       "      <td>name: Yuan Tang;\\nrepos: https://github.com/te...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2994</th>\n",
       "      <td>WilliamZekaiWang</td>\n",
       "      <td>153846264</td>\n",
       "      <td>username: WilliamZekaiWang;\\nname: None;\\nemai...</td>\n",
       "      <td>name: Mathias S. Renaud;\\nrepos: https://githu...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>avalentino</td>\n",
       "      <td>51907604</td>\n",
       "      <td>username: avalentino;\\nname: Antonio Valentino...</td>\n",
       "      <td>name: L. Uieda;\\nrepos: https://github.com/fat...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>prakharb10</td>\n",
       "      <td>71208381</td>\n",
       "      <td>username: prakharb10;\\nname: Prakhar Bhatnagar...</td>\n",
       "      <td>name: Matthew Treinish;\\nrepos: https://github...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>jmsexton03</td>\n",
       "      <td>2108239862</td>\n",
       "      <td>username: jmsexton03;\\nname: Jean M. Sexton;\\n...</td>\n",
       "      <td>name: Weiqun Zhang;\\nrepos: https://github.com...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>haarburger</td>\n",
       "      <td>1737693</td>\n",
       "      <td>username: haarburger;\\nname: Christoph Haarbur...</td>\n",
       "      <td>name: D. Merhof;\\nrepos: https://github.com/ju...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2999 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             github_id  semantic_scholar_id  \\\n",
       "0              JonasGe             48985590   \n",
       "1        lindonroberts              2671934   \n",
       "2               retdop              3278559   \n",
       "3         benjaminpope           2086347474   \n",
       "4            zachmayer            144385402   \n",
       "...                ...                  ...   \n",
       "2994  WilliamZekaiWang            153846264   \n",
       "2995        avalentino             51907604   \n",
       "2996        prakharb10             71208381   \n",
       "2997        jmsexton03           2108239862   \n",
       "2998        haarburger              1737693   \n",
       "\n",
       "                                            dev_details  \\\n",
       "0     username: JonasGe;\\nname: Jonas Geuens;\\nemail...   \n",
       "1     username: lindonroberts;\\nname: Lindon Roberts...   \n",
       "2     username: retdop;\\nname: Gabriel Bastard;\\nema...   \n",
       "3     username: benjaminpope;\\nname: Benjamin Pope;\\...   \n",
       "4     username: zachmayer;\\nname: Zach Deane-Mayer;\\...   \n",
       "...                                                 ...   \n",
       "2994  username: WilliamZekaiWang;\\nname: None;\\nemai...   \n",
       "2995  username: avalentino;\\nname: Antonio Valentino...   \n",
       "2996  username: prakharb10;\\nname: Prakhar Bhatnagar...   \n",
       "2997  username: jmsexton03;\\nname: Jean M. Sexton;\\n...   \n",
       "2998  username: haarburger;\\nname: Christoph Haarbur...   \n",
       "\n",
       "                                         author_details  match  \n",
       "0     name: J. Geuens;\\nrepos: https://github.com/On...   True  \n",
       "1     name: Á. Bürmen;\\nrepos: https://github.com/jf...  False  \n",
       "2     name: David Eargle;\\nrepos: https://github.com...  False  \n",
       "3     name: Jordan Dennis;\\nrepos: https://github.co...  False  \n",
       "4     name: Yuan Tang;\\nrepos: https://github.com/te...  False  \n",
       "...                                                 ...    ...  \n",
       "2994  name: Mathias S. Renaud;\\nrepos: https://githu...  False  \n",
       "2995  name: L. Uieda;\\nrepos: https://github.com/fat...  False  \n",
       "2996  name: Matthew Treinish;\\nrepos: https://github...  False  \n",
       "2997  name: Weiqun Zhang;\\nrepos: https://github.com...  False  \n",
       "2998  name: D. Merhof;\\nrepos: https://github.com/ju...  False  \n",
       "\n",
       "[2999 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load annotated dataset\n",
    "annotated_dataset = load_annotated_dev_author_em_dataset()\n",
    "\n",
    "annotated_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A Predictive Model for Matching Article Authors and Source Code Contributors\n",
    "\n",
    "- To optimize our predictive model for author-contributor matching, we evaluate a variety of Transformer-based architectures and input features.\n",
    "\t- multiple transformer base models available and there isn’t clear information as to which is “best” for entity matching\n",
    "\t- we have minimal info for authors, just their name, but we have a few features for developer accounts and it isn’t clear which are most important or useful\n",
    "\t- explain potential problems and benefits of certain features\n",
    "\n",
    "- To ensure that our trained model is as accurate as possible, we trained and evaluated multiple combinations of pre-trained Transformer base models and different developer account information feature sets.\n",
    "\t- explain the feature sets a bit more (username only, username + name, etc.)\n",
    "\t- explain the testing strategy (10% of unique authors and developers are used for testing)\n",
    "\n",
    "- After testing all base-model and feature set combinations, we find that our best performing model is fine-tuned from: Y and uses Z features.\n",
    "\t- specifics of best model\n",
    "\t- table of model configurations and results\n",
    "\t- minor observations about feature sets that perform poorly\n",
    "\n",
    "- Finally, we additionally make our best performing model publicly available for reuse.\n",
    "\t- We provide a structured python library for interaction with the model at link\n",
    "\t- Direct access to the model files can be found on huggingface.\n",
    "\n",
    "# Preliminary Analysis Code Contributor Authorship and Development Dynamics of Research Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 72\u001b[0m\n\u001b[1;32m     68\u001b[0m researchers_coded \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m researchers_w_3_docs\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# Check for dev account\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     dev_links \u001b[38;5;241m=\u001b[39m researcher_dev_links\u001b[38;5;241m.\u001b[39mloc[\n\u001b[0;32m---> 72\u001b[0m         \u001b[43mresearcher_dev_links\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresearcher_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresearcher_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     73\u001b[0m     ]\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dev_links) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     75\u001b[0m         researchers_coded\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m     76\u001b[0m             {\n\u001b[1;32m     77\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresearcher_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresearcher_id\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m             }\n\u001b[1;32m     81\u001b[0m         )\n",
      "File \u001b[0;32m~/micromamba/envs/rs-graph/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/rs-graph/lib/python3.12/site-packages/pandas/core/arraylike.py:40\u001b[0m, in \u001b[0;36mOpsMixin.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__eq__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cmp_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meq\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/micromamba/envs/rs-graph/lib/python3.12/site-packages/pandas/core/series.py:6119\u001b[0m, in \u001b[0;36mSeries._cmp_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   6116\u001b[0m lvalues \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   6117\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m extract_array(other, extract_numpy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, extract_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m-> 6119\u001b[0m res_values \u001b[38;5;241m=\u001b[39m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomparison_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(res_values, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[0;32m~/micromamba/envs/rs-graph/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:347\u001b[0m, in \u001b[0;36mcomparison_op\u001b[0;34m(left, right, op)\u001b[0m\n\u001b[1;32m    344\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m \u001b[43m_na_arithmetic_op\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_cmp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[0;32m~/micromamba/envs/rs-graph/lib/python3.12/site-packages/pandas/core/ops/array_ops.py:218\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[0;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[1;32m    215\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 218\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mright\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    221\u001b[0m         left\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(right, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m\n\u001b[1;32m    222\u001b[0m     ):\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[1;32m    226\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/rs-graph/lib/python3.12/site-packages/pandas/core/computation/expressions.py:242\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[0;32m--> 242\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[0;32m~/micromamba/envs/rs-graph/lib/python3.12/site-packages/pandas/core/computation/expressions.py:73\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[0;34m(op, op_str, a, b)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[1;32m     72\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 73\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# First, get the set of researchers who have at least 3 documents\n",
    "researchers_w_3_docs = researchers.loc[\n",
    "    researchers[\"id\"].isin(\n",
    "        document_contributors[\"researcher_id\"]\n",
    "        .value_counts()\n",
    "        .loc[lambda x: x >= 3]\n",
    "        .index\n",
    "    )\n",
    "]\n",
    "\n",
    "# Next, for each researcher, get the set of documents they have contributed to\n",
    "researchers_w_3_docs = document_contributors.loc[\n",
    "    document_contributors[\"researcher_id\"].isin(researchers_w_3_docs[\"id\"])\n",
    "].merge(\n",
    "    researchers_w_3_docs,\n",
    "    left_on=\"researcher_id\",\n",
    "    right_on=\"id\",\n",
    ")\n",
    "\n",
    "# Attach document for publication date\n",
    "researchers_w_3_docs = researchers_w_3_docs.merge(\n",
    "    documents[[\"id\", \"publication_date\"]],\n",
    "    left_on=\"document_id\",\n",
    "    right_on=\"id\",\n",
    ").drop(\n",
    "    columns=[\"id\"],\n",
    ")\n",
    "\n",
    "# Keep only certain columns\n",
    "researchers_w_3_docs = researchers_w_3_docs[\n",
    "    [\n",
    "        \"researcher_id\",\n",
    "        \"document_id\",\n",
    "        \"publication_date\",\n",
    "        \"position\",\n",
    "        \"is_corresponding\",\n",
    "        \"works_count\",\n",
    "        \"cited_by_count\",\n",
    "        \"h_index\",\n",
    "        \"i10_index\",\n",
    "        \"two_year_mean_citedness\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Next, for each researcher_doc, attach the document details (domain, reduced_doc_type)\n",
    "researchers_w_3_docs = (\n",
    "    researchers_w_3_docs.merge(\n",
    "        document_topics[[\"document_id\", \"topic_id\"]],\n",
    "        left_on=\"document_id\",\n",
    "        right_on=\"document_id\",\n",
    "    )\n",
    "    .merge(\n",
    "        topics[[\"id\", \"domain_name\"]],\n",
    "        left_on=\"topic_id\",\n",
    "        right_on=\"id\",\n",
    "    )\n",
    "    .drop(\n",
    "        columns=[\"id\", \"topic_id\"],\n",
    "    )\n",
    "    .merge(\n",
    "        reduced_doc_types,\n",
    "        left_on=\"document_id\",\n",
    "        right_on=\"document_id\",\n",
    "    )\n",
    ")\n",
    "\n",
    "# Now for each of these, we want to see if they have coded on the document\n",
    "researchers_coded = []\n",
    "for _, row in researchers_w_3_docs.iterrows():\n",
    "    # Check for dev account\n",
    "    dev_links = researcher_dev_links.loc[\n",
    "        researcher_dev_links[\"researcher_id\"] == row[\"researcher_id\"]\n",
    "    ]\n",
    "    if len(dev_links) == 0:\n",
    "        researchers_coded.append(\n",
    "            {\n",
    "                \"researcher_id\": row[\"researcher_id\"],\n",
    "                \"document_id\": row[\"document_id\"],\n",
    "                \"coded_on_article\": 0,\n",
    "            }\n",
    "        )\n",
    "        continue\n",
    "\n",
    "    # Skip this person if they have more than 3 links\n",
    "    # Likely something went wrong\n",
    "    if len(dev_links) > 3:\n",
    "        continue\n",
    "\n",
    "    # Get repos associated with document\n",
    "    repo_links_for_doc = doc_repo_links.loc[\n",
    "        doc_repo_links[\"document_id\"] == row[\"document_id\"]\n",
    "    ]\n",
    "\n",
    "    # Skip if there is more than 1 repo associated with the document\n",
    "    # We just don't know how to handle these cases right now\n",
    "    if len(repo_links_for_doc) > 1:\n",
    "        continue\n",
    "\n",
    "    # Also skip if 0\n",
    "    if len(repo_links_for_doc) == 0:\n",
    "        continue\n",
    "\n",
    "    # Get the repo_id for the single repo\n",
    "    repo_id = repo_links_for_doc[\"repository_id\"].iloc[0]\n",
    "\n",
    "    # Get the repo_contributors for this repository\n",
    "    repo_contributors = repository_contributors.loc[\n",
    "        repository_contributors[\"repository_id\"] == repo_id\n",
    "    ]\n",
    "\n",
    "    # Check if any of the dev accounts are in the repo contribs\n",
    "    researcher_coded = (\n",
    "        len(\n",
    "            set(repo_contributors[\"developer_account_id\"].unique()).intersection(\n",
    "                set(dev_links[\"developer_account_id\"].unique()),\n",
    "            )\n",
    "        )\n",
    "        > 0\n",
    "    )\n",
    "\n",
    "    # Finally assert any of the repo_contributors are the dev account\n",
    "    # associated with the researcher\n",
    "    researchers_coded.append(\n",
    "        {\n",
    "            \"researcher_id\": row[\"researcher_id\"],\n",
    "            \"document_id\": row[\"document_id\"],\n",
    "            \"coded_on_article\": int(researcher_coded),\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create dataframe\n",
    "researchers_coded_df = pd.DataFrame(researchers_coded)\n",
    "\n",
    "# Merge with researchers_w_3_docs\n",
    "researchers_w_3_docs_and_coded = researchers_coded_df.merge(\n",
    "    researchers_w_3_docs,\n",
    "    left_on=[\"researcher_id\", \"document_id\"],\n",
    "    right_on=[\"researcher_id\", \"document_id\"],\n",
    ")\n",
    "researchers_w_3_docs_and_coded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _mode_or_recent_reduce(group: pd.DataFrame, col: str) -> str:\n",
    "    # Get the mode\n",
    "    mode = group[col].mode().tolist()\n",
    "    if len(mode) == 1:\n",
    "        return mode[0]\n",
    "\n",
    "    # Otherwise, iter over most recent publications until value in mode is found\n",
    "    group_ordered_by_date = group.sort_values(\"publication_date\", ascending=False)\n",
    "    for _, row in group_ordered_by_date.iterrows():\n",
    "        if row[col] in mode:\n",
    "            return row[col]\n",
    "\n",
    "\n",
    "def _agg_apply(group: pd.DataFrame) -> dict:\n",
    "    return {\n",
    "        \"n_documents\": group[\"document_id\"].nunique(),\n",
    "        \"n_coded\": group[\"coded_on_article\"].sum(),\n",
    "        \"works_count\": group[\"works_count\"].iloc[0],\n",
    "        \"cited_by_count\": group[\"cited_by_count\"].iloc[0],\n",
    "        \"h_index\": group[\"h_index\"].iloc[0],\n",
    "        \"i10_index\": group[\"i10_index\"].iloc[0],\n",
    "        \"two_year_mean_citedness\": group[\"two_year_mean_citedness\"].iloc[0],\n",
    "        \"position\": _mode_or_recent_reduce(group, \"position\"),\n",
    "        \"domain_name\": _mode_or_recent_reduce(group, \"domain_name\"),\n",
    "        \"reduced_doc_type\": _mode_or_recent_reduce(group, \"reduced_doc_type\"),\n",
    "    }\n",
    "\n",
    "\n",
    "researchers_w_3_docs_and_coded_agg = (\n",
    "    researchers_w_3_docs_and_coded.groupby(\"researcher_id\")[\n",
    "        [col for col in researchers_w_3_docs_and_coded if col != \"researcher_id\"]\n",
    "    ]\n",
    "    .apply(_agg_apply)\n",
    "    .reset_index(name=\"dicts\")\n",
    ")\n",
    "researchers_w_3_docs_and_coded_agg = researchers_w_3_docs_and_coded_agg.join(\n",
    "    pd.json_normalize(researchers_w_3_docs_and_coded_agg[\"dicts\"])\n",
    ").drop(columns=[\"dicts\"])\n",
    "\n",
    "# Create three features for coding status\n",
    "# \"any\" coding status\n",
    "# \"majority\" coding status\n",
    "# \"always\" coding status\n",
    "researchers_w_3_docs_and_coded_agg[\"any_coding\"] = (\n",
    "    researchers_w_3_docs_and_coded_agg[\"n_coded\"] > 0\n",
    ").astype(int)\n",
    "researchers_w_3_docs_and_coded_agg[\"majority_coding\"] = (\n",
    "    researchers_w_3_docs_and_coded_agg[\"n_coded\"]\n",
    "    >= researchers_w_3_docs_and_coded_agg[\"n_documents\"] / 2\n",
    ").astype(int)\n",
    "researchers_w_3_docs_and_coded_agg[\"always_coding\"] = (\n",
    "    researchers_w_3_docs_and_coded_agg[\"n_coded\"]\n",
    "    == researchers_w_3_docs_and_coded_agg[\"n_documents\"]\n",
    ").astype(int)\n",
    "\n",
    "# Store counts of coding status for table\n",
    "coding_status_counts = (\n",
    "    researchers_w_3_docs_and_coded_agg[\n",
    "        [\"any_coding\", \"majority_coding\", \"always_coding\"]\n",
    "    ]\n",
    "    .value_counts()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Drop n_documents, n_coded and\n",
    "# rename \"position\" to \"common_author_position\",\n",
    "# \"domain_name\" to \"common_domain\",\n",
    "# and \"reduced_doc_type\" to \"common_article_type\"\n",
    "researchers_w_3_docs_and_coded_agg = researchers_w_3_docs_and_coded_agg.drop(\n",
    "    columns=[\"n_documents\", \"n_coded\"]\n",
    ")\n",
    "researchers_w_3_docs_and_coded_agg = researchers_w_3_docs_and_coded_agg.rename(\n",
    "    columns={\n",
    "        \"position\": \"common_author_position\",\n",
    "        \"domain_name\": \"common_domain\",\n",
    "        \"reduced_doc_type\": \"common_article_type\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# Get dummies for categorical variables\n",
    "researchers_w_3_docs_and_coded_agg_dummies = pd.get_dummies(\n",
    "    researchers_w_3_docs_and_coded_agg,\n",
    "    columns=[\"common_author_position\", \"common_domain\", \"common_article_type\"],\n",
    "    drop_first=True,\n",
    ")\n",
    "\n",
    "# Cast all to float\n",
    "researchers_w_3_docs_and_coded_agg_dummies = (\n",
    "    researchers_w_3_docs_and_coded_agg_dummies.astype(float)\n",
    ")\n",
    "\n",
    "researchers_w_3_docs_and_coded_agg_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of people who code any, majority, and always for each control variable\n",
    "control_vars = {\n",
    "    \"common_author_position\": \"Most Freq. Author Position\",\n",
    "    \"common_domain\": \"Most Freq. Domain\",\n",
    "    \"common_article_type\": \"Most Freq. Article Type\",\n",
    "}\n",
    "control_var_tables = {}\n",
    "for control_var, control_display_name in control_vars.items():\n",
    "    # Get counts of coding status\n",
    "    count_table = (\n",
    "        researchers_w_3_docs_and_coded_agg.groupby(control_var)[\n",
    "            [\"any_coding\", \"majority_coding\", \"always_coding\"]\n",
    "        ]\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Add totals\n",
    "    for val in count_table[control_var].unique():\n",
    "        count_table.loc[count_table[control_var] == val, \"total\"] = len(\n",
    "            researchers_w_3_docs_and_coded_agg.loc[\n",
    "                researchers_w_3_docs_and_coded_agg[control_var] == val\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    # Convert total to int\n",
    "    count_table[\"total\"] = count_table[\"total\"].astype(int)\n",
    "\n",
    "    # Change name of the control_var column to \"Control Values\"\n",
    "    count_table = count_table.rename(columns={control_var: \"Control Values\"})\n",
    "\n",
    "    # Order columns\n",
    "    count_table = count_table[\n",
    "        [\"Control Values\", \"any_coding\", \"majority_coding\", \"always_coding\", \"total\"]\n",
    "    ]\n",
    "\n",
    "    # Rename columns\n",
    "    count_table = count_table.rename(\n",
    "        columns={\n",
    "            \"any_coding\": \"Coded Any\",\n",
    "            \"majority_coding\": \"Coded Majority\",\n",
    "            \"always_coding\": \"Coded Always\",\n",
    "            \"total\": \"Total\",\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Order alphabetically\n",
    "    count_table = count_table.sort_values(\"Control Values\")\n",
    "\n",
    "    # Append\n",
    "    control_var_tables[control_display_name] = count_table\n",
    "\n",
    "# Constuct HTML Table\n",
    "\n",
    "# Construct multi-row span HTML table\n",
    "# Columns should be: \"Coded Any\", \"Coded Majority\", \"Coded Always\", \"Total\"\n",
    "# Rows should be:\n",
    "# \"Most Freq. Author Position\", \"Most Freq. Domain\", \"Most Freq. Article Type\"\n",
    "\n",
    "# HTML templates\n",
    "count_piece_inital_row_template = \"\"\"\n",
    "<tr>\n",
    "  <td rowspan=\"{n_rows}\">{row_name}</td>\n",
    "  <td>{value_name}</td>\n",
    "  <td>{any_coding}</td>\n",
    "  <td>{majority_coding}</td>\n",
    "  <td>{always_coding}</td>\n",
    "  <td>{total}</td>\n",
    "</tr>\n",
    "\"\"\".strip()\n",
    "\n",
    "count_piece_subsequent_row_template = \"\"\"\n",
    "<tr>\n",
    "  <td>{value_name}</td>\n",
    "  <td>{any_coding}</td>\n",
    "  <td>{majority_coding}</td>\n",
    "  <td>{always_coding}</td>\n",
    "  <td>{total}</td>\n",
    "</tr>\n",
    "\"\"\".strip()\n",
    "\n",
    "# Iter over stats portions (and total)\n",
    "count_portions_html = []\n",
    "for key, count_table in control_var_tables.items():\n",
    "    count_portion_html = []\n",
    "    for i, control_value in enumerate(count_table[\"Control Values\"].unique()):\n",
    "        if i == 0:\n",
    "            count_portion_html.append(\n",
    "                count_piece_inital_row_template.format(\n",
    "                    n_rows=len(count_table),\n",
    "                    row_name=key,\n",
    "                    value_name=control_value,\n",
    "                    any_coding=count_table.loc[\n",
    "                        count_table[\"Control Values\"] == control_value, \"Coded Any\"\n",
    "                    ].iloc[0],\n",
    "                    majority_coding=count_table.loc[\n",
    "                        count_table[\"Control Values\"] == control_value, \"Coded Majority\"\n",
    "                    ].iloc[0],\n",
    "                    always_coding=count_table.loc[\n",
    "                        count_table[\"Control Values\"] == control_value, \"Coded Always\"\n",
    "                    ].iloc[0],\n",
    "                    total=count_table.loc[\n",
    "                        count_table[\"Control Values\"] == control_value, \"Total\"\n",
    "                    ].iloc[0],\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            count_portion_html.append(\n",
    "                count_piece_subsequent_row_template.format(\n",
    "                    value_name=control_value,\n",
    "                    any_coding=count_table.loc[\n",
    "                        count_table[\"Control Values\"] == control_value, \"Coded Any\"\n",
    "                    ].iloc[0],\n",
    "                    majority_coding=count_table.loc[\n",
    "                        count_table[\"Control Values\"] == control_value, \"Coded Majority\"\n",
    "                    ].iloc[0],\n",
    "                    always_coding=count_table.loc[\n",
    "                        count_table[\"Control Values\"] == control_value, \"Coded Always\"\n",
    "                    ].iloc[0],\n",
    "                    total=count_table.loc[\n",
    "                        count_table[\"Control Values\"] == control_value, \"Total\"\n",
    "                    ].iloc[0],\n",
    "                )\n",
    "            )\n",
    "\n",
    "    count_portions_html.append(\"\\n\".join(count_portion_html))\n",
    "\n",
    "# Concat and wrap in table\n",
    "count_table_html = f\"\"\"\n",
    "<table>\n",
    "  <tr>\n",
    "    <th><b>Control Variable</b></th>\n",
    "    <th><b>Control Values</b></th>\n",
    "    <th><b>Coded Any</b></th>\n",
    "    <th><b>Coded Majority</b></th>\n",
    "    <th><b>Coded Always</b></th>\n",
    "  </tr>\n",
    "  {\" \".join(count_portions_html)}\n",
    "</table>\n",
    "\"\"\".strip()\n",
    "\n",
    "IPython.display.HTML(count_table_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_models(\n",
    "    y_col: str,\n",
    "    data: pd.DataFrame,\n",
    "    glm_family: sm.families.Family,\n",
    ") -> dict[str, sm.GLM]:\n",
    "    # Remove all \"zero\" y_col authors\n",
    "    no_outliers = data[data[y_col] > 0].copy()\n",
    "\n",
    "    # Remove outliers\n",
    "    no_outliers = no_outliers[\n",
    "        no_outliers[y_col].between(\n",
    "            no_outliers[y_col].quantile(0.03),\n",
    "            no_outliers[y_col].quantile(0.97),\n",
    "        )\n",
    "    ].copy()\n",
    "\n",
    "    print(no_outliers[y_col].describe())\n",
    "    print()\n",
    "    print()\n",
    "    print(no_outliers[\"works_count\"].describe())\n",
    "\n",
    "    # Common features to use in all models\n",
    "    required_features = [\n",
    "        y_col,\n",
    "        \"works_count\",\n",
    "        \"any_coding\",\n",
    "        \"majority_coding\",\n",
    "        \"always_coding\",\n",
    "    ]\n",
    "\n",
    "    # Iter over different control variables and create models for each\n",
    "    models = {}\n",
    "    for control_var in [\n",
    "        \"common_author_position\",\n",
    "        \"common_article_type\",\n",
    "        \"common_domain\",\n",
    "    ]:\n",
    "        # Get control variable list\n",
    "        control_variables = [\n",
    "            col for col in no_outliers.columns if col.startswith(control_var)\n",
    "        ]\n",
    "\n",
    "        # Create control variable subset of the data\n",
    "        control_var_subset = no_outliers[required_features + control_variables].copy()\n",
    "\n",
    "        # Create interactions\n",
    "        for coding_status_col in [\"any_coding\", \"majority_coding\", \"always_coding\"]:\n",
    "            for control_col in control_variables:\n",
    "                control_var_subset[f\"{coding_status_col} * {control_col}\"] = (\n",
    "                    control_var_subset[coding_status_col]\n",
    "                    * control_var_subset[control_col]\n",
    "                )\n",
    "\n",
    "        # Drop inf and nan\n",
    "        control_var_subset = control_var_subset.replace(\n",
    "            [float(\"inf\"), -float(\"inf\")], float(\"nan\")\n",
    "        ).dropna()\n",
    "\n",
    "        # Create x and y\n",
    "        y = control_var_subset[y_col]\n",
    "        x = control_var_subset.drop(columns=[y_col])\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "        # Fit model\n",
    "        model = sm.GLM(y, x, family=glm_family).fit()\n",
    "        models[control_var] = model\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cited_by_count_models = compute_models(\n",
    "    \"cited_by_count\",\n",
    "    researchers_w_3_docs_and_coded_agg_dummies,\n",
    "    glm_family=sm.families.NegativeBinomial(),\n",
    ")\n",
    "cited_by_count_models[\"common_author_position\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cited_by_count_models[\"common_domain\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cited_by_count_models[\"common_article_type\"].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Research Team Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88551/88551 [03:01<00:00, 487.83it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document_id</th>\n",
       "      <th>repository_id</th>\n",
       "      <th>repository_last_push_datetime</th>\n",
       "      <th>n_authors</th>\n",
       "      <th>n_author_devs</th>\n",
       "      <th>n_devs</th>\n",
       "      <th>publication_date</th>\n",
       "      <th>cited_by_count</th>\n",
       "      <th>fwci</th>\n",
       "      <th>is_open_access</th>\n",
       "      <th>domain</th>\n",
       "      <th>article_type</th>\n",
       "      <th>pct_authors_contributing_code</th>\n",
       "      <th>years_since_publication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2020-11-09 20:59:12</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>34</td>\n",
       "      <td>2.795</td>\n",
       "      <td>1</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>research article</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>4.835044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2020-04-13 04:01:08</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-07-17</td>\n",
       "      <td>73</td>\n",
       "      <td>4.176</td>\n",
       "      <td>1</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>research article</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>5.295003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2024-08-02 19:42:36</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>preprint</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>3.832991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>2023-06-17 04:29:49</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>preprint</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.832991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>2023-10-27 14:43:57</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2023-04-01</td>\n",
       "      <td>10</td>\n",
       "      <td>5.260</td>\n",
       "      <td>1</td>\n",
       "      <td>Social Sciences</td>\n",
       "      <td>research article</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1.587953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88546</th>\n",
       "      <td>157303</td>\n",
       "      <td>153581</td>\n",
       "      <td>2024-08-13 13:47:44</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>40</td>\n",
       "      <td>3.477</td>\n",
       "      <td>1</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>software article</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>6.833676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88547</th>\n",
       "      <td>157304</td>\n",
       "      <td>153582</td>\n",
       "      <td>2018-09-21 06:40:23</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>0.320</td>\n",
       "      <td>1</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>software article</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.833676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88548</th>\n",
       "      <td>157305</td>\n",
       "      <td>153584</td>\n",
       "      <td>2024-08-12 16:22:25</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>40</td>\n",
       "      <td>3.102</td>\n",
       "      <td>1</td>\n",
       "      <td>Health Sciences</td>\n",
       "      <td>software article</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>6.833676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88549</th>\n",
       "      <td>157306</td>\n",
       "      <td>153585</td>\n",
       "      <td>2018-07-27 08:08:50</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>12</td>\n",
       "      <td>0.762</td>\n",
       "      <td>1</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>software article</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.833676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88550</th>\n",
       "      <td>157307</td>\n",
       "      <td>153587</td>\n",
       "      <td>2018-06-15 10:53:42</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>27</td>\n",
       "      <td>3.951</td>\n",
       "      <td>1</td>\n",
       "      <td>Physical Sciences</td>\n",
       "      <td>software article</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.833676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71194 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       document_id  repository_id repository_last_push_datetime  n_authors  \\\n",
       "1                3              3           2020-11-09 20:59:12          5   \n",
       "2                7              7           2020-04-13 04:01:08          6   \n",
       "3                8              8           2024-08-02 19:42:36          8   \n",
       "4                9              9           2023-06-17 04:29:49          4   \n",
       "5               10             10           2023-10-27 14:43:57          6   \n",
       "...            ...            ...                           ...        ...   \n",
       "88546       157303         153581           2024-08-13 13:47:44          6   \n",
       "88547       157304         153582           2018-09-21 06:40:23          5   \n",
       "88548       157305         153584           2024-08-12 16:22:25          5   \n",
       "88549       157306         153585           2018-07-27 08:08:50          3   \n",
       "88550       157307         153587           2018-06-15 10:53:42          8   \n",
       "\n",
       "       n_author_devs  n_devs publication_date  cited_by_count   fwci  \\\n",
       "1                  1       1       2020-01-01              34  2.795   \n",
       "2                  1       1       2019-07-17              73  4.176   \n",
       "3                  3       7       2021-01-01               1    NaN   \n",
       "4                  2       2       2021-01-01               1    NaN   \n",
       "5                  1       2       2023-04-01              10  5.260   \n",
       "...              ...     ...              ...             ...    ...   \n",
       "88546              4      21       2018-01-01              40  3.477   \n",
       "88547              0       1       2018-01-01              12  0.320   \n",
       "88548              3       6       2018-01-01              40  3.102   \n",
       "88549              0       1       2018-01-01              12  0.762   \n",
       "88550              0       1       2018-01-01              27  3.951   \n",
       "\n",
       "       is_open_access             domain      article_type  \\\n",
       "1                   1  Physical Sciences  research article   \n",
       "2                   1  Physical Sciences  research article   \n",
       "3                   1  Physical Sciences          preprint   \n",
       "4                   1  Physical Sciences          preprint   \n",
       "5                   1    Social Sciences  research article   \n",
       "...               ...                ...               ...   \n",
       "88546               1  Physical Sciences  software article   \n",
       "88547               1  Physical Sciences  software article   \n",
       "88548               1    Health Sciences  software article   \n",
       "88549               1  Physical Sciences  software article   \n",
       "88550               1  Physical Sciences  software article   \n",
       "\n",
       "       pct_authors_contributing_code  years_since_publication  \n",
       "1                           0.200000                 4.835044  \n",
       "2                           0.166667                 5.295003  \n",
       "3                           0.375000                 3.832991  \n",
       "4                           0.500000                 3.832991  \n",
       "5                           0.166667                 1.587953  \n",
       "...                              ...                      ...  \n",
       "88546                       0.666667                 6.833676  \n",
       "88547                       0.000000                 6.833676  \n",
       "88548                       0.600000                 6.833676  \n",
       "88549                       0.000000                 6.833676  \n",
       "88550                       0.000000                 6.833676  \n",
       "\n",
       "[71194 rows x 14 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create subset documents\n",
    "docs_w_1_citation = documents.loc[documents[\"cited_by_count\"] >= 1].copy()\n",
    "\n",
    "# Subset to only certain columns\n",
    "docs_w_1_citation = docs_w_1_citation[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"publication_date\",\n",
    "        \"cited_by_count\",\n",
    "        \"fwci\",\n",
    "        \"is_open_access\",\n",
    "    ]\n",
    "]\n",
    "\n",
    "# Rename id to document_id\n",
    "docs_w_1_citation = docs_w_1_citation.rename(columns={\"id\": \"document_id\"})\n",
    "\n",
    "# Merge repository id in\n",
    "docs_w_1_citation = docs_w_1_citation.merge(\n",
    "    doc_repo_links[\n",
    "        [\n",
    "            \"document_id\",\n",
    "            \"repository_id\",\n",
    "        ]\n",
    "    ],\n",
    "    left_on=\"document_id\",\n",
    "    right_on=\"document_id\",\n",
    ")\n",
    "\n",
    "# Merge in document details (domain, document type)\n",
    "docs_w_1_citation = (\n",
    "    docs_w_1_citation.merge(\n",
    "        document_topics[[\"document_id\", \"topic_id\"]],\n",
    "        left_on=\"document_id\",\n",
    "        right_on=\"document_id\",\n",
    "    )\n",
    "    .merge(\n",
    "        topics[[\"id\", \"domain_name\"]],\n",
    "        left_on=\"topic_id\",\n",
    "        right_on=\"id\",\n",
    "    )\n",
    "    .drop(\n",
    "        columns=[\"id\", \"topic_id\"],\n",
    "    )\n",
    "    .merge(\n",
    "        reduced_doc_types,\n",
    "        left_on=\"document_id\",\n",
    "        right_on=\"document_id\",\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"domain_name\": \"domain\",\n",
    "            \"reduced_doc_type\": \"article_type\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "\n",
    "# Drop any documents that have more than one repository (and vice versa)\n",
    "docs_w_1_citation = docs_w_1_citation.drop_duplicates(\n",
    "    subset=[\"document_id\"], keep=False\n",
    ")\n",
    "docs_w_1_citation = docs_w_1_citation.drop_duplicates(\n",
    "    subset=[\"repository_id\"], keep=False\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Iter over articles and get the team composition info\n",
    "team_composition_rows = []\n",
    "for _, row in tqdm(\n",
    "    docs_w_1_citation.iterrows(),\n",
    "    total=len(docs_w_1_citation),\n",
    "):\n",
    "    # Get a boolean value for \"no pushes after publication\"\n",
    "    repo_details = repositories.loc[repositories[\"id\"] == row[\"repository_id\"]].iloc[0]\n",
    "\n",
    "    # Get the number of authors\n",
    "    author_ids = document_contributors.loc[\n",
    "        document_contributors[\"document_id\"] == row[\"document_id\"]\n",
    "    ][\"researcher_id\"].unique()\n",
    "    n_authors = len(author_ids)\n",
    "\n",
    "    # Get the number of devs\n",
    "    dev_ids = repository_contributors.loc[\n",
    "        repository_contributors[\"repository_id\"] == row[\"repository_id\"]\n",
    "    ][\"developer_account_id\"].unique()\n",
    "    n_devs = len(dev_ids)\n",
    "\n",
    "    # Get the set of researcher_dev_links for the authors\n",
    "    author_dev_links = researcher_dev_links.loc[\n",
    "        researcher_dev_links[\"researcher_id\"].isin(author_ids)\n",
    "    ]\n",
    "\n",
    "    # Drop duplicates by developer_account_id (keeping first)\n",
    "    # as we may have accidently matched the same dev to the multiple authors\n",
    "    author_dev_links = author_dev_links.drop_duplicates(\n",
    "        subset=[\"developer_account_id\"],\n",
    "        keep=\"first\",\n",
    "    )\n",
    "\n",
    "    # Get the number of authors who were devs on this paper\n",
    "    n_author_devs = 0\n",
    "    for author_id in author_ids:\n",
    "        author_dev_ids = author_dev_links.loc[\n",
    "            author_dev_links[\"researcher_id\"] == author_id\n",
    "        ][\"developer_account_id\"].unique()\n",
    "\n",
    "        # Fast exit\n",
    "        if len(author_dev_ids) == 0:\n",
    "            continue\n",
    "\n",
    "        # Something likely went wrong in matching\n",
    "        if len(author_dev_ids) > 3:\n",
    "            continue\n",
    "\n",
    "        if any(author_dev_id in dev_ids for author_dev_id in author_dev_ids):\n",
    "            n_author_devs += 1\n",
    "\n",
    "    # Append\n",
    "    team_composition_rows.append(\n",
    "        {\n",
    "            \"document_id\": row[\"document_id\"],\n",
    "            \"repository_id\": row[\"repository_id\"],\n",
    "            \"repository_last_push_datetime\": repo_details[\"last_pushed_datetime\"],\n",
    "            \"n_authors\": n_authors,\n",
    "            \"n_author_devs\": n_author_devs,\n",
    "            \"n_devs\": n_devs,\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Create dataframe\n",
    "team_composition = pd.DataFrame(team_composition_rows)\n",
    "\n",
    "# Merge with docs_w_1_citation\n",
    "team_composition = team_composition.merge(\n",
    "    docs_w_1_citation,\n",
    "    left_on=[\"document_id\", \"repository_id\"],\n",
    "    right_on=[\"document_id\", \"repository_id\"],\n",
    ")\n",
    "\n",
    "# Filter out papers with less than 3 authors or 1 dev\n",
    "team_composition = team_composition.loc[team_composition[\"n_authors\"] >= 3]\n",
    "team_composition = team_composition.loc[team_composition[\"n_devs\"] >= 1]\n",
    "\n",
    "# Create a pct_authors_contributing_code column\n",
    "team_composition[\"pct_authors_contributing_code\"] = (\n",
    "    team_composition[\"n_author_devs\"] / team_composition[\"n_authors\"]\n",
    ")\n",
    "\n",
    "# Convert datetimes to datetime\n",
    "team_composition[\"publication_date\"] = pd.to_datetime(\n",
    "    team_composition[\"publication_date\"]\n",
    ")\n",
    "team_composition[\"repository_last_push_datetime\"] = pd.to_datetime(\n",
    "    team_composition[\"repository_last_push_datetime\"]\n",
    ")\n",
    "\n",
    "# Calculate years since publication from 2024-11-01\n",
    "team_composition[\"years_since_publication\"] = (\n",
    "    pd.to_datetime(\"2024-11-01\") - team_composition[\"publication_date\"]\n",
    ").dt.days / 365.25\n",
    "\n",
    "team_composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x2c47303b0>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a \"days_since_last_push\" column\n",
    "team_composition[\"days_from_publication_to_last_push\"] = (\n",
    "    team_composition[\"repository_last_push_datetime\"] - team_composition[\"publication_date\"]\n",
    ").dt.days\n",
    "\n",
    "# Create copy of dataframe to filter out outliers\n",
    "team_comp_for_dist = team_composition.copy()\n",
    "\n",
    "# Filter out outliers\n",
    "team_comp_for_dist = team_comp_for_dist[\n",
    "    team_comp_for_dist[\"days_from_publication_to_last_push\"].between(\n",
    "        team_comp_for_dist[\"days_from_publication_to_last_push\"].quantile(0.03),\n",
    "        team_comp_for_dist[\"days_from_publication_to_last_push\"].quantile(0.97),\n",
    "    )\n",
    "]\n",
    "\n",
    "# Plot distribution of days since last push\n",
    "import seaborn as sns\n",
    "\n",
    "sns.displot(\n",
    "    team_comp_for_dist,\n",
    "    x=\"days_from_publication_to_last_push\",\n",
    "    bins=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    66925.000000\n",
       "mean       357.020202\n",
       "std        410.412902\n",
       "min       -282.000000\n",
       "25%         30.000000\n",
       "50%        269.000000\n",
       "75%        573.000000\n",
       "max       1681.000000\n",
       "Name: days_from_publication_to_last_push, dtype: float64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "team_comp_for_dist[\"days_from_publication_to_last_push\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_models(\n",
    "    y_col: str,\n",
    "    data: pd.DataFrame,\n",
    "    glm_family: sm.families.Family,\n",
    ") -> dict[str, sm.GLM]:\n",
    "    # Remove outliers\n",
    "    no_outliers = data[\n",
    "        data[y_col].between(\n",
    "            data[y_col].quantile(0.03),\n",
    "            data[y_col].quantile(0.97),\n",
    "        )\n",
    "    ].copy()\n",
    "\n",
    "    # Remove nans\n",
    "    no_outliers = no_outliers.dropna(subset=[y_col])\n",
    "\n",
    "    print(no_outliers[y_col].describe())\n",
    "\n",
    "    # Common features to use in all models\n",
    "    required_features = [\n",
    "        y_col,\n",
    "        \"n_authors\",\n",
    "        \"n_author_devs\",\n",
    "        # \"pct_authors_contributing_code\",\n",
    "        \"years_since_publication\",\n",
    "    ]\n",
    "\n",
    "    # Iter over different control variables and create models for each\n",
    "    models = {}\n",
    "    for control_var in [\n",
    "        \"article_type\",\n",
    "        \"domain\",\n",
    "        \"is_open_access\",\n",
    "    ]:\n",
    "        # Get control variable list\n",
    "        control_variables = [\n",
    "            col for col in no_outliers.columns if col.startswith(control_var)\n",
    "        ]\n",
    "\n",
    "        # Create control variable subset of the data\n",
    "        control_var_subset = no_outliers[required_features + control_variables].copy()\n",
    "\n",
    "        # Create interactions\n",
    "        for coding_status_col in [\"n_author_devs\"]:\n",
    "            for control_col in control_variables:\n",
    "                control_var_subset[f\"{coding_status_col} * {control_col}\"] = (\n",
    "                    control_var_subset[coding_status_col]\n",
    "                    * control_var_subset[control_col]\n",
    "                )\n",
    "\n",
    "        # Drop inf and nan\n",
    "        control_var_subset = control_var_subset.replace(\n",
    "            [float(\"inf\"), -float(\"inf\")], float(\"nan\")\n",
    "        ).dropna()\n",
    "\n",
    "        # Create x and y\n",
    "        y = control_var_subset[y_col]\n",
    "        x = control_var_subset.drop(columns=[y_col])\n",
    "        x = sm.add_constant(x)\n",
    "\n",
    "        # Fit model\n",
    "        model = sm.GLM(y, x, family=glm_family).fit()\n",
    "        models[control_var] = model\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evamaxfield/micromamba/envs/rs-graph/lib/python3.12/site-packages/statsmodels/genmod/families/family.py:1367: ValueWarning: Negative binomial dispersion parameter alpha not set. Using default value alpha=1.0.\n",
      "  warnings.warn(\"Negative binomial dispersion parameter alpha not \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    22649.000000\n",
      "mean        13.439004\n",
      "std         18.664143\n",
      "min          1.000000\n",
      "25%          2.000000\n",
      "50%          6.000000\n",
      "75%         16.000000\n",
      "max        116.000000\n",
      "Name: cited_by_count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>cited_by_count</td>  <th>  No. Observations:  </th>  <td> 22649</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 22643</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>    <td>NegativeBinomial</td> <th>  Df Model:          </th>  <td>     5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -78507.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 20 Nov 2024</td> <th>  Deviance:          </th> <td>  22924.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:00:57</td>     <th>  Pearson chi2:      </th> <td>3.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>34</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.2857</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                   <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                          <td>    0.8682</td> <td>    0.059</td> <td>   14.752</td> <td> 0.000</td> <td>    0.753</td> <td>    0.984</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_authors</th>                      <td>    0.0219</td> <td>    0.001</td> <td>   20.743</td> <td> 0.000</td> <td>    0.020</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_author_devs</th>                  <td>    0.0575</td> <td>    0.046</td> <td>    1.250</td> <td> 0.211</td> <td>   -0.033</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_since_publication</th>        <td>    0.3750</td> <td>    0.004</td> <td>   93.201</td> <td> 0.000</td> <td>    0.367</td> <td>    0.383</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>is_open_access</th>                 <td>    0.4322</td> <td>    0.060</td> <td>    7.208</td> <td> 0.000</td> <td>    0.315</td> <td>    0.550</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_author_devs * is_open_access</th> <td>   -0.0326</td> <td>    0.047</td> <td>   -0.692</td> <td> 0.489</td> <td>   -0.125</td> <td>    0.060</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     & cited\\_by\\_count & \\textbf{  No. Observations:  } &    22649    \\\\\n",
       "\\textbf{Model:}                             &       GLM        & \\textbf{  Df Residuals:      } &    22643    \\\\\n",
       "\\textbf{Model Family:}                      & NegativeBinomial & \\textbf{  Df Model:          } &        5    \\\\\n",
       "\\textbf{Link Function:}                     &       Log        & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}                            &       IRLS       & \\textbf{  Log-Likelihood:    } &   -78507.   \\\\\n",
       "\\textbf{Date:}                              & Wed, 20 Nov 2024 & \\textbf{  Deviance:          } &    22924.   \\\\\n",
       "\\textbf{Time:}                              &     12:00:57     & \\textbf{  Pearson chi2:      } &  3.47e+04   \\\\\n",
       "\\textbf{No. Iterations:}                    &        34        & \\textbf{  Pseudo R-squ. (CS):} &   0.2857    \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                              &       0.8682  &        0.059     &    14.752  &         0.000        &        0.753    &        0.984     \\\\\n",
       "\\textbf{n\\_authors}                         &       0.0219  &        0.001     &    20.743  &         0.000        &        0.020    &        0.024     \\\\\n",
       "\\textbf{n\\_author\\_devs}                    &       0.0575  &        0.046     &     1.250  &         0.211        &       -0.033    &        0.148     \\\\\n",
       "\\textbf{years\\_since\\_publication}          &       0.3750  &        0.004     &    93.201  &         0.000        &        0.367    &        0.383     \\\\\n",
       "\\textbf{is\\_open\\_access}                   &       0.4322  &        0.060     &     7.208  &         0.000        &        0.315    &        0.550     \\\\\n",
       "\\textbf{n\\_author\\_devs * is\\_open\\_access} &      -0.0326  &        0.047     &    -0.692  &         0.489        &       -0.125    &        0.060     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:         cited_by_count   No. Observations:                22649\n",
       "Model:                            GLM   Df Residuals:                    22643\n",
       "Model Family:        NegativeBinomial   Df Model:                            5\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -78507.\n",
       "Date:                Wed, 20 Nov 2024   Deviance:                       22924.\n",
       "Time:                        12:00:57   Pearson chi2:                 3.47e+04\n",
       "No. Iterations:                    34   Pseudo R-squ. (CS):             0.2857\n",
       "Covariance Type:            nonrobust                                         \n",
       "==================================================================================================\n",
       "                                     coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------------------\n",
       "const                              0.8682      0.059     14.752      0.000       0.753       0.984\n",
       "n_authors                          0.0219      0.001     20.743      0.000       0.020       0.024\n",
       "n_author_devs                      0.0575      0.046      1.250      0.211      -0.033       0.148\n",
       "years_since_publication            0.3750      0.004     93.201      0.000       0.367       0.383\n",
       "is_open_access                     0.4322      0.060      7.208      0.000       0.315       0.550\n",
       "n_author_devs * is_open_access    -0.0326      0.047     -0.692      0.489      -0.125       0.060\n",
       "==================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a \"days_since_last_push\" column\n",
    "team_composition[\"days_from_publication_to_last_push\"] = (\n",
    "    team_composition[\"repository_last_push_datetime\"] - team_composition[\"publication_date\"]\n",
    ").dt.days\n",
    "\n",
    "team_comp_no_push_after_pub = team_composition.loc[\n",
    "    team_composition[\"days_from_publication_to_last_push\"] <= 90\n",
    "]\n",
    "\n",
    "# Add dummies\n",
    "team_comp_no_push_after_pub_dummies = pd.get_dummies(\n",
    "    team_comp_no_push_after_pub,\n",
    "    columns=[\"article_type\", \"domain\"],\n",
    "    drop_first=True,\n",
    ")\n",
    "\n",
    "# Drop datetime columns\n",
    "team_comp_no_push_after_pub_dummies = team_comp_no_push_after_pub_dummies.drop(\n",
    "    columns=[\n",
    "        \"publication_date\",\n",
    "        \"repository_last_push_datetime\",\n",
    "        \"days_from_publication_to_last_push\",\n",
    "        \"n_devs\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Cast all to float\n",
    "team_comp_no_push_after_pub_dummies = team_comp_no_push_after_pub_dummies.astype(float)\n",
    "\n",
    "cited_by_count_models = compute_models(\n",
    "    \"cited_by_count\",\n",
    "    team_comp_no_push_after_pub_dummies,\n",
    "    glm_family=sm.families.NegativeBinomial(),\n",
    ")\n",
    "cited_by_count_models[\"is_open_access\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>cited_by_count</td>  <th>  No. Observations:  </th>  <td> 22649</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 22639</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>    <td>NegativeBinomial</td> <th>  Df Model:          </th>  <td>     9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -78483.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 20 Nov 2024</td> <th>  Deviance:          </th> <td>  22877.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:00:57</td>     <th>  Pearson chi2:      </th> <td>3.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>36</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.2872</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                      <td></td>                        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                    <td>    1.1377</td> <td>    0.057</td> <td>   20.100</td> <td> 0.000</td> <td>    1.027</td> <td>    1.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_authors</th>                                <td>    0.0230</td> <td>    0.001</td> <td>   21.690</td> <td> 0.000</td> <td>    0.021</td> <td>    0.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_author_devs</th>                            <td>    0.0735</td> <td>    0.047</td> <td>    1.580</td> <td> 0.114</td> <td>   -0.018</td> <td>    0.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_since_publication</th>                  <td>    0.3903</td> <td>    0.004</td> <td>   97.613</td> <td> 0.000</td> <td>    0.383</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>domain_Life Sciences</th>                     <td>   -0.1961</td> <td>    0.067</td> <td>   -2.937</td> <td> 0.003</td> <td>   -0.327</td> <td>   -0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>domain_Physical Sciences</th>                 <td>    0.1537</td> <td>    0.056</td> <td>    2.722</td> <td> 0.006</td> <td>    0.043</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>domain_Social Sciences</th>                   <td>   -0.2158</td> <td>    0.075</td> <td>   -2.892</td> <td> 0.004</td> <td>   -0.362</td> <td>   -0.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_author_devs * domain_Life Sciences</th>     <td>    0.0143</td> <td>    0.055</td> <td>    0.261</td> <td> 0.794</td> <td>   -0.093</td> <td>    0.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_author_devs * domain_Physical Sciences</th> <td>   -0.0624</td> <td>    0.048</td> <td>   -1.307</td> <td> 0.191</td> <td>   -0.156</td> <td>    0.031</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_author_devs * domain_Social Sciences</th>   <td>    0.0538</td> <td>    0.060</td> <td>    0.889</td> <td> 0.374</td> <td>   -0.065</td> <td>    0.172</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                              & cited\\_by\\_count & \\textbf{  No. Observations:  } &    22649    \\\\\n",
       "\\textbf{Model:}                                      &       GLM        & \\textbf{  Df Residuals:      } &    22639    \\\\\n",
       "\\textbf{Model Family:}                               & NegativeBinomial & \\textbf{  Df Model:          } &        9    \\\\\n",
       "\\textbf{Link Function:}                              &       Log        & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}                                     &       IRLS       & \\textbf{  Log-Likelihood:    } &   -78483.   \\\\\n",
       "\\textbf{Date:}                                       & Wed, 20 Nov 2024 & \\textbf{  Deviance:          } &    22877.   \\\\\n",
       "\\textbf{Time:}                                       &     12:00:57     & \\textbf{  Pearson chi2:      } &  3.44e+04   \\\\\n",
       "\\textbf{No. Iterations:}                             &        36        & \\textbf{  Pseudo R-squ. (CS):} &   0.2872    \\\\\n",
       "\\textbf{Covariance Type:}                            &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                     & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                                       &       1.1377  &        0.057     &    20.100  &         0.000        &        1.027    &        1.249     \\\\\n",
       "\\textbf{n\\_authors}                                  &       0.0230  &        0.001     &    21.690  &         0.000        &        0.021    &        0.025     \\\\\n",
       "\\textbf{n\\_author\\_devs}                             &       0.0735  &        0.047     &     1.580  &         0.114        &       -0.018    &        0.165     \\\\\n",
       "\\textbf{years\\_since\\_publication}                   &       0.3903  &        0.004     &    97.613  &         0.000        &        0.383    &        0.398     \\\\\n",
       "\\textbf{domain\\_Life Sciences}                       &      -0.1961  &        0.067     &    -2.937  &         0.003        &       -0.327    &       -0.065     \\\\\n",
       "\\textbf{domain\\_Physical Sciences}                   &       0.1537  &        0.056     &     2.722  &         0.006        &        0.043    &        0.264     \\\\\n",
       "\\textbf{domain\\_Social Sciences}                     &      -0.2158  &        0.075     &    -2.892  &         0.004        &       -0.362    &       -0.070     \\\\\n",
       "\\textbf{n\\_author\\_devs * domain\\_Life Sciences}     &       0.0143  &        0.055     &     0.261  &         0.794        &       -0.093    &        0.122     \\\\\n",
       "\\textbf{n\\_author\\_devs * domain\\_Physical Sciences} &      -0.0624  &        0.048     &    -1.307  &         0.191        &       -0.156    &        0.031     \\\\\n",
       "\\textbf{n\\_author\\_devs * domain\\_Social Sciences}   &       0.0538  &        0.060     &     0.889  &         0.374        &       -0.065    &        0.172     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:         cited_by_count   No. Observations:                22649\n",
       "Model:                            GLM   Df Residuals:                    22639\n",
       "Model Family:        NegativeBinomial   Df Model:                            9\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -78483.\n",
       "Date:                Wed, 20 Nov 2024   Deviance:                       22877.\n",
       "Time:                        12:00:57   Pearson chi2:                 3.44e+04\n",
       "No. Iterations:                    36   Pseudo R-squ. (CS):             0.2872\n",
       "Covariance Type:            nonrobust                                         \n",
       "============================================================================================================\n",
       "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------\n",
       "const                                        1.1377      0.057     20.100      0.000       1.027       1.249\n",
       "n_authors                                    0.0230      0.001     21.690      0.000       0.021       0.025\n",
       "n_author_devs                                0.0735      0.047      1.580      0.114      -0.018       0.165\n",
       "years_since_publication                      0.3903      0.004     97.613      0.000       0.383       0.398\n",
       "domain_Life Sciences                        -0.1961      0.067     -2.937      0.003      -0.327      -0.065\n",
       "domain_Physical Sciences                     0.1537      0.056      2.722      0.006       0.043       0.264\n",
       "domain_Social Sciences                      -0.2158      0.075     -2.892      0.004      -0.362      -0.070\n",
       "n_author_devs * domain_Life Sciences         0.0143      0.055      0.261      0.794      -0.093       0.122\n",
       "n_author_devs * domain_Physical Sciences    -0.0624      0.048     -1.307      0.191      -0.156       0.031\n",
       "n_author_devs * domain_Social Sciences       0.0538      0.060      0.889      0.374      -0.065       0.172\n",
       "============================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cited_by_count_models[\"domain\"].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.602661258781"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.exp(-0.5064)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>    <td>cited_by_count</td>  <th>  No. Observations:  </th>  <td> 22649</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>       <th>  Df Residuals:      </th>  <td> 22641</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>    <td>NegativeBinomial</td> <th>  Df Model:          </th>  <td>     7</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>          <td>Log</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -78130.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 20 Nov 2024</td> <th>  Deviance:          </th> <td>  22169.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>12:00:58</td>     <th>  Pearson chi2:      </th> <td>3.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>34</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.3091</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                        <td></td>                           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                                         <td>    0.7721</td> <td>    0.035</td> <td>   21.939</td> <td> 0.000</td> <td>    0.703</td> <td>    0.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_authors</th>                                     <td>    0.0213</td> <td>    0.001</td> <td>   20.157</td> <td> 0.000</td> <td>    0.019</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_author_devs</th>                                 <td>   -0.0458</td> <td>    0.024</td> <td>   -1.894</td> <td> 0.058</td> <td>   -0.093</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>years_since_publication</th>                       <td>    0.3956</td> <td>    0.004</td> <td>   99.544</td> <td> 0.000</td> <td>    0.388</td> <td>    0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>article_type_research article</th>                 <td>    0.5032</td> <td>    0.035</td> <td>   14.196</td> <td> 0.000</td> <td>    0.434</td> <td>    0.573</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>article_type_software article</th>                 <td>   -0.5197</td> <td>    0.116</td> <td>   -4.475</td> <td> 0.000</td> <td>   -0.747</td> <td>   -0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_author_devs * article_type_research article</th> <td>    0.0954</td> <td>    0.026</td> <td>    3.599</td> <td> 0.000</td> <td>    0.043</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>n_author_devs * article_type_software article</th> <td>    0.0697</td> <td>    0.058</td> <td>    1.210</td> <td> 0.226</td> <td>   -0.043</td> <td>    0.183</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                    & cited\\_by\\_count & \\textbf{  No. Observations:  } &    22649    \\\\\n",
       "\\textbf{Model:}                                            &       GLM        & \\textbf{  Df Residuals:      } &    22641    \\\\\n",
       "\\textbf{Model Family:}                                     & NegativeBinomial & \\textbf{  Df Model:          } &        7    \\\\\n",
       "\\textbf{Link Function:}                                    &       Log        & \\textbf{  Scale:             } &    1.0000   \\\\\n",
       "\\textbf{Method:}                                           &       IRLS       & \\textbf{  Log-Likelihood:    } &   -78130.   \\\\\n",
       "\\textbf{Date:}                                             & Wed, 20 Nov 2024 & \\textbf{  Deviance:          } &    22169.   \\\\\n",
       "\\textbf{Time:}                                             &     12:00:58     & \\textbf{  Pearson chi2:      } &  3.37e+04   \\\\\n",
       "\\textbf{No. Iterations:}                                   &        34        & \\textbf{  Pseudo R-squ. (CS):} &   0.3091    \\\\\n",
       "\\textbf{Covariance Type:}                                  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                           & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}                                             &       0.7721  &        0.035     &    21.939  &         0.000        &        0.703    &        0.841     \\\\\n",
       "\\textbf{n\\_authors}                                        &       0.0213  &        0.001     &    20.157  &         0.000        &        0.019    &        0.023     \\\\\n",
       "\\textbf{n\\_author\\_devs}                                   &      -0.0458  &        0.024     &    -1.894  &         0.058        &       -0.093    &        0.002     \\\\\n",
       "\\textbf{years\\_since\\_publication}                         &       0.3956  &        0.004     &    99.544  &         0.000        &        0.388    &        0.403     \\\\\n",
       "\\textbf{article\\_type\\_research article}                   &       0.5032  &        0.035     &    14.196  &         0.000        &        0.434    &        0.573     \\\\\n",
       "\\textbf{article\\_type\\_software article}                   &      -0.5197  &        0.116     &    -4.475  &         0.000        &       -0.747    &       -0.292     \\\\\n",
       "\\textbf{n\\_author\\_devs * article\\_type\\_research article} &       0.0954  &        0.026     &     3.599  &         0.000        &        0.043    &        0.147     \\\\\n",
       "\\textbf{n\\_author\\_devs * article\\_type\\_software article} &       0.0697  &        0.058     &     1.210  &         0.226        &       -0.043    &        0.183     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Generalized Linear Model Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:         cited_by_count   No. Observations:                22649\n",
       "Model:                            GLM   Df Residuals:                    22641\n",
       "Model Family:        NegativeBinomial   Df Model:                            7\n",
       "Link Function:                    Log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -78130.\n",
       "Date:                Wed, 20 Nov 2024   Deviance:                       22169.\n",
       "Time:                        12:00:58   Pearson chi2:                 3.37e+04\n",
       "No. Iterations:                    34   Pseudo R-squ. (CS):             0.3091\n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================================\n",
       "                                                    coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------\n",
       "const                                             0.7721      0.035     21.939      0.000       0.703       0.841\n",
       "n_authors                                         0.0213      0.001     20.157      0.000       0.019       0.023\n",
       "n_author_devs                                    -0.0458      0.024     -1.894      0.058      -0.093       0.002\n",
       "years_since_publication                           0.3956      0.004     99.544      0.000       0.388       0.403\n",
       "article_type_research article                     0.5032      0.035     14.196      0.000       0.434       0.573\n",
       "article_type_software article                    -0.5197      0.116     -4.475      0.000      -0.747      -0.292\n",
       "n_author_devs * article_type_research article     0.0954      0.026      3.599      0.000       0.043       0.147\n",
       "n_author_devs * article_type_software article     0.0697      0.058      1.210      0.226      -0.043       0.183\n",
       "=================================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cited_by_count_models[\"article_type\"].summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- To enrich our pre-existing dataset, we apply our trained predictive model across pairs of authors and developer accounts.\n",
    "\t- again, these pairs are all combinations of author and developer account within an individual paper\n",
    "\t- specifics, how many unique author-developer account pairs are we able to find\n",
    "\t- table of author-developer account pairs for by data source / by field\n",
    "\t- we next use this enriched dataset to understand software development dynamics within research teams, and characterize the authors who are and who aren’t code contributors.\n",
    "\n",
    "## Software Development Dynamics Within Research Teams\n",
    "\n",
    "- We begin by measuring the distributions of different coding and non-coding contributors across all of the article-code-repository pairs within our dataset.\n",
    "\t- explain more, what are the different types of contributions? (coding contributor, coding-with-authorship contributor, non-coding-author, etc.)\n",
    "\t- what are the basics / what do we see across the board? What are the distributions of each of these contributor types\n",
    "\t- compare against analysis built on CRediT statements?\n",
    "\n",
    "- Next we investigate if these distributions change over time, or, by “research team size”.\n",
    "\t- define research team size, in our case this is the total number of author-developers + non-coding authors + non-credited developers\n",
    "\t- plot the medians of the contributor type distributions over time (by publication year)\n",
    "\t- create subplots of different bins of research team size (i.e. <= 3 members, >3 <= 5, >5 <= 10, >10) and show distributions again.\n",
    "\t- results in summary\n",
    "\n",
    "- We further investigate how these distributions are affected by article type and research domain.\n",
    "\t- refresher on article type (research articles, software articles, and pre-prints)\n",
    "\t- explain research domains\n",
    "\t- subplots of both\n",
    "\t- results in summary\n",
    "\n",
    "## Characteristics of Scientific Code Contributors\n",
    "\n",
    "- Next we investigate the differences between coding and non-coding article authors.\n",
    "\t- specifics, author position in authorship list is a commonly used tool in scientometrics\n",
    "\t- similarly, metrics of “scientific impact” such as h-index, i10 index, and two-year mean citedness are also available to us.\n",
    "\t- plot / table of the distributions between coding and non-coding authors\n",
    "\t- ANOVA / Chi2 tests to see if these differences are significant\n",
    "\t- results in summary\n",
    "\n",
    "- Just as before, we next investigate if these results are affected by article type and research domain.\n",
    "\t- subplot + stats tests for differences by each article type\n",
    "\t- subplot + stats tests for differences by each domain\n",
    "\t- results in summary\n",
    "\n",
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
